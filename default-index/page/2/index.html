<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="May All Your Troubles Be little Ones">
<meta property="og:type" content="website">
<meta property="og:title" content="Olivia的博客">
<meta property="og:url" content="http://example.com/default-index/page/2/index.html">
<meta property="og:site_name" content="Olivia的博客">
<meta property="og:description" content="May All Your Troubles Be little Ones">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Olivia">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/default-index/page/2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>
<link rel="stylesheet" href="//cdn.jsdelivr.net/gh/theme-next/theme-next-needmoreshare2@1/needsharebutton.min.css"><style>
#needsharebutton-postbottom {
  cursor: pointer;
  height: 26px;
  margin-top: 10px;
  position: relative;
}
#needsharebutton-postbottom .btn {
  border: 1px solid $btn-default-border-color;
  border-radius: 3px;
  display: initial;
  padding: 1px 4px;
}
</style><style>
#needsharebutton-float {
  bottom: 88px;
  cursor: pointer;
  left: -8px;
  position: fixed;
  z-index: 9999;
}
#needsharebutton-float .btn {
  border: 1px solid $btn-default-border-color;
  border-radius: 4px;
  padding: 0 10px 0 14px;
}
</style>
  <title>Olivia的博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Olivia的博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/03/15/%E7%AC%AC07%E5%91%A8/Query%20Graph%20Generation%20for%20Answering%20Multi-hop%20Complex%20Questions%20from%20Knowledge%20Bases/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Olivia">
      <meta itemprop="description" content="May All Your Troubles Be little Ones">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Olivia的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/03/15/%E7%AC%AC07%E5%91%A8/Query%20Graph%20Generation%20for%20Answering%20Multi-hop%20Complex%20Questions%20from%20Knowledge%20Bases/" class="post-title-link" itemprop="url">Query Graph Generation for Answering Multi-hop Complex Questions from Knowledge Bases</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-03-15 00:00:00" itemprop="dateCreated datePublished" datetime="2021-03-15T00:00:00+08:00">2021-03-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-06 11:56:45" itemprop="dateModified" datetime="2021-05-06T11:56:45+08:00">2021-05-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/" itemprop="url" rel="index"><span itemprop="name">Knowledge Base Qestion Answering</span></a>
                </span>
                  >
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/paper-comprehension/" itemprop="url" rel="index"><span itemprop="name">paper comprehension</span></a>
                </span>
                  >
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/paper-comprehension/latest/" itemprop="url" rel="index"><span itemprop="name">latest</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>3.4k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>3 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ul>
<li>论文原文：https://www.aclweb.org/anthology/2020.acl-main.91.pdf</li>
</ul>
<h2 id="introduction">1. Introduction</h2>
<ul>
<li>目前主要在研究两种复杂性问题：
<ul>
<li>带约束的单一关系问题(Single-relation questions with constraints)</li>
<li>具有多跳关系的问题(Questions with <em>multiple hops</em> of relations)
<ul>
<li>减少需考虑的多跳关系路径的数量，本文采用beam search，即consider only the best matching relation instead of all relations when extending a relation path.</li>
</ul></li>
</ul></li>
<li>本文同时处理复杂KBQA的约束和多跳关系。
<ul>
<li>在查询图的生成过程中，允许更长的关系路径。</li>
<li>不再是关系路径构建完成之后再添加约束，而是同时合并约束和扩展关系路径，可以减少搜索空间。</li>
</ul></li>
</ul>
<h2 id="method">2. Method</h2>
<h3 id="preliminaries">2.1 Preliminaries</h3>
<ul>
<li><p>现有的查询图生成方法【本文largely inspired by】</p>
<p>【<span id="2015"><a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/P15-1128.pdf">Semantic parsing via staged query graph generation: Question answering with knowledge base, 2015</a></span></p>
<p><span id="2016"><a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/C16-1236.pdf">Constraint-based question an- swering with knowledge graph, 2016</a></span></p>
<p><span id="2018"><a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/D18-1242.pdf">Knowledge base question answering via en- coding of complex query graphs, 2018</a></span>】</p></li>
<li><p>一个查询图(query graph)有四种结点：</p>
<ul>
<li>grounded entity(带阴影的矩形)：知识库中已经存在的实体</li>
<li>existential variable(无阴影的矩形)：不是一个grounded entity</li>
<li>lambda variable(圆形)：不是一个grounded entity，但是代表了答案</li>
<li>aggregation function(菱形)：聚合函数</li>
</ul></li>
<li><p>查询图的边来自知识图中的关系，一个查询图应该只有一个lambda变量表示答案，不止一个grounded entity、没有或者多个existential变量和聚合函数。</p></li>
<li><p>查询图生成过程(<a href="#2015">Yih et al., 2015</a>; <a href="#2016">Bao et al., 2016</a>)：</p>
<ol type="1">
<li><p>Starting from a grounded entity found in the question (referred to as a <em>topic entity</em>), identify a core relation path linking the topic entity to a lambda variable. Existing work considers core relation paths containing a single relation(<a href="#2015">Yih et al., 2015</a>; <a href="#2016">Bao et al., 2016</a>; <a href="#2018">Luo et al., 2018</a>).</p></li>
<li><p>From a core relation path identified in Step 1, attach one or more constraints found in the question. A constraint consists of either a grounded entity or an aggregation function together with a relation.</p></li>
<li><p>With all the candidate query graphs generated from Step 1 and Step 2, rank them by measuring their similarities with the question. This is typically done through a neural network model such as a CNN . (<a href="#2015">Yih et al., 2015</a>; <a href="#2016">Bao et al., 2016</a>).</p></li>
<li><p>Execute the top-ranked query graph against the KB to obtain the answer entities.</p></li>
</ol>
<figure>
<img src="https://i.loli.net/2021/03/22/XeE7IC63fdyuUp5.png" alt="image-20210322215711338.png" /><figcaption aria-hidden="true">image-20210322215711338.png</figcaption>
</figure></li>
</ul>
<h3 id="motivation">2.2 Motivation</h3>
<ul>
<li>看起来更像是两个模型的组合：上述模型不利于解决多跳问题；最新研究出的多跳模型(beam search，在生成t+1跳关系路径之前只保留前K个t跳关系路径【(<a href="#2019">Chen et al., 2019</a>; <a href="#2019b">Lan et al., 2019b</a>)】)但忽略了在生成过程中的约束。</li>
<li>不再是关系路径构建完成之后再添加约束，而是同时合并约束和扩展关系路径。</li>
<li>This more flexible way of generating query graphs, coupled with <strong>a beam search mechanism</strong> and <strong>a semantic matching model</strong> to guide pruning, explores a much smaller search space while still maintaining a high chance of finding the correct query graph.</li>
</ul>
<h3 id="query-graph-generation">2.3 Query Graph Generation</h3>
<ul>
<li><p>利用波束搜索来迭代生成候选查询图。假设第<span class="math inline">\(t\)</span>次迭代产生K个查询图的集合，在<span class="math inline">\(t+1\)</span>次迭代中，作者使用了extend、connect、aggregate三个行为之一来为当前的查询图添加一条边或一个节点。在每个时间步获得查询图之后，用评分函数来对所有查询图进行排序，并找出 top-k。如此持续迭代，<strong>直到某一迭代的评分不高于它前一迭代的评分。</strong></p>
<p>如下图：<img src="http://p3.itc.cn/q_70/images03/20200715/7d053c5f849e45c0b9c06fc39fda1b8f.png" alt="img" /></p></li>
</ul>
<h4 id="extend">2.3.1 extend</h4>
<ul>
<li><strong>扩展</strong>动作将核心关系路径扩展了 R 中的一个关系。如果当前查询图仅包含主题实体 e，则扩展动作将在 KB 中找到链接到 e 的关系 r，并将路径增长到 r。<strong>它还使 r 的另一端成为 lambda 变量 x。</strong>如果当前查询图具有 lambda 变量 x，则扩展操作会将 x 更改为存在变量 y，通过对 KB 执行当前查询图来查找 KB 中 y 的所有绑定，找到链接到这些实体之一的关系 r ，最后将 r 附加到 y。r 的另一端成为新的 lambda 变量 x。</li>
</ul>
<h4 id="connect">2.3.2 connect</h4>
<ul>
<li>除了当前核心关系路径开始处的主题实体之外，问题中通常还会找到其他实体。 <strong>连接</strong>操作将这样的实体 e <strong>链接到 lambda 变量 x 或连接到 x 的存在变量</strong>（即 CVT 节点）。要确定使用哪个关系 r 链接 e 和 x，我们可以再次找到 x 的所有绑定，通过执行当前查询图，然后找到这些实体之一与 e 之间存在的关系。</li>
</ul>
<h4 id="aggregate">2.3.3 aggregate</h4>
<ul>
<li>作者使用一组预定义的关键字从问题中检测聚合函数。聚合操作会将检测到的聚合函数作为新节点附加到 lambda 变量 x 或连接到作为 CVT 节点的 x 的存在变量。</li>
</ul>
<h4 id="总结">2.3.4 总结</h4>
<ul>
<li>该方法的新颖之处在于，可以在连接和聚合操作之后应用扩展操作，而以前的方法是不允许的。扩展和连接操作可以理解为对多跳推理的实现，而聚合操作可理解为对问题约束的实现。</li>
</ul>
<h3 id="query-graph-ranking">2.4. Query Graph Ranking</h3>
<ul>
<li>在第 t 次迭代的末尾，算法对候选查询图进行排序，每个图获得 7 维的特征向量，并将这些向量馈送到一个全连接层。</li>
<li>向量的第一个维度来自基于 BERT 的语义匹配模型。具体来说，算法通过遵循构造查询图 g 所采取的动作序列并将每个步骤所涉及的实体和关系的文本描述顺序添加到序列中，将 g 转换为标记序列。存在变量和 lambda 变量将被忽略。</li>
<li>向量的其他 6 个维度如下：第一个维度是查询图中所有已链接实体的累积实体链接得分。第二个是查询图中出现的链接实体的数量。第三到第五个分别是查询图中实体类型的数量，时间表达式和最高级的数量。最后一个特征是查询图的答案实体的数量。</li>
</ul>
<h2 id="引用">引用</h2>
<ol type="1">
<li><p><a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/P15-1128.pdf">Semantic parsing via staged query graph generation: Question answering with knowledge base, 2015</a></p></li>
<li><p><a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/C16-1236.pdf">Constraint-based question an- swering with knowledge graph, 2016</a></p></li>
<li><p><a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/D18-1242.pdf">Knowledge base question answering via encoding of complex query graphs, 2018</a></p></li>
<li><p><span id="2019"><a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/N19-1031.pdf">Uhop: An unrestricted-hop relation extraction framework for knowledge-based question answering, 2019</a></span></p></li>
<li><p><span id="2019b"><a target="_blank" rel="noopener" href="https://ink.library.smu.edu.sg/cgi/viewcontent.cgi?article=5939&amp;context=sis_research">Multi-hop knowledge base question answering with an iterative sequence matching model, 2019b</a></span></p></li>
</ol>

      
    </div>

    
	
	

	
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/03/08/%E7%AC%AC06%E5%91%A8/1.%20Improving%20Machine%20Reading%20Comprehension%20with%20General%20Reading%20Strategies/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Olivia">
      <meta itemprop="description" content="May All Your Troubles Be little Ones">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Olivia的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/03/08/%E7%AC%AC06%E5%91%A8/1.%20Improving%20Machine%20Reading%20Comprehension%20with%20General%20Reading%20Strategies/" class="post-title-link" itemprop="url">Improving Machine Reading Comprehension with General Reading Strategies</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-03-08 00:00:00" itemprop="dateCreated datePublished" datetime="2021-03-08T00:00:00+08:00">2021-03-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-06 11:48:00" itemprop="dateModified" datetime="2021-05-06T11:48:00+08:00">2021-05-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/" itemprop="url" rel="index"><span itemprop="name">Knowledge Base Qestion Answering</span></a>
                </span>
                  >
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/paper-comprehension/" itemprop="url" rel="index"><span itemprop="name">paper comprehension</span></a>
                </span>
                  >
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/paper-comprehension/%E7%9E%8E%E7%9C%8B%E7%9C%8B/" itemprop="url" rel="index"><span itemprop="name">瞎看看</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>2.9k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>3 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ul>
<li>论文地址：https://www.aclweb.org/anthology/N19-1270.pdf</li>
</ul>
<h2 id="abstract">Abstract</h2>
<ul>
<li>在给定有限的计算资源(只有一个预先训练的模型和固定数量的训练实例)的情况下，我们提出了三个通用策略——即时机器提取阅读理解(MRC):(1)考虑输入序列的原始顺序和反向顺序的<strong>前后阅读(BACK AND FORTH READING, BF)</strong>，(2)<strong>高亮显示(HIGHLIGHTING, HL)</strong>，这将可训练的嵌入添加到与问题和候选答案相关的标记的文本嵌入中，以及(3)自我评估(SELF-ASSESSMENT, SA)，这将直接从文本中以无监督的方式生成练习问题和候选答案。</li>
</ul>
<h2 id="introduction">1. Introduction</h2>
<ul>
<li><p><strong>本文主要关注于非提取型MRC，其中相当大比例的候选答案不限于参考文档或语料库的文本spans。</strong>与提取型MRC任务(第2.1节)相比，<strong>非提取型MRC(第2.2节)需要不同的阅读技能</strong>，因此，机器读者在这些任务上的表现更准确地表明了机器读者在现实环境(如考试)中的理解能力(赖等人，2017年)。</p></li>
<li><p>在微调时提高机器阅读理解能力，而不是通过昂贵的预训练。提出了三个相应的领域独立地策略，以提高基于目前现有的pre-trained transformer模型的MRC(Sec 3.1)。</p>
<ul>
<li>BACK AND FORTH READING(“我在文本中前前后后寻找其中的想法之间的关系。”):<strong>考虑输入序列的原始顺序和反向顺序</strong>(第3.2节)</li>
<li>HIGHLIGHTING(“我突出显示文本中的信息，以帮助我记住它。”)<strong>在与问题和候选答案相关的标记的文本嵌入中添加一个可训练的嵌入</strong>(第3.3节)</li>
<li>自我评估(“我问自己想在文本中回答的问题，然后检查我对文本的猜测是对还是错。”):<strong>从现有参考文件中生成练习问题及其相关的基于范围的候选答案</strong>(第3.4节)</li>
</ul></li>
</ul>
<h2 id="task-introduction">2. Task Introduction</h2>
<ul>
<li>根据<strong>预期的答案类型</strong>（其实是根据目前现有的数据集类型），将机器阅读理解分为两大类：提取型(extractive)(Sec 2.1)和非提取型(non-extractive)(Sec 2.2)</li>
</ul>
<h3 id="提取型mrc">2.1 提取型MRC</h3>
<ul>
<li>给定一个参考文档和一个问题，<strong>期望的答案是文档的一小段</strong>。</li>
<li>另一种：在例如SearchQA和NarrativeQA等数据集上的答案则是基于给定文档的由人设置的自由形式的文本。然而<strong>由于注释者倾向于直接复制spans作为答案</strong>，所以大多数答案仍然是提取的。</li>
</ul>
<h3 id="非提取型mrc">2.2 非提取型MRC</h3>
<ul>
<li><p>主要讨论多选择MRC数据集，其中答案选项不限于提取的文本范围。<strong>给定一个问题和一个参考文档/语料库，提供多个答案选项，其中至少有一个是正确的。</strong></p></li>
<li><p>与抽取式MRC任务中的问题相比，<strong>除了表面匹配之外，还有各种类型的复杂问题，</strong>如数学应用题、摘要、逻辑推理和情感分析，需要高级阅读技能和先验世界知识。此外，在大多数情况下，我们可以采用准确性等客观的评估标准来评估系统性能(克拉克等人，2016；Lai等人，2017)。</p></li>
</ul>
<h2 id="approach">3. Approach</h2>
<h3 id="framework-overview">3.1 Framework Overview</h3>
<ul>
<li><p>遵循有区别地微调生成预训练transformer的框架(GPT)。它采用预先训练的多层transformer将语言模型转换为标记数据集<span class="math inline">\(C\)</span>，其中每一个实例由一系列输入标记<span class="math inline">\(x^1,...,x^n\)</span>及标签<span class="math inline">\(y\)</span>，最大化： <span class="math display">\[
\sum_{x,y}logP(y|x^1,...,x^n)+\lambda \cdot L(C)
\]</span> <span class="math inline">\(L\)</span>: 语言的似然函数</p>
<p><span class="math inline">\(\lambda\)</span>: 语言模型的权重</p>
<p><span class="math inline">\(P(y|x^1,...,x^n)\)</span>: 通过语言模型的最后transformer模块激活上的线性分类层得到的。</p>
<p>对于多选择MRC，<span class="math inline">\(x_1,...x_n\)</span>来自开始标记、参考文档、问题、分隔符标记、答案选项和结束标记的连接</p>
<p><span class="math inline">\(y\)</span>表示答案选项的正确性。</p></li>
<li><p>下图为整体框架<img src="https://s3.ax1x.com/2021/03/15/6rmHcq.png" alt="6rmHcq.png" /></p></li>
</ul>
<h3 id="back-and-forth-readingbf">3.2 Back and Forth Reading(BF)</h3>
<ul>
<li>将GPT原始输入序列表示为<span class="math inline">\([dq\ \$\ o]\)</span>，其中<span class="math inline">\([\ ,\$\ \)</span>和<span class="math inline">\(]\ \)</span>分别表示开始标记(start token)，定界标记(delimiter token)和结束标记(end token)。</li>
<li>考虑原始序列和反向序列<span class="math inline">\([o\ \$\ qd]\)</span>。<span class="math inline">\(d,q,o\)</span>中的token依旧保留。分别对两个分别使用<span class="math inline">\([dq\ \$\ o]\)</span>和<span class="math inline">\([o\ \$\ qd]\)</span>作为输入序列的GPT进行微调，然后将两个模型合在一起。</li>
<li>同时还考虑了其他类似的输入序列对，例如<span class="math inline">\([qd\ \$\ o]\)</span>和<span class="math inline">\([o\ \$\ dq]\)</span>。【Sec. 4.3】</li>
</ul>
<h3 id="highlightinghl">3.3 Highlighting(HL)</h3>
<ul>
<li><p>文档的文本嵌入独立于其相关的问题和候选答案。旨在使文档编码了解相关的问答选项对<span class="math inline">\((q,o_i)\)</span>。专注于问题和答案选项中的内容词，我们通过其词性(POS)标签（例如：名词、动词、形容词、副词、数字、或外来词）来分辨内容词。</p></li>
<li><p><span class="math inline">\(T\)</span>：POS标签集</p>
<p><span class="math inline">\(d\)</span>：文档<span class="math inline">\(d\)</span>的文本嵌入顺序</p>
<p><span class="math inline">\(d^j\)</span>：表示<span class="math inline">\(d\)</span>中第<span class="math inline">\(j\)</span>个token【对应文档<span class="math inline">\(d\)</span>】，表示<span class="math inline">\(d\)</span>中的第<span class="math inline">\(j\)</span>个文本embedding【对应embedding】</p>
<p>给定文档<span class="math inline">\(d\)</span>和一个问题答案对<span class="math inline">\((q,o_i)\)</span>，我们将文档<span class="math inline">\(d\)</span>中第<span class="math inline">\(j\)</span>个token对应的<em>highlight embedding</em><span class="math inline">\(h_i^j\)</span>定义为<img src="https://s3.ax1x.com/2021/03/16/6sfvMF.png" alt="6sfvMF.png" /></p></li>
<li><p>高亮嵌入<span class="math inline">\(h_i=h_i^1,h_i^2,...,h_i^n\)</span>的长度与<span class="math inline">\(d\)</span>相同。当对文档编码时，将<span class="math inline">\(d\)</span>替换成<span class="math inline">\(d_i=d+h_i\)</span>。更具体地说，我们在微调期间使用<span class="math inline">\(b,d_i,q,l,o_i\)</span>和<span class="math inline">\(e\)</span>的concatenation作为GPT的新输入【Sec. 3.1】，其中<span class="math inline">\(b,l\)</span>和<span class="math inline">\(e\)</span>分别表示开始token、分割符号token和结束符号token的embedding，<span class="math inline">\(q\)</span>和<span class="math inline">\(o_i\)</span>分别表示<span class="math inline">\(q\)</span>和<span class="math inline">\(o_i\)</span>的文本embedding序列。</p></li>
</ul>
<h3 id="self-assessmentsa">3.4. Self-Assessment(SA)</h3>
<ul>
<li><p>在自我评估阅读策略的启发下开发了一种微调方法。我们提出了一种简单的方法来生成问题及其关联的多个基于span的答案选项，这些选项涵盖了参考文档中多个句子的内容。目标是使得到的微调模型更了解输入结构，并根据回答给定问题可能需要的跨多个句子集成信息。</p></li>
<li><p>基于结束任务（即本文中的RACE）的每个文档随机生成不超过<span class="math inline">\(n_q\)</span>个问题和相关的答案选项，步骤描述如下：</p>
<ul>
<li>输入：来自结束任务的参考文档</li>
<li>输出：与参考文档相关联的一个问题和四个答案选项</li>
</ul>
<ol type="1">
<li>从文档中随机选择不超过<span class="math inline">\(n_s\)</span>个句子，并将这些句子连接在一起。</li>
<li>从连接的句子中随机选择不超过<span class="math inline">\(n_c\)</span>个不重复的span。每个span在单个句子中随机包含不超过<span class="math inline">\(n_t\)</span>个token。我们将选定的span连接起来，以形成正确的答案选项。我们从连接的句子中删除选定的span，并使用剩余的文本作为问题。</li>
<li>通过将正确答案选项中的span随机替换为从文档中随机选出的span，生成三个干扰项（错误选项）</li>
<li><span class="math inline">\(n_q,n_s,n_c,n_t\)</span>都是用于控制问题的数量和难度级别。</li>
</ol></li>
</ul>

      
    </div>

    
	
	

	
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/03/08/%E7%AC%AC06%E5%91%A8/2.%20LUKE-Deep%20Contextualized%20Entity%20Representations%20with%20Entity-aware%20Self-attention/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Olivia">
      <meta itemprop="description" content="May All Your Troubles Be little Ones">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Olivia的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/03/08/%E7%AC%AC06%E5%91%A8/2.%20LUKE-Deep%20Contextualized%20Entity%20Representations%20with%20Entity-aware%20Self-attention/" class="post-title-link" itemprop="url">LUKE-Deep Contextualized Entity Representations with Entity-aware Self-attention</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-03-08 00:00:00" itemprop="dateCreated datePublished" datetime="2021-03-08T00:00:00+08:00">2021-03-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-06 11:48:24" itemprop="dateModified" datetime="2021-05-06T11:48:24+08:00">2021-05-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/" itemprop="url" rel="index"><span itemprop="name">Knowledge Base Qestion Answering</span></a>
                </span>
                  >
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/paper-comprehension/" itemprop="url" rel="index"><span itemprop="name">paper comprehension</span></a>
                </span>
                  >
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/paper-comprehension/%E7%9E%8E%E7%9C%8B%E7%9C%8B/" itemprop="url" rel="index"><span itemprop="name">瞎看看</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>2.8k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>3 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>论文地址：https://www.aclweb.org/anthology/2020.emnlp-main.523/</p>
<h2 id="abstract">Abstract</h2>
<ul>
<li>新的基于BERT的单词和实体的预处理上下文化表示，<strong>所提出的模型将给定文本中的单词和实体视为独立的标记，并输出它们的上下文化表示</strong>。我们还提出了一种实体感知的自我注意机制，它是transformer中自我注意机制的扩展，并在计算注意力分数时考虑了标记(单词或实体)的类型。</li>
</ul>
<h2 id="introduction">1. Introduction</h2>
<ul>
<li>之前的知识库(KB)需要实体链接来表示文本中的实体，并且不能表示知识库中不存在的实体。</li>
<li>基于transformer的<strong>语境化单词表征(CWR, contextualized word representations)</strong>，如BRET和Roberta，提供了利用基于语言建模的无监督预训练模型训练的有效的通用单词表征。但是CWR体系结构不太适合表示实体，因为
<ul>
<li><strong>CWR不输出实体的span级别的表示</strong>，它们通常需要学习如何基于通常较小的下游数据集来计算这样的表示。</li>
<li>许多实体相关任务，如关系分类、问答等，都涉及到实体间关系的推理。尽管transformer可以通过使用自我注意机制将单词相互关联来捕捉单词之间的复杂关系，但很难<strong>在实体之间执行这样的推理，因为许多实体在模型中被分成多个token</strong>。</li>
<li><strong>CWR的基于单词的预训练任务不适合于学习实体表示</strong>，因为预测实体中给出其他单词的掩蔽单词，例如给出"The Lord Of [MASK]"预测"Rings"显然比预测整个实体更容易。</li>
</ul></li>
<li><strong>LUKE(Language Understanding with Knowledge-based Embedding)</strong>【基于知识的嵌入式语言理解】，基于一个transformer，使用从维基百科获得的大量实体注释语料库进行训练。与现有CWR的一个重要区别是，<strong>不仅将单词视为一个独立的token，还将实体视为独立的token，并使用transformer计算所有令牌的中间和输出表示，如图1。由于实体可被视为token，因此LUKE可以直接对实体之间的关系建模。</strong><img src="https://s3.ax1x.com/2021/03/17/66bu2d.png" alt="66bu2d.png" /></li>
</ul>
<h2 id="related-work">2. Related Work</h2>
<h3 id="静态实体表示static-entity-representations">2.1 静态实体表示(Static Entity Representations)</h3>
<ul>
<li>常规实体表示为KB中的每个实体分配固定嵌入。<strong>包括在知识图上训练的知识嵌入，以及使用从知识库检索到的实体的文本上下文或描述来训练的嵌入</strong></li>
<li>NTEE(Yamada等人，2017年)和Relic(Ling等人，2020年)使用一种方法，<strong>通过预测从知识库获得的实体的文本上下文来训练实体嵌入</strong>。当用文本表示实体时，这一行的主要缺点是(1)它们需要将文本中的实体解析为相应的知识库条目来表示实体，以及(2)它们不能表示知识库中不存在的实体。</li>
</ul>
<h3 id="语境化的词表示contextualized-word-representations">2.2 语境化的词表示(Contextualized Word Representations)</h3>
<ul>
<li>最近都是基于使用CWR的</li>
</ul>
<h2 id="luke">3. LUKE</h2>
<ul>
<li>图一显示了LUKE的架构，采用多层bidirectional transformer。将文档中的单词和实体视为输入令牌，并计算每个令牌的表现形式。形式上，给定<span class="math inline">\(m\)</span>个词<span class="math inline">\(w_1,w_2,...w_m\)</span>和<span class="math inline">\(n\)</span>个实体<span class="math inline">\(e_1,e_2,...,e_n\)</span>组成的序列，我们的模型计算<span class="math inline">\(D\)</span>维子表示<span class="math inline">\(h_{w_1},h_{w_2},...,h_{w_m}\)</span>和实体表示<span class="math inline">\(h_{e_1},h_{e_2},...h_{e_n}\)</span>。这些实体可以是维基百科实体（例如Beyonce in Figure 1）或者特殊实体（例如[MASK]）</li>
</ul>
<h3 id="输入表示input-representation">3.1 输入表示(Input Representation)</h3>
<ul>
<li>使用以下三个embeddings计算令牌(单词或实体)的输入表示</li>
</ul>
<h4 id="token-embedding">3.1.1 Token embedding</h4>
<ul>
<li>word token embedding: <span class="math inline">\(A \in R^{V_w×D}\)</span>,<span class="math inline">\(V_w\)</span>是词汇表中的单词数量</li>
<li>entity token embedding: 为提高计算效率，将entity token embedding分解为两个小矩阵<span class="math inline">\(B\in R^{V_e×H}\)</span>和<span class="math inline">\(U\in R^{H×D}\)</span>，<span class="math inline">\(V_e\)</span>是词汇表中所有实体数量。故entity token embedding可以计算为<span class="math inline">\(BU\)</span>。</li>
</ul>
<h4 id="position-embedding">3.1.2 Position embedding</h4>
<ul>
<li>表示token在单词序列中的位置。</li>
<li>出现在序列中第<span class="math inline">\(i\)</span>个位置的单词和实体分别表示为<span class="math inline">\(C_i\in R^D\)</span>和<span class="math inline">\(D_i\in R^D\)</span>。</li>
<li>如果实体名称包含多个单词，则通过平均相应位置的embedding来计算其位置嵌入。</li>
</ul>
<h4 id="entity-type-embedding">3.1.3 Entity type embedding</h4>
<ul>
<li>表示token是一个entity</li>
<li>是由<span class="math inline">\(e\in R^D\)</span>表示的单个向量。</li>
</ul>
<h4 id="combination">3.1.4 Combination</h4>
<ul>
<li>单词的输入表示：Token embedding+Position embedding</li>
<li>实体的输入表示：Token embedding+Position embedding+Entity type embedding</li>
<li>将特殊标记<strong>[CLS]</strong>和<strong>[SEP]</strong>分别作为第一个和最后一个单词插入到单词序列中。</li>
</ul>
<h3 id="entity-aware-self-attention">3.2 Entity-aware Self-attention</h3>
<ul>
<li><p>自注意力机制基于每对标记之间的注意分数将标记彼此关联。给定输入向量序列<span class="math inline">\(x_1,x_2,...,x_k,x_i\in R^D\)</span>。每个输出向量序列<span class="math inline">\(y_1,y_2,...,y_k,y_i\in R^L\)</span>都是基于transformer的输入向量的加权和来计算的。这里，每个输入和输出向量对应于我们模型中的一个令牌（一个单词或一个实体），所以<span class="math inline">\(k=m+n\)</span>，第<span class="math inline">\(i\)</span>个输出向量<span class="math inline">\(y_i\)</span>的计算公式为：<img src="https://s1.imagehub.cc/images/2021/03/17/image-20210317165507977.png" alt="image-20210317165507977.png" /></p></li>
<li><p>以上为正常计算方法，但因LUKE处理两种类型的标记（单词和实体），因此我们假设在计算注意力得分(<span class="math inline">\(e_{ij}\)</span>)时使用目标标记的类型信息时有益的。故通过引入<em>实体感知(entity-aware)</em>查询机制来增强该机制，该机制对每对可能的令牌类型<span class="math inline">\(x_i\)</span>和<span class="math inline">\(x_j\)</span>采用不同的查询矩阵，注意力得分(<span class="math inline">\(e_{ij}\)</span>)计算方法如下：<img src="https://s1.imagehub.cc/images/2021/03/17/image-20210317170448320.png" alt="image-20210317170448320.png" /></p>
<p>其中<span class="math inline">\(Q_{w2e},Q_{e2w},Q_{e2e} \in R^{L×D}\)</span>都是查询矩阵</p></li>
<li><p>除了在训练时计算梯度和更新附加查询矩阵的参数的额外开销之外，原始机制和我们提出的机制的计算成本是相同的。</p></li>
</ul>
<h3 id="pretraining-task">3.3 Pretraining Task</h3>
<ul>
<li><p>对LUKE进行预训练，使用传统的掩码语言模型(Masked Language Model, MML)和MML的扩展来学习实体表示。</p></li>
<li><p>通过用特殊的[MASK]实体来替换特定百分比的实体，然后训练模型来预测被掩码的实体。</p></li>
<li><p>通过在我们的词汇表中的所有实体上应用Softmax函数来预测与屏蔽实体相对应的原始实体：</p>
<figure>
<img src="C:\Users\Olivia~\AppData\Roaming\Typora\typora-user-images\image-20210317172031283.png" alt="image-20210317172031283" /><figcaption aria-hidden="true">image-20210317172031283</figcaption>
</figure></li>
</ul>

      
    </div>

    
	
	

	
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/03/01/%E7%AC%AC05%E5%91%A8/1.%20%E8%AF%AD%E4%B9%89%E8%A7%A3%E6%9E%90-Semantic%20Parsing%20on%20Freebase%20from%20Question-Answer%20Pairs/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Olivia">
      <meta itemprop="description" content="May All Your Troubles Be little Ones">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Olivia的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/03/01/%E7%AC%AC05%E5%91%A8/1.%20%E8%AF%AD%E4%B9%89%E8%A7%A3%E6%9E%90-Semantic%20Parsing%20on%20Freebase%20from%20Question-Answer%20Pairs/" class="post-title-link" itemprop="url">1. 语义解析-Semantic Parsing on Freebase from Question-Answer Pairs</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-03-01 00:00:00" itemprop="dateCreated datePublished" datetime="2021-03-01T00:00:00+08:00">2021-03-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-04 15:15:37" itemprop="dateModified" datetime="2021-05-04T15:15:37+08:00">2021-05-04</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/" itemprop="url" rel="index"><span itemprop="name">Knowledge Base Qestion Answering</span></a>
                </span>
                  >
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/paper-comprehension/" itemprop="url" rel="index"><span itemprop="name">paper comprehension</span></a>
                </span>
                  >
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/paper-comprehension/basis/" itemprop="url" rel="index"><span itemprop="name">basis</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>4.7k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>4 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ul>
<li>论文原文：https://nlp.stanford.edu/pubs/semparseEMNLP13.pdf</li>
</ul>
<h2 id="简介">1. 简介</h2>
<ul>
<li><p>经典的语义解析，baseline方法</p></li>
<li><p><strong>语义解析（Semantic Parsing）</strong>KB-QA的思路是通过对自然语言进行语义上的分析，转化为一种在知识库中的语义表示，进而通过知识库中的知识，进行<strong>推理（Inference）查询（Query）</strong>，得出最终答案，这种语义表示即<strong>逻辑形式（Logic Form）</strong></p></li>
<li><p>逻辑形式</p>
<ul>
<li><p>Lambda Dependency-Based Compositional Semantics ( Lambda-DCS)是一种经典的逻辑语言，它用于处理逻辑形式（在实际操作中，逻辑形式会转化SPARQL query，可以在Virtuoso engine上对Freebase进行查询）</p></li>
<li><p>用<span class="math inline">\(z\)</span>表示一个逻辑形式，用<span class="math inline">\(K\)</span>表示知识库，<span class="math inline">\(e\)</span>表示实体，<span class="math inline">\(p\)</span>表示实体关系（谓词或属性）。逻辑形式分为一元形式（unary）和二元形式（binary）。对于一个一元实体<span class="math inline">\(e\)</span>，我们可以查询出对应知识库中的实体，给定一个二元关系<span class="math inline">\(p\)</span>，可以查到它在知识库中所有与该实体关系<span class="math inline">\(p\)</span>相关的三元组中的实体对。并且我们可以像数据库语言一样，进行连接Join，并求交集Intersection和聚合Aggregate（如计数，求最大值等等）操作。具体来说，逻辑形式有以下形式和操作</p>
<figure>
<img src="https://pic1.zhimg.com/v2-9e277da14c5756f74b97cc36c626e69c_r.jpg" alt="img" /><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>有了上面的定义，就可将一个自然语言问题表示为一个可以在知识库中进行查询的逻辑形式，比如问句</p>
<p>"Number of dramas starring Tom Cruise"</p>
<p>它对应的逻辑形式是</p>
<p><span class="math inline">\(count(Genre.Drama\cap Performance.Actor.TomCruise)\)</span></p>
<p>当自然语言问题转化为逻辑形式后，通过相应的逻辑语言（转化为SPARQL query）查询知识库就可以得到答案。</p></li>
</ul></li>
</ul>
<h2 id="语义解析kb-qa的方法框架">2. 语义解析KB-QA的方法框架</h2>
<ul>
<li><p>语义解析的过程可以看作是自底向上构造语法树的过程，树的根节点，就是该自然语言问题最终的逻辑形式表达。整个流程可以分为两部分</p>
<ul>
<li><strong>词汇映射</strong>：即构造底层的语法树节点。将单个自然语言短语或单词映射到知识库实体或知识库实体关系所对应的逻辑形式。我们可以通过构造一个<strong>词汇表(Lexicon)</strong>来完成这样的映射。</li>
<li><strong>构建(Composition)</strong>：即自底向上对树的节点进行两两合并，最后生成根节点，完成语法树的构建。这一步有很多方法，诸如构造大量手工规则，组合范畴语法（Combinatory Categorical Grammars，CCG），本文采用了最暴力的方法，即对于两个节点都可以执行上面所谈到的连接Join，求交Intersection，聚合Aggregate三种操作，以及本文独创的桥接Bridging操作进行结点合并。显然，这种合并方式复杂程度是指数级的，最终会生成许多棵语法树，我们需要通过对训练数据进行训练，训练一个分类器，对语法树进行筛选。</li>
</ul></li>
<li><p>自然语言转化为逻辑形式的流程如下图所示：</p>
<figure>
<img src="https://pic1.zhimg.com/v2-30043234fb15d3c23f1739fdaffb9278_r.jpg" alt="img" /><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>红色部分即<strong>逻辑形式</strong>，绿色部分where was Obama born为自然语言问题，蓝色部分为<strong>词汇映射（Lexicon）</strong>和<strong>构建（Composition）</strong>使用的操作，最后形成的语义解析树的根节点即语义解析结果。</p></li>
</ul>
<h2 id="训练分类器">3. 训练分类器</h2>
<ul>
<li><p>分类器的 任务是计算每一种语义解析结果<span class="math inline">\(d\)</span>（Derivation）的概率，作者通过discrimminative loglinear model进行modeling，使用Softmax进行概率归一化，公式如下</p>
<figure>
<img src="https://pic1.zhimg.com/v2-14c20c55d76c3b34edcc0a933615bd28_r.jpg" alt="img" /><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>其中<span class="math inline">\(x\)</span>代表自然语言问题，<span class="math inline">\(\phi(x,d_i)\)</span>是一个从语义解析结果<span class="math inline">\(d_i\)</span>和<span class="math inline">\(x\)</span>中提取出来的b维特征向量（该特征向量包括了构造该语法树所有操作的对应特征）<span class="math inline">\(\theta\)</span>是b维的参数向量。</p>
<p>对于训练数据 问题-答案对<span class="math inline">\((x_i,y_i)\)</span>，最大化log-likelihood损失函数，通过AdaGrad算法（一种动态调整学习率的随机梯度下降算法）进行参数更新。目标函数如下：</p>
<figure>
<img src="https://pic3.zhimg.com/v2-28e033572f6ccd29d0f9a9488adedb46_r.jpg" alt="img" /><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>可以看出特征向量的训练实际上是一种弱监督训练（准确的说是一种远程监督，Distant Supervison）。</p>
<ul>
<li><p>AdaGrad算法[https://zhuanlan.zhihu.com/p/61955391]</p>
<ul>
<li><p>该算法的思想是<strong>独立地适应模型的每个参数：具有较大偏导的参数相应有一个较大的学习率，而具有小偏导的参数则对应一个较小的学习率</strong></p></li>
<li><p>具体来说，每个参数的学习率会缩放各参数反比于其<strong>历史梯度平方值总和的平方根</strong></p></li>
<li><p>算法描述</p>
<figure>
<img src="https://pic4.zhimg.com/v2-72891bc0e46a96e2aa07681e4df686c3_r.jpg" alt="img" /><figcaption aria-hidden="true">img</figcaption>
</figure></li>
<li><p>注意：全局学习率<span class="math inline">\(\epsilon\)</span>并没有更新，而是每次应用时被缩放</p></li>
</ul></li>
</ul></li>
</ul>
<h2 id="构建词汇表">4. 构建词汇表</h2>
<ul>
<li><p>词汇表即自然语言与知识库实体或知识库实体关系的单点映射，这一操作也被成为<strong>对齐（Alignment）</strong>。</p></li>
<li><p>自然语言<strong>实体</strong>到知识库<strong>实体</strong>映射相对简单。比如将<em>“Obama was also born in Honolulu.”</em>中的实体<em>Obama</em>映射为知识库中的实体<em>BarackObama</em>，可以使用一些简单的字符串匹配方式进行映射。</p></li>
<li><p>但<strong>自然语言短语</strong>到相应知识库实体<strong>关系</strong>的映射较难，如<em>“was also born in”</em>映射到<em>PlaceOfBirth</em>。则可以<strong>使用统计</strong>，在文档中，如果有较多的实体对（entity1, entity2）作为主语和宾语出现在was born in的两侧，并且，在知识库中，这些实体也同时出现在包含<em>PlaceOfBirth</em>的三元组中，那么我们可以认为<em>"was also born in"</em>这个短语可以和<em>PlaceOfBirth</em>建立映射。</p>
<p>比如<em>（“Barack Obama”，“Honolulu”）,（“MichelleObama”，“Chicago”）</em>等实体对在文档中经常作为“was also <em>born in”</em>这个短语的主语和宾语，并且它们也都和实体关系<em>PlaceOfBirth</em>组成三元组出现在知识库中。</p></li>
<li><p>本文构建的词汇表</p>
<ul>
<li><p>利用<a target="_blank" rel="noopener" href="http://reverb.cs.washington.edu">ReVerbopen IE system</a>在<a target="_blank" rel="noopener" href="http://lemurproject.org/clueweb09/FACC1/">ClueWeb09</a>（注：该数据集由卡耐基梅隆学校在09年构建，还有一个12年的版本，<a target="_blank" rel="noopener" href="http://lemurproject.org/clueweb12/">ClueWeb12</a>）上抽取15millions个三元组构成一个数据集，如<em>(“Obama”, “was also born in”, “<strong>August 1961</strong>”)，</em>可以看出三元组的实体和关系都是自然语言的形式，取出其中的一个三元组子集，<strong>对里面的每一个三元组的主语实体和宾语实体通过字符匹配的方式替换为知识库的实体，并使用<a target="_blank" rel="noopener" href="http://nlp.stanford.edu/pubs/lrec2012-sutime.pdf">SUTime</a>对数据进行归一化。</strong>如：<em>(“Obama”, “was also born in”, “August 1961”)</em> 经过预处理后转化为 <em>(BarackObama, “was also born in”, 1961-08)</em>。</p></li>
<li><p>接着对每一个三元组中的自然语言短语<span class="math inline">\(r_1\)</span>两边的实体对（entity1, entity2）进行标注，同时需要注意，由于自然语言短语<span class="math inline">\(r_1\)</span>和知识库实体关系<span class="math inline">\(r_2\)</span>的对应关系是<strong>多对多</strong>的，比如<em>“was also born in”</em>可能对应<em>PlaceOfBirth</em>，也可能对应<em>DateOfBrith</em>，我们需要对每一个<span class="math inline">\(r_1\)</span>进行区分，我们可以通过知识库查询到每一个实体的<strong>类型（type），</strong>比如<em>1961-08</em>的类型是<em>date</em>而<em>honolulu</em>的类型是<em>place</em>，我们对<span class="math inline">\(r_1\)</span>两边的实体类型进行查询可以得到主语实体的类型<span class="math inline">\(t_1\)</span>和宾语实体的类型<span class="math inline">\(t_2\)</span>，因此<span class="math inline">\(r_1\)</span>可以进一步表示为<span class="math inline">\(r[t_1,t_2]\)</span>，我们对其所在三元组两边的实体进行统计，得到实体对集合<span class="math inline">\(F(r[t_1,t_2])\)</span>。</p>
<p>同样的，通过对知识库进行统计，对每一个知识库三元组中的实体关系<span class="math inline">\(r_2\)</span>也统计其两边的实体，可以得到实体对集合<span class="math inline">\(F(r_2)\)</span>，通过比较集合<span class="math inline">\(F(r[t_1,t_2])\)</span>和集合<span class="math inline">\(F(r_2)\)</span>类似Jaccard距离（集合交集元素数目比集合并集元素个数）这样的特征来确定是否建立词汇映射，如下图所示</p>
<figure>
<img src="https://pic3.zhimg.com/v2-fffcd8fa43219bfe3aaa6fc19b384c72_r.jpg" alt="img" /><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>图中绿色字体为<span class="math inline">\(r_1\)</span>，蓝色字体为<span class="math inline">\(r_2\)</span>。作者定义了词汇映射操作的三种特征（用于训练分类器），对齐特征（Alignment features），文本相似特征（Text similarity features），和词汇化特征（Lexicalized features），具体内容如下表<img src="https://pic2.zhimg.com/v2-663915191bcb3eb1e1717a2797ac27e1_r.jpg" alt="img" /></p>
<p>其中文本相似度特征中的<span class="math inline">\(s_2\)</span>指<span class="math inline">\(r_2\)</span>的freebase name。</p>
<p>在实际使用中，我们可以通过词性标注（POS）和命名实体识别（NER）来确定哪些短语和单词需要被词汇映射（Lexicon），从而忽略对一些skipped words进行词汇映射。并且，作者还建立了18种手工规则，对问题词（<em>question words</em>）进行逻辑形式的直接映射，如“<em>where，how many”</em>映射为<em>Type.Location</em> 和 <em>Count。</em></p></li>
</ul></li>
</ul>
<h2 id="桥接操作bridging">5. 桥接操作(Bridging)</h2>
<ul>
<li><p>完成词汇表的构建后，仍然存在一些问题。比如，对于go, have, do 这样的轻动词(light verb)，难以直接映射到一个知识库实体关系上。其次，有些知识库实体关系极少出现，不容易通过统计的方式找到映射方式，还有一些词比如actress，实际上是两个知识库实体关系进行组合操作后的结果(<span class="math inline">\(actor\cap gender.female\)</span>)（作者最后提到这个问题有希望通过在知识库上进行随机游走Random walk或者使用马尔科夫逻辑Markov logic解决），因此我们需要找到一个额外的二元关系将当前的逻辑形式连接起来，就是桥接</p>
<p>例：<em>“Which college did Obama go to?”</em></p>
<p>假设“<em>Obama</em>” 和 “<em>college</em>” 可被词汇映射映射为 <em>BarackObama</em> 和 <em>Type.University</em>, 这里"go to" 却难以找到一个映射，事实上，这里我们需要去寻找一个中间二元关系<span class="math inline">\(b\)</span>(即<em>Education</em>)使得上面的句子可以被解析为<span class="math inline">\((Type.University\cap Education.BarackObama)\)</span>，如下图所示<img src="https://pic4.zhimg.com/v2-1db39b61fccb5447df696d4b6aab982b_r.jpg" alt="img" />具体来说，给定两个类型（tpye）分别是<span class="math inline">\(t_1\)</span>和<span class="math inline">\(t_2\)</span>的一元逻辑形式<span class="math inline">\(z_1\)</span>和<span class="math inline">\(z_2\)</span>，我们需要找到一个二元逻辑形式<span class="math inline">\(b\)</span>，在<span class="math inline">\(b\)</span>对应的实体对类型满足<span class="math inline">\((t_1,t_2)\)</span>的条件下生成逻辑形式<span class="math inline">\((z_1\cap b,z_2)\)</span>，<strong>这就是桥接</strong>，由于这里有类型限制，所以我们可以在知识库中相邻的逻辑关系中暴力搜索符合条件的二元关系<span class="math inline">\(b\)</span>。</p>
<p>（注：在论文中还提到了另外两种需要进行桥接的场景，但不再详细写）</p>
<p>同样的，作者也为桥接操作定义了相应的特征（为了分类器训练），定义如下表所示<img src="https://pic2.zhimg.com/v2-951fe5ee41549505d281310e904ae0cd_r.jpg" alt="img" /></p>
<p>对于构建(composition)的其他三种操作：连接Join，求交集Intersection和聚合Aggregate，作者也定义了相应的特征（为了分类器的训练），如下表<img src="https://pic2.zhimg.com/v2-150278f7206e060eef59e7be580e5c15_r.jpg" alt="img" /></p></li>
</ul>
<h2 id="存在问题">6. 存在问题</h2>
<ul>
<li>词汇映射是整个算法有效（work）的基点，然而这里采用的词汇映射（尤其是关系映射）是基于<strong>比较简单的统计方式，对数据有较大依赖性</strong>。最重要的是，这种方式<strong>无法完成自然语言短语到复杂知识库关系组合的映射</strong>（如<em>actress</em> 映射为<span class="math inline">\(actor\cap gender.female\)</span>）。</li>
<li>在答案获取的过程中，通过远程监督学习训练分类器对语义树进行评分，注意，这里的语义树实际的组合方式是很多的，要训练这样一个强大的语义解析分类器，需要大量的训练数据。但无论是Free917还是WebQuestion，这两个数据集的问题-答案对都比较少。</li>
</ul>

      
    </div>

    
	
	

	
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/03/01/%E7%AC%AC05%E5%91%A8/2.%20%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96-Information%20Extraction%20over%20Structured%20Data_Question%20Answering%20with%20Freebase/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Olivia">
      <meta itemprop="description" content="May All Your Troubles Be little Ones">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Olivia的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/03/01/%E7%AC%AC05%E5%91%A8/2.%20%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96-Information%20Extraction%20over%20Structured%20Data_Question%20Answering%20with%20Freebase/" class="post-title-link" itemprop="url">2. 信息抽取-Information Extraction over Structured Data_Question Answering with Freebase</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-03-01 00:00:00" itemprop="dateCreated datePublished" datetime="2021-03-01T00:00:00+08:00">2021-03-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-04 15:15:42" itemprop="dateModified" datetime="2021-05-04T15:15:42+08:00">2021-05-04</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/" itemprop="url" rel="index"><span itemprop="name">Knowledge Base Qestion Answering</span></a>
                </span>
                  >
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/paper-comprehension/" itemprop="url" rel="index"><span itemprop="name">paper comprehension</span></a>
                </span>
                  >
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/paper-comprehension/basis/" itemprop="url" rel="index"><span itemprop="name">basis</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>3.1k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>3 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ul>
<li>论文原文：http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.650.469&amp;rep=rep1&amp;type=pdf</li>
</ul>
<h2 id="简介">1. 简介</h2>
<ul>
<li>本论文中的方法通过提取问题中的实体，通过在知识库中查询该实体可以得到以该实体节点为中心的知识库子图，子图中的每一个节点或边都可以作为候选答案。通过观察问题，依据某些规则或模版进行信息抽取，得到表征问题和候选答案特征的特征向量，建立分类器，通过输入特征向量对候选答案进行筛选，从而得出最终答案。</li>
<li>导入
<ul>
<li>如何回答问题？
<ul>
<li>问题： <em>“what is the name of Justin Bieber brother?”</em></li>
<li>主题词(topic)是<em>Justin Bieber</em>，因此我们会去知识库中搜索<em>Justin Bieber</em>这个实体，寻找与该实体相关的知识(此时相当于我们确定了答案的范围，得到了一些候选答案)。接下来我们去寻找和实体关系 brother相关的实体(事实上freebase里没有brother这个实体关系，而是sibling，我们需要进行一个简单的推理），最后得到答案。)</li>
</ul></li>
<li>如何确定候选答案
<ul>
<li>根据主题词，结合知识库，确定候选答案。如果我们把知识库中的实体看作是图节点，把实体关系看作是边，那么知识库就是一个庞大的图，通过主题词对应图节点的相邻几跳(hop)范围内的节点和边抽取出来得到一个知识库的子图，这个子图本文称为<strong>主题图(Topic graph)</strong>，一般来说，这里的跳数一般为一跳或两跳，即与主题词对应的图节点在一条或两条边之内的距离。主题图中的节点，即是<strong>候选答案</strong>。接下来，需要继续观察问题，对问题进行信息抽取，获取能帮助我们在候选答案中筛选出正确答案的信息。</li>
</ul></li>
<li>如何对问题进行信息抽取
<ul>
<li>结合人的理解，先对句子结构进行分析，下图是<em>"what is the name of Justin Bieber brother"</em>语句的语法依存树(Dependency tree)。 <img src="https://i.loli.net/2021/03/02/xRJiksfuWL7zNd4.jpg" alt="0D3EEADC-95E5-4EB4-9061-1213A4E0B287.jpeg" /></li>
<li>首先通过依存关系nsubj(what,name)和prep_of(name, brother)这两条信息知道答案是一个名字，并且这个名字和brother有关，当然我们此时还不能判断是否是人名。进一步，通过nn(brother, Justin Bieber)这条信息我们可以根据Justin Bieber 是个人，推导出他的brother也是个人，综合前面的信息，可以推理出我们最终的答案应该是个人命。(注：nsubj代表名词性主语，prep_of代表of介词修饰，nn 代表名词组合)，当确定了最终答案是个人名，就很容易在候选答案中筛选出正确答案了。</li>
<li>本质上是对问题进行<strong>信息抽取</strong></li>
</ul></li>
</ul></li>
</ul>
<h2 id="论文中的处理">2. 论文中的处理</h2>
<h3 id="信息抽取">3.1 信息抽取</h3>
<ul>
<li>首先提取的第一个信息就是<strong>问题词</strong>(question word, 记作<strong><em>qword</em></strong>)，例如 who, when, what, where, how, which, why, whom, whose，它是问题的一个明显特征 。</li>
<li>第二个关键信息，就是<strong>问题焦点</strong>(question focus, 记作<strong><em>qfocus</em></strong>)这个词暗示了答案的类型，比如name/time/place，我们直接将问题词<strong><em>qword</em></strong>相关的那个名词抽取出来作为<strong><em>qfocus</em></strong>，在这个例子中，what name中的name就是<strong><em>qfocus</em></strong></li>
<li>第三个需要的信息，就是这个问题的主题词(word topic，记作<strong><em>qtopic</em></strong>)，在这个句子里Justin Bieber就是<strong><em>qtopic</em></strong>，这个词能够帮助我们找到freebase中相关的知识，<strong>我们可以通过命名实体识别（Named Entity Recognition，NER）来确定主题词</strong>，需要注意的是，一个问题中可能存在多个主题词。</li>
<li>最后需要提取的特征是问题的中心动词(question verb，记作<strong><em>qverb</em></strong>)，词能够给我们提供很多和答案相关的信息，比如play，那么答案有可能是某种球类或者乐器。<strong>我们可以通过词性标注（Part-of-Speech，POS）确定qverb。</strong></li>
<li>总结：通过对问题提取 <strong>问题词<em>qword</em></strong>，<strong>问题焦点<em>qfocus</em></strong>，<strong>问题主题词<em>qtopic</em></strong>和<strong>问题中心动词<em>qverb</em></strong>这四个问题特征，我们可以将该问题的依存树转化为<strong>问题图（Question Graph）</strong>，如下图所示 <img src="https://i.loli.net/2021/03/02/mZt6IX4HYFWkLne.png" alt="0239E2A3-F15A-48E3-ABD1-19B907664289.png" /></li>
<li>总结来说，将依存树转化为问题图进行了三个操作：
<ol type="1">
<li>将问题词qword，问题焦点qfocus，问题主题词qtopic和问题中心动词qverb加入相对应的节点中，如what -&gt; qword=what。</li>
<li>如果该节点是命名实体，那就把该节点变为命名实体形式，如justin -&gt; qtopic=person （justin对应的命名实体形式是person）。这一步的目的是因为数据中涉及到的命名实体名字太多了，这里我们只需要区分它是人名 地名 还是其他类型的名字即可。</li>
<li>删除掉一些不重要的叶子节点，如限定词（determiner，如a/the/some/this/each等），介词（preposition）和标点符号（punctuation）。</li>
<li><strong>从依存树到问题图的转换，实质上就是对问题进行信息抽取，提取出有利于寻找答案的问题特征，删减掉不重要的信息</strong></li>
</ol></li>
</ul>
<h3 id="构建特征向量对候选答案进行分类">3.2 构建特征向量对候选答案进行分类</h3>
<ul>
<li>在候选答案中找出正确答案，实际上是一个<strong>二分类问题</strong>（判断每个候选答案是否是正确答案），我们使用训练数据问题-答案对，训练一个分类器来找到正确答案。分类器的输入特征向量中的每一维，对应一个问题-候选答案特征。每一个问题-候选答案特征由问题特征中的一个特征，和候选答案特征的一个特征，<strong>组合（combine）而成</strong>。
<ul>
<li><strong>问题特征</strong>：我们从问题图中的每一条边e(s,t)，抽取4种问题特征：s，t，s|t，和s|e|t。如对于边prep_of(qfocus=name，brother)，我们可以抽取这样四个特征：qfocus=name，brother，qfocus=name|brother 和 qfoc us=name|prep_of|brother。</li>
<li><strong>候选答案特征</strong>：对于主题图中的每一个节点，我们都可以抽取出以下特征：该节点的所有<strong>关系</strong>（relation，记作rel），和该节点的所有<strong>属性</strong>（property，如type/gender/age）。对于Justin Bieber 这个topic我们可以在知识库找到它对应的主题图，如下图所示：
<ul>
<li><img src="https://i.loli.net/2021/03/02/GvSs1l4iO2gTeJR.png" title="fig:" alt="9DCE247B-50AA-47E6-AD93-A43A320D4071.png" /></li>
<li>(注：图中虚线表示属性，实线表示关系，虚线框即属性值，实现框为topic node。在知识库中，如果同一个topic节点的同一个关系对应了多个实体，如Justin Bieber的preon.sibing_s关系可能对应多个实体，那freebase中会设置一个<em>虚拟的dummy node</em>，来连接所有相关的实体）</li>
<li>例如，对于Jaxon Bieber这个topic节点，我们可以提取出这些特征：gender=male，type=person，rel=sibling 。可以看出关系和属性都刻画了这个候选答案的特征，对判断它是否是正确答案有很大的帮助。</li>
</ul></li>
<li><strong>问题-候选答案特征</strong>：每一个问题-候选答案特征由问题特征中的一个特征和候选答案特征中的一个特征，组合（combine）而成（组合记作 | ）。我们希望一个<strong>关联度较高</strong>的问题-候选答案特征有较高的权重，比如对于问题-候选答案特征 qfocus=money|node type=currency（注意，这里qfocus=money是来自问题的特征，而node type=currency则是来自候选答案的特征），我们希望它的权重较高，而对于问题-候选答案特征qfocus=money|node type=person我们希望它的权重较低。</li>
</ul></li>
</ul>

      
    </div>

    
	
	

	
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/03/01/%E7%AC%AC05%E5%91%A8/3.%20%E5%90%91%E9%87%8F%E5%BB%BA%E6%A8%A1-Question%20Answering%20with%20Subgraph%20Embeddings/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Olivia">
      <meta itemprop="description" content="May All Your Troubles Be little Ones">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Olivia的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/03/01/%E7%AC%AC05%E5%91%A8/3.%20%E5%90%91%E9%87%8F%E5%BB%BA%E6%A8%A1-Question%20Answering%20with%20Subgraph%20Embeddings/" class="post-title-link" itemprop="url">3. 向量建模-Question Answering with Subgraph Embeddings</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-03-01 00:00:00" itemprop="dateCreated datePublished" datetime="2021-03-01T00:00:00+08:00">2021-03-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-04 15:15:49" itemprop="dateModified" datetime="2021-05-04T15:15:49+08:00">2021-05-04</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/" itemprop="url" rel="index"><span itemprop="name">Knowledge Base Qestion Answering</span></a>
                </span>
                  >
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/paper-comprehension/" itemprop="url" rel="index"><span itemprop="name">paper comprehension</span></a>
                </span>
                  >
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/paper-comprehension/basis/" itemprop="url" rel="index"><span itemprop="name">basis</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>2.2k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>2 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ul>
<li>论文原文：https://arxiv.org/abs/1406.3676</li>
</ul>
<h2 id="向量建模核心思想">1. 向量建模核心思想</h2>
<ul>
<li>首先根据问题中的主题词在知识库中确定候选答案。把问题和候选答案都映射到一个低维空间，得到它们的<strong>分布式表达</strong>(Distributed Embedding)，通过训练数据对该分布式表达进行训练，使得问题向量和它对应的正确答案在低维空间的关联得分(通常以点乘为形式)尽量高。当模型训练完成后，则可根据候选答案的向量表达和问题表达的得分进行筛选，找出得分最高的作为最终答案。</li>
<li>需解决两个问题：
<ul>
<li>如何将问题和答案映射到低维空间。不能仅仅将自然语言的问题和答案进行映射，还要将知识库里的知识也映射到这个低维空间</li>
<li>这种方法需要<strong>大量数据</strong>去训练，而 KB-QA中的benchmark数据集WebQuestion只含有5800多个问题答案对，这样的数据是难以训练好这种表达的。</li>
</ul></li>
</ul>
<h2 id="如何用分布式表达表示答案和问题">2. 如何用分布式表达表示答案和问题</h2>
<ul>
<li><strong>问题的分布式表达</strong>：
<ul>
<li>首先把自然语言问题进行向量化，作者将输入空间的<strong>维度N设置为字典大小+知识库实体数目+知识库实体关系数目</strong>，<strong>对于输入向量每一维的值设置为该维所代表的单词</strong>(当然这一维也可能代表的是某个实体数目或实体关系，对于问题的向量化，这些维数都设置为 0)<strong>在问题中的出现次数</strong>(一般为 0 或 1 次)，可以看出这是一种multi-hot的稀疏表达，是一种简化版的词袋模型(Bag-of-words model)</li>
<li>我们用q代表问题，用<span class="math inline">\(\phi (q)\)</span>代表N维的问题向量，用矩阵<span class="math inline">\(W\)</span>将N维的问题向量映射到<span class="math inline">\(k\)</span>维的低维空间，那么问题的分布式表达即<span class="math inline">\(f(q)=W\phi (q)\)</span></li>
</ul></li>
<li><strong>答案的分布式表达</strong>
<ul>
<li>最简单的方式就是像对问题一样的向量化方式，使用一个简化版的词袋模型。由于答案都是一个知识库实体，那么这种表达就是一个 one-hot 的表达，显然，并没有把知识库的知识引入到我们的输入空间中。</li>
<li>第二种方式，我们把知识库想象成一个图，图的节点代表实体，边代表实体关系。通过问题中的主题词可以定位到图中的一个节点，该节点到答案节点有一条路径，我们把该路径上的所有边（实体关系）和点（实体）都以multi-hot的形式存下来作为答案的输入向量。我们这里只考虑一跳（hop）或者两跳的路径，如路径(barack obama, place of birth, honolulu)是一跳，路径(barack obama, people.person.place of birth, location.location.containedby, hawaii) 是两跳。因此这种表示是一种3-hot或4-hot的表示。</li>
<li>第三种方式
<ul>
<li>在信息抽取篇介绍的信息抽取办法中，对于每一个候选答案，该答案所对应的属性（type/gender等）和关系都是能够帮助我们判断它是否是正确答案的重要信息，因此我们可以把每个候选答案对应的知识库子图（1跳或2跳范围）也加入到输入向量中，假设该子图包含C个实体和D个关系，那么我们最终的表达是一种3+C+D-hot或者4+C+D-hot的表达。和信息抽取方法一样，我们也对关系的方向进行区分，因此我们**输入向量的大小变为字典的大小+2*(知识库实体数目+知识库实体关系数目)。**</li>
<li>同样的，我们用<span class="math inline">\(a\)</span>表示答案，用<span class="math inline">\(\psi (a)\)</span>表示答案的输入向量，用矩阵<span class="math inline">\(W\)</span>将答案向量映射到<span class="math inline">\(k\)</span>维的低维空间，答案的分布式表达即<span class="math inline">\(g(a)=W\psi (a)\)</span>。</li>
</ul></li>
</ul></li>
</ul>
<h2 id="向量得分">3. 向量得分</h2>
<ul>
<li>最后我们用一个函数表征答案和问题的得分，我们希望问题和它对应的正确答案得尽量高分，通过比较每个候选答案的得分，选出最高的作为正确答案。得分函数定义为二者分布式表达的点乘，即<span class="math inline">\(s(q, a)=f(q)^T\cdot g(a)\)</span>。</li>
<li>上述整个流程如下图所示 <img src="https://ftp.bmp.ovh/imgs/2021/03/363065f4b4f71aeb.png" /></li>
</ul>
<h2 id="如何训练分布式表达">4. 如何训练分布式表达</h2>
<ul>
<li>对于训练数据集<span class="math inline">\(D=\lbrace (q_i,a_i),\ ....\rbrace\)</span>，我们定义 margin-based ranking 损失函数，公示如下 <img src="https://ftp.bmp.ovh/imgs/2021/03/2321063525beadd5.png" /> 其中<span class="math inline">\(\bar a\)</span>表示负样本集<span class="math inline">\(\bar A\)</span>中的一个负样本(错误答案)，m 是一个值为 0.1 的 margin。最小化这个损失函数，意味着我们希望正确答案和问题的得分要比任意错误答案的得分高出一个 margin</li>
</ul>
<h2 id="总结">5. 总结</h2>
<ul>
<li>可以看出，相比信息抽取和语义解析的方法，该方法几乎不需要任何手工定义的特征（hand- crafted features），也不需要借助额外的系统（词汇映射表，词性标注，依存树等）。相对来说，比较简单，也较容易实现，能取得39.2的F1-scor e得分（斯坦福13年的语义解析方法只有35.7）也说明了该方法的强大性。通过自动化的方式扩展数据集和多任务训练也部分解决了实验数据不足的缺点。</li>
<li>然而，向量建模方法，是一种趋于黑盒的方法，缺少了解释性（语义解析可以将问题转化成一种逻辑形式的表达，而信息抽取构造的每一维特征的含义也是离散可见的），更重要的是，它也缺少了我们的<strong>先验知识</strong>和<strong>推理</strong>（可以看出其F1-score略低于14年使用了大量先验知识的信息抽取方法，该方法F1-score为42.0），事实上，这也是现在深度学习一个比较有争议的诟病。</li>
<li>就篇论文的向量建模方法来说，也存在一些问题，比如对问题的向量表示采用了类似词袋模型的方法，这样相当于并未考虑问题的语言顺序（比如 “谢霆锋的爸爸是谁？” 谢霆锋是谁的爸爸？ 这两个问题用该方法得到的表达是一样的，然而这两个问题的意思显然是不同的），且训练分布式表达的模型很简单，相当于一个两层的感知机。</li>
</ul>

      
    </div>

    
	
	

	
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/03/01/%E7%AC%AC05%E5%91%A8/4.%20Multi-Column%E5%90%91%E9%87%8F%E5%BB%BA%E6%A8%A1-Question%20Answering%20over%20Freebase%20with%20Multi-Column%20Convolutional%20Neural%20Networks/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Olivia">
      <meta itemprop="description" content="May All Your Troubles Be little Ones">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Olivia的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/03/01/%E7%AC%AC05%E5%91%A8/4.%20Multi-Column%E5%90%91%E9%87%8F%E5%BB%BA%E6%A8%A1-Question%20Answering%20over%20Freebase%20with%20Multi-Column%20Convolutional%20Neural%20Networks/" class="post-title-link" itemprop="url">4. Multi-Column向量建模-Question Answering over Freebase with Multi-Column Convolutional Neural Networks</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-03-01 00:00:00" itemprop="dateCreated datePublished" datetime="2021-03-01T00:00:00+08:00">2021-03-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-04 15:15:54" itemprop="dateModified" datetime="2021-05-04T15:15:54+08:00">2021-05-04</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/" itemprop="url" rel="index"><span itemprop="name">Knowledge Base Qestion Answering</span></a>
                </span>
                  >
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/paper-comprehension/" itemprop="url" rel="index"><span itemprop="name">paper comprehension</span></a>
                </span>
                  >
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/paper-comprehension/basis/" itemprop="url" rel="index"><span itemprop="name">basis</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>3.3k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>3 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ul>
<li>论文原文：https://www.aclweb.org/anthology/P15-1026.pdf</li>
</ul>
<h2 id="简介">1. 简介</h2>
<ul>
<li>本文章采用卷积神经网络的一种变体（作者称为multi-column）从三个方面<strong>（答案路径Answer Path，答案上下文信息Answer Context，答案的类型Answer Type）</strong>对问题和答案的分布式进行学习，使得该分布式表达相比之前的向量建模方法包含更多有效的特征。</li>
<li>在传统向量建模方法中存在一些问题
<ul>
<li>第一个是存在于<strong>问题的向量化</strong>。
<ul>
<li>传统向量建模方法采用了类似词袋模型的方式，相当于它并未考虑问题的语言顺序（比如 “<em>谢霆锋的爸爸是谁？” “谢霆锋是谁的爸爸？”</em> 这两个问题用该方法得到的表达是一样的，然而这两个问题的意思显然是不同的）。</li>
<li>对于这个缺陷，我们可以使用深度学习的模型对问题进行向量化，比如使用循环神经网络（Recurrent Nerual Networks, RNNs）、卷积神经网络（Counvoulutional Nerual Networks, CNNs ）等模型提取问题特征，<strong>这样的方式考虑了语言的顺序，并且提取特征的能力也更加强大。</strong></li>
</ul></li>
<li>第二个问题存在于<strong>答案向量化</strong>。
<ul>
<li><p>在对答案进行向量化的时候，直接将答案的路径（问题主题词到答案实体的路径）和上下文信息（答案实体周围的知识库子图）一起作为答案特征，通过multi-hot的方式对答案进行向量化。事实上，这样的形式不利于模型区分答案的特征（仅仅根据答案的multi-hot向量是不好区分哪些是答案的类型，哪些来自答案的上下文，哪些来自问题主题词到答案实体的路径）。</p></li>
<li><p>因此我们可以将问题的特征表示拆解开，用三个向量分别表示答案的三个特征，即<strong>（答案路径Answer Path，答案上下文信息Answer Context，答案的类型Answer Type）</strong>，对于每一个答案特征向量，都用一个<strong>卷积网络</strong>去对<strong>问题</strong>进行特征提取，<strong>将提取出的分布式表达和该答案对应特征向量的分布式表达进行点乘</strong>，这样我们就可以得到一个包含三部分的得分函数：<img src="https://pic3.zhimg.com/80/v2-945c8248709343cac7b3b25730c6efda_720w.png" alt="img" /></p>
<p>其中<span class="math inline">\(q\)</span>代表问题，<span class="math inline">\(a\)</span>代表答案，<span class="math inline">\(f_i(q)\)</span>代表问题经过卷积神经网络输出的分布式表达，<span class="math inline">\(g_i(a)\)</span>表示答案在对应特征下的分布式表达。</p>
<p>有了得分函数，我们就可以像向量建模方法一样，通过定义margin-based ranking损失函数对模型参数进行训练。</p></li>
</ul></li>
</ul></li>
</ul>
<h2 id="multi-column卷积神经网络">2. Multi-Column卷积神经网络</h2>
<ul>
<li><p>对于问题的特征提取，作者使用Multi-Column卷积神经网络，其结构实质上是共享<a href="https://link.zhihu.com/?target=http%3A//papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf">word-embedding</a>层的三个<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1408.5882">text-CNNs</a>，text-CNNs模型在文本分类问题上取得了很好的效果。</p>
<ul>
<li><p>text-CNNs</p>
<ul>
<li><p><strong>词向量（Word-embedding）</strong>：对于问题序列<span class="math inline">\(q=w_1...w_n\)</span>，对于其中的每一个单词<span class="math inline">\(w_i\)</span>它对应的one-hot形式<span class="math inline">\(u(w_i)\)</span>，我们可以通过word-embedding矩阵<span class="math inline">\(W_v\)</span>转化为一个<span class="math inline">\(d\)</span>维的分布式向量（这里的word-embedding矩阵是通过word2vec等pre-train方式初始化的），即<span class="math inline">\(w_i=W_vu(w_i)\)</span></p></li>
<li><p><strong>卷积操作（Convolution）</strong>：对于一个含<span class="math inline">\(n\)</span>个单词的问题<span class="math inline">\(q\)</span>，我们可以得到一个<span class="math inline">\(n×d\)</span>的矩阵。如果将这个矩阵想象成是一个图片，那么就可以对该图片进行卷积操作了。与图片卷积操作的不同之处在于，每一个卷积核的大小（即卷积窗口）是<span class="math inline">\(m×d\)</span>，表示每次对<span class="math inline">\(m\)</span>个单词的embedding进行卷积操作。</p></li>
<li><p><strong>池化操作（Pooling）</strong>：对于每一个卷积核的输出（假设卷积核大小为<span class="math inline">\(m\)</span>，在<span class="math inline">\(n×d\)</span>的矩阵上进行卷积，那么输出是一个<span class="math inline">\(n-m+1\)</span>维的向量），通过对该向量进行max-pooling操作（即取最大值）可以得到一个标量，该标量将作为问题最终表达<span class="math inline">\(f_q\)</span>的某一维度（可以理解成一个卷积核负责对整个问题提取一个一维的特征）。因此通过控制卷积核的数目我们可以控制最终输出的维度，即<span class="math inline">\(k\)</span>个卷积核可以输出一个<span class="math inline">\(k\)</span>维的最终表达（注意这里卷积核大小可以不同，一般设置为2，3，4）。流程可如下图，对于不同长度问题，会通过补零（padding）操作将所有问题的长度限定到固定长度<img src="https://pic1.zhimg.com/80/v2-ae615339713f0320104103cd3619bdf0_720w.png" alt="img" /></p>
<p>这样我们通过三个text-CNNs，在共享word-embedding的情况下，就可以得到<span class="math inline">\(f_1(q)\)</span>,<span class="math inline">\(f_2(q)\)</span>和<span class="math inline">\(f_3(q)\)</span>。（事实上，在这篇文章中所使用的卷积操作，对于每一个column只采用了一个卷积核，一个卷积核对一个卷积窗口的卷积结果并非一个值而是一个向量，max-pooling作用在每一个卷积窗口的卷积结果上，具体方式可以参看后面的图。个人认为这样的卷积方式减少了参数，显得特征提取更加粗粒度，效果很可能不如text-CNNs）</p></li>
</ul></li>
</ul></li>
<li><p>用三个向量来分别表示答案的三种特征。</p>
<ul>
<li><p><strong>答案路径（Answer Path）</strong>：从问题中的主题词到答案在知识库中形成的一条路径，我们记录该路径上的每一个实体关系，可以通过multi-hot的形式<span class="math inline">\(u_p(a)\)</span>来进行表示，答案路径的分布式表达<span class="math inline">\(g_1(a)\)</span>可以表示为<span class="math inline">\(g_1(a)=\frac 1 {\begin{Vmatrix}u_p(a)\end{Vmatrix}}_1W_pu_p(a)\)</span>，这里由于路径的长度不确定，所以使用一范式来做一个归一化normalization。</p></li>
<li><p><strong>答案上下文信息（Answer Context）</strong>：我们将答案实体对应1跳（hop）范围内的实体关系和实体作为答案实体的上下文信息。通过同样的方式我们得到答案上下文信息的分布式表达<span class="math inline">\(g_2(a)=\frac 1 {\begin{Vmatrix}u_c(a)\end{Vmatrix}}_1W_cu_c(a)\)</span></p></li>
<li><p><strong>答案类型（Answer Type）</strong>：答案类型是一个很重要的特征。类型是一个特殊的实体关系。在实际操作中，可以在freebase里通过实体关系<em>common.topic.notable.types</em> 来查询实体对应的所有类型。通过同样的方式，我们可以得到相应的分布式表达<span class="math inline">\(g_3(a)=\frac 1 {\begin{Vmatrix}u_t(a)\end{Vmatrix}}_1W_tu_t(a)\)</span>，注意如果候选答案是一个值，那么就用该值的类型（string/float/datetime）作为答案的类型，比如答案是2009-12-17，那么类型就是string。</p></li>
<li><p>至此，我们得到了包含三部分的得分函数：<img src="https://pic3.zhimg.com/80/v2-945c8248709343cac7b3b25730c6efda_720w.png" alt="img" /></p>
<p>整个流程如下图：<img src="https://pic3.zhimg.com/80/v2-b4bf6fa8346f2ccfd67da64d6c90a1f6_720w.png" alt="img" /></p>
<p>（图中方块带红色斜线的为主题词，红色箭头表示路径，绿色椭圆表示答案类型，蓝色虚线椭圆表示上下文信息范围）</p>
<p>对于问题<em>“when</em> <em>did Avatar release in UK”</em>和它的答案<em>2009-12-17，</em>我们通过multi-column卷积神经网络提取三种问题的分布式表达，再通过答案的路径、上下文信息和类型得到答案相应的三种分布式表达，通过分别点乘再求和的方式得到最终的答案-问题对得分。</p>
<p>可通过向量建模中提到的同样的方式构造损失函数和多任务学习来训练模型参数。</p></li>
</ul></li>
</ul>
<h2 id="存在问题">3. 存在问题</h2>
<ul>
<li><strong>候选答案生成</strong>：有些问题的主题词是难以正确提取出来的，比如缩写词和表达不全，如问题“where did jfk and his wife live<em>”</em> ，很难将jfk这个缩写词对应到<em>John F. Kennedy</em>这个人名上，这样会导致我们无法得到正确的候选答案集合。要解决这种情况，可能需要对问题进行一些预处理。</li>
<li><strong>问题歧义：</strong>对于数据集中有些有歧义的问题，难以获得和正确答案相应的关系，如问题<em>“who is aidan quinn”</em>，答案是演员，我们很难通过该问题<em>who is</em>推断出和职业相关。这种情况该怎么办呢？</li>
<li><strong>时序敏感（Time-Aware）问题：</strong>对于问题中带有 first / second 这种与时间顺序相关的词语，如<em>“who is johnny cash’s <strong>first</strong> wife”</em> ，答案可能给出的是second wife的名字（模型只关注到了wife而忽略了first的含义，并没有进行额外的推理）。对于这种情况，可能需要定义专门（ad-hoc）的操作，注意的是，这一点是该类方法相比<strong>语义解析</strong>方法的一个缺点。</li>
</ul>

      
    </div>

    
	
	

	
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/03/01/%E7%AC%AC05%E5%91%A8/5.%20%E6%9F%A5%E8%AF%A2%E5%9B%BE-%E8%AF%AD%E4%B9%89%E8%A7%A3%E6%9E%90-Semantic%20Parsing%20via%20Staged%20Query%20Graph%20Generation_Question%20Answering%20with%20Knowledge%20Base/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Olivia">
      <meta itemprop="description" content="May All Your Troubles Be little Ones">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Olivia的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/03/01/%E7%AC%AC05%E5%91%A8/5.%20%E6%9F%A5%E8%AF%A2%E5%9B%BE-%E8%AF%AD%E4%B9%89%E8%A7%A3%E6%9E%90-Semantic%20Parsing%20via%20Staged%20Query%20Graph%20Generation_Question%20Answering%20with%20Knowledge%20Base/" class="post-title-link" itemprop="url">5. 查询图-语义解析-Semantic Parsing via Staged Query Graph Generation_Question Answering with Knowledge Base</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-03-01 00:00:00" itemprop="dateCreated datePublished" datetime="2021-03-01T00:00:00+08:00">2021-03-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-04 15:15:59" itemprop="dateModified" datetime="2021-05-04T15:15:59+08:00">2021-05-04</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/" itemprop="url" rel="index"><span itemprop="name">Knowledge Base Qestion Answering</span></a>
                </span>
                  >
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/paper-comprehension/" itemprop="url" rel="index"><span itemprop="name">paper comprehension</span></a>
                </span>
                  >
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/paper-comprehension/basis/" itemprop="url" rel="index"><span itemprop="name">basis</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>5k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>5 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ul>
<li>论文原文：https://www.microsoft.com/en-us/research/publication/semantic-parsing-via-staged-query-graph-generation-question-answering-with-knowledge-base/</li>
</ul>
<h2 id="简介">1. 简介</h2>
<ul>
<li>思想是把自然语言问题转化为逻辑形式，通过逻辑形式转化为查询语句，在知识库中查询得出最终答案。在进行语义解析生成逻辑形式的过程中，主要是在提取自然语言问题中的信息和利用训练好的语法解析器进行解析，<strong>这一过程几乎没有使用到知识库里的信息</strong>。而在向量建模和信息抽取方法中，我们不仅对问题进行了特征提取，还借助知识库确定了候选答案范围（相比语义解析中的词汇映射要在大范围的知识库实体关系中寻找映射，这样的方式使得搜索范围大大减小），并将候选答案在知识库中的信息作为特征。相比之下，可以看出传统的语义解析和知识库本身的联系是<strong>不够紧密</strong>的（Decoupled from KB），也就是说，<strong>传统语义解析方法对知识库的利用还不够</strong>。</li>
<li>其中语义解析的第一步，词汇映射（Lexicon）。要将自然语言中的谓语关系映射到知识库中的实体关系仅仅通过<strong>统计方式</strong>进行映射，效果并不好。如果能考虑知识库中的信息，即可将词汇映射的范围缩小，使用深度学习的办法通过分布式表达来代替基于统计方法的词汇映射，可能会取得更好的效果。</li>
<li>于是为了更好的利用知识库中的知识，缩小语义解析树的搜索范围，并获得更多有益的信息，提出本文。</li>
</ul>
<h2 id="查询图">2. 查询图</h2>
<h3 id="定义和组成">2.1 定义和组成</h3>
<ul>
<li><p>对于问句*“**Who first voiced Meg on Family Guy?"* (谁是第一个为Family Guy里的MegGriffin角色配音的人，<em>注：Family Guy是美国的一部动画片，MegGriffin是其中的一个角色，有两个人先后为其配音过</em>)</p>
<p>对于深度学习的向量建模法来说，<em>first</em>这种时序敏感（Time-Aware）词常常会被模型忽略而给出错误答案。语义解析方法可以将first解析为逻辑形式的聚合函数（<em>arg min</em>），但它又难以将问题中的<em>Meg</em>这一缩写词通过词汇表映射为知识库中的<em>MegGriffin</em>。</p>
<p>为了更好的利用知识库，我们可以先去知识库里搜Family Guy，在它对应的知识库子图中搜索和Meg很接近的实体，也就是说我们一开始就借助知识库，帮我们缩小了范围，这样我们就很容易找到Meg其实对应的是MegGriffin。我们可以借助这样的思想来对我们的语义解析进行改进。<strong>用一种图的形式来代替语法解析树表示逻辑形式，这个图被称为查询图（query graph）</strong>。</p>
<p>问句<em>“Who first voiced Meg on Family Guy?"</em>对应的查询图如下图所示：<img src="https://pic4.zhimg.com/80/v2-8de621b2d2a7896042f05bbf06176a2b_720w.png" alt="img" /></p></li>
<li><p>查询图的组成</p>
<ul>
<li><strong>知识库实体</strong>：在图中用圆角矩形表示。</li>
<li><strong>中间变量</strong>：在图中用白底圆圈表示。</li>
<li><strong>聚合函数</strong>：用菱形表示。</li>
<li><strong>lambda变量（答案）</strong>：在图中用灰底圆圈表示。</li>
</ul>
<p>图中实体节点到答案变量的路径可以转化为一系列join操作，不同路径可以通过intersection操作结合到一起，因此，该查询图在不考虑聚合函数argmin的情况下可以转化为一个lambda表达式，即：<img src="https://www.zhihu.com/equation?tex=+%5Clambda+x.%5Cexists+y.cast%28FamilyGuy%2C+y%29++%5Cwedge++actor%28y%2Cx%29+%5Cwedge++character%28y%2CMegGriffin%29" alt="[公式]" /></p>
<p><em>（上式表示 我们要寻找x，使得在知识库中存在实体y，满足 1. y和FamilyGuy存在cast关系；2. y和x存在actor关系；3.y和MegGriffin存在character关系，这里我们可以把y想象成是一个中间变量，通过对它增加约束来缩小它的范围，通过它和答案x的关系来确定答案x）</em></p></li>
</ul>
<h3 id="查询图的阶段生成">2.2 查询图的阶段生成</h3>
<ul>
<li><p><strong>核心推导链（core inferential chain）</strong>：问题中的主题词（可以看作是一个根节点）到答案变量的这条路径（如Family Guy - y - x）包含了所有的中间变量，这条路径可以看作是从问题到答案的一个核心推导过程。而对于核心推导链里的中间变量，我们可以对它加一些<strong>约束</strong>（要求它与其他实体具有一定的关系，如 y - character -&gt; Meg Griifin）和<strong>聚合函数</strong>（如 y - from -&gt; arg min）。</p></li>
<li><p>故查询图生成可分为以下步骤：<strong>确定主题词</strong>，<strong>确定核心推导链</strong>，<strong>是否增加约束和聚合</strong>。可如下图这个有限状态机自动机表示：<img src="https://pic3.zhimg.com/80/v2-25d90924a565306502b7c4e964fa155a_720w.png" alt="img" /></p>
<p>其中状态集合<span class="math inline">\(S=\{\phi,S_e,S_p,S_c\}\)</span>分别表示空集、仅含主题词节点、含核心推导链、含约束节点。而动作集合<span class="math inline">\(A=\{A_e,A_p,A_a,A_c\}\)</span>分别表示选择主题词节点、选择核心推导链、加入聚合函数、加入约束。</p></li>
<li><p>查询图可以分阶段生成，这个生成的过程实质上是一个<strong>搜索</strong>。依照我们的有限状态自动机，根据图所处的状态<span class="math inline">\(s\)</span>，我们可以确定在该状态下可以采取的动作集合<span class="math inline">\(\Pi(s)\)</span>（比如当前我们处在状态<span class="math inline">\(\phi\)</span>，根据有限自动机我们的动作为选择主题词节点，假设检测出来问句有3个主题词候选，那么我们的动作集合大小为3）。因此，查询图生成过程实际上是一个搜索过程，如果对这个搜索不加任何限制，那么这个搜索是指数级复杂度的。因此对于每一个状态<span class="math inline">\(s\)</span>，我们可以用<strong>奖励函数</strong>（reward function）对它进行评估，奖励函数<span class="math inline">\(\gamma\)</span>得分越高表示这个状态对应的查询图和正确的语义解析表达越接近，我们用一个对数线性模型（log-linear）模型来学习奖励函数。有了奖励函数，我们用best-first的策略利用优先队列进行启发式搜索，算法流程如下：<img src="https://pic3.zhimg.com/80/v2-4414dfdb988c5c5b441103627927079e_720w.png" alt="img" /></p>
<p>其中<span class="math inline">\(T(s,a)\)</span>代表在<span class="math inline">\(s\)</span>状态下采取动作<span class="math inline">\(a\)</span>后得到的新状态，我们将优先队列的大小<span class="math inline">\(N\)</span>限制为1000。上述算法可以简单概括为：<strong>每次从队列中取出得分最高的状态分别执行动作集中的每一个动作生成一批新的状态并压入优先队列，始终记录得分最高的状态，最终将得分最高的状态作为最后的查询图。</strong></p></li>
</ul>
<h3 id="查询图生成举例">2.3 查询图生成举例</h3>
<h4 id="主题词链接linking-topic-entity">2.3.1 主题词链接（Linking Topic Entity）</h4>
<ul>
<li>从问题中确定主题词</li>
<li>作者使用了<a target="_blank" rel="noopener" href="https://yiyangnlp.github.io/downloads/yang-acl-2015-updated.pdf">S-MART</a>作为实体链接系统，该系统是针对带噪音的短文本设计的，适合用于对问句提取主题词，它会为相应的 实体-自然语言短语 链接对 给出<strong>链接得分</strong>（Linking Score）<img src="https://pic1.zhimg.com/v2-fc1cd35137a0e5c2f1cc377003530f18_r.jpg" alt="img" /></li>
</ul>
<h4 id="核心推导链">2.3.2 核心推导链</h4>
<ul>
<li><p>对于每一个候选的主题词，将它在知识库中对应的实体节点周围长度为1的路径（如下图<span class="math inline">\(s_5\)</span>和长度为2且包含<a target="_blank" rel="noopener" href="http://blog.maidou.info/?p=169">CVT</a>节点的路径（如下图<span class="math inline">\(s_3\)</span>和<span class="math inline">\(s_4\)</span>）作为核心推导链的候选（CVT，即复合值类型 Compound Value Types，是freebase中用于表示复杂数据而引入的概念）。如下图：<img src="https://pic3.zhimg.com/v2-8212ab7bac6ffe2544850f1aac6509a6_r.jpg" alt="img" /></p></li>
<li><p>核心推导链其实就是将自然语言问题映射为一个<strong>谓语序列</strong>（如cast-actor），因此可以用<strong>卷积神经网络</strong>来对映射进行打分，如图所示：<img src="https://pic2.zhimg.com/v2-d270f48ce95509ab63a76038b85ad8bd_r.jpg" alt="img" /></p></li>
<li><p>将自然语言和谓语序列分别作为输入，分别经过两个不同的卷积神经网络得到300维的分布式表达，利用表达向量之间的相似度距离（如cosine距离）计算自然语言和谓语序列的<strong>语义相似度得分</strong>。</p></li>
<li><p>输入采用的是<strong>字母三元组</strong>（letter-trigram），类似于<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1509.01626.pdf">character-CNN</a>。每个单词都拆分成几个 字母三元组，作为CNN的输入。比如单词<em>who</em>可以拆分为#-w-h, w-h-o, h-o-#。每个单词通过前后添加符号#来区分单词界限（并且单词最短只含一个字母，添加两个#可以保证能形成至少一个字母三元组）。</p></li>
<li><p>采用<strong>字母三元组的好处</strong>：</p>
<ul>
<li>1.减小输入维度，这样输入维度可以稳定在字母集大小+1(#号)的三次方，即<span class="math inline">\(27^3\)</span>，而不是字典大小（同时可以处理一些字典中不存在的词和一些低频词，如缩写词等等）。</li>
<li>相同语义的词语可能因为词根等缘故，前缀或者后缀会比较相似，这样能更好的提取单词语义的特征。</li>
<li>对于现实生活中的用户，有时候可能会发生单词拼写错误，但错误拼写不会对这种输入方式造成太大影响。</li>
</ul></li>
</ul>
<h4 id="增加约束和聚合函数">2.3.3 增加约束和聚合函数</h4>
<ul>
<li><p>通过增加约束和聚合函数的方式来扩展查询图，缩小答案的范围，以增加准确率，如下图：<img src="https://pic4.zhimg.com/v2-cf8cee1305f077c185cc213593ae8bcb_r.jpg" alt="img" /></p></li>
<li><p>是否要为CVT节点添加约束节点和聚合节点：</p>
<ol type="1">
<li>约束实体出现在问句中</li>
<li>约束谓词表示事件的结束时间，但没有值（这表示它是当前事件）</li>
<li>问题中出现约束实体名称的一些单词</li>
<li>谓语是<em>people.marriage</em>.<em>type_of_union</em>（这说明关系是否是家庭伴侣关系、婚姻关系还是民事关系）</li>
<li>问句中包含单词 <em>first</em> 或者 <em>oldest</em>，并且谓语是from形式的谓语（表明事件的起始时间）</li>
<li>问句中包含单词 <em>last</em>, <em>latest</em> 或 <em>newest</em> ，并且谓语是to形式的谓语（表明事件的结束时间）</li>
</ol></li>
<li><p>对于答案节点，如果包含以下之一的谓语，我们会增加一个<strong>约束节点</strong>：</p>
<p><em>people.person.gender /</em> <em>common.topic.notable types /</em> <em>common.topic.notable_for</em></p></li>
</ul>
<h2 id="奖励函数的特征定义">3. 奖励函数的特征定义</h2>
<ul>
<li><p>利用对数线性模型训练奖励函数，需手工定义一个特征向量来表征整个查询图的信息，将其作为对数线性模型的输入。</p></li>
<li><p>例如问题：“<em>Who first voiced Meg on Family Guy?</em>” 对应的查询图，它的特征如下图所示：<img src="https://pic3.zhimg.com/v2-22f7a9d0ca105aeda97d27af5e9a087e_r.jpg" alt="img" /></p>
<ul>
<li><p>从<strong>主题词链接</strong>、<strong>核心推导链</strong>、<strong>增加约束聚合</strong>三个方面定义特征。</p>
<ul>
<li><p><strong>主题词链接特征</strong>：实体链接得分（EntityLinkingScore），由实体链接系统给出。例如：<em>EntityLinkingScore(FamilyGuy,"Family Guy")=0.9</em></p></li>
<li><p><strong>核心推导链特征</strong>：</p>
<ol type="1">
<li><p><strong>PatChain</strong>：将问句中的主题词替换为实体符号，和谓语序列同时输入两个不同的CNN，根据CNN输出的表达求语义相似度作为特征。</p>
<p>如: <em>PatChain("Who first voiced Meg on <e>", cast-actor) =0.7</em></p></li>
<li><p><strong>QuesEp</strong>：将谓语序列和主题词的规范名称（canonical name）连接（concatenate）起来作为输入，和问题求语义相似度</p>
<p>如: <em>QuesEP(q,“family guy cast-actor”</em>) = 0.6</p></li>
<li><p><strong>ClueWeb</strong>：用<a target="_blank" rel="noopener" href="http://lemurproject.org/clueweb12/index.php">ClueWeb</a>来训练一个更加<em>in-domain</em>的模型。如果一句话包含两个实体和谓语，那么就把这句话和谓语作为一组 数据对 输入模型进行训练。<em>注意：ClueWeb的输入和PatChain是一样的，但是其模型是用不同数据训练的。</em></p></li>
</ol>
<p>从这定义的三个特征可以看出，这其实是一个<em>ensemble</em>模型，将三种模型的输出结果进行了一个log-linear组合。</p></li>
<li><p><strong>约束聚合特征</strong>：</p>
<ul>
<li>对于CVT节点，有以下特征：
<ol type="1">
<li>约束实体是否出现在问句中 如<em>ConstraintEntityInQ("Meg Griffin",q)=1</em></li>
<li>是否是当前发生的事件</li>
<li>是否是当前发生的事件，且问句中包含关键词“currently”, “current”, “now”, “present” 和“presently”</li>
<li>约束实体单词出现在问句中的百分比 如<em>ConstraintEntityWord("Meg Griffin",q)=0.5</em></li>
<li>约束谓语的类型是<em>people.marriage.type_of_union</em></li>
<li>问题中是否包含“first” 或 “oldest” ，谓语是from形式谓语，并且CVT节点按该from性质排序是第一</li>
<li>问题中是否包含“last”, “latest” 或 “newest” ，谓语是to形式谓语，并且CVT节点按该to性质排序是最后</li>
</ol></li>
<li>对于答案节点有以下特征：
<ol type="1">
<li>性别一致性（男性）：约束谓语是<em>gender</em>，并且问句中出现了以下男性关键词中的一个{“dad”, “father”, “brother”, “grandfather”, “grandson”, “son”, “husband”}</li>
<li>性别一致性（女性）：约束谓语是<em>gender</em>，并且问句中出现了以下女性关键词中的一个{“mom”, “mother”, “sister”, “grandmother”, “granddaughter”, “daughter”, “wife”}</li>
<li>当约束谓语是 <em>notable_types</em> 或 <em>notable_for</em> 时，约束实体单词出现在问题中的百分比</li>
</ol></li>
</ul></li>
<li><p><strong>总体特征</strong></p>
<ul>
<li>查询图对应的答案数量<strong>NumAns</strong></li>
<li>查询图的节点数<strong>NumNodes</strong></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<h2 id="模型学习">4. 模型学习</h2>
<ul>
<li>根据查询图对应的实体和真实答案的F1-score进行排名。</li>
<li>基于<a target="_blank" rel="noopener" href="https://pdfs.semanticscholar.org/0df9/c70875783a73ce1e933079f328e8cf5e9ea2.pdf">lambda-rank</a>算法对一个一层的神经网络进行训练。</li>
<li>好处：有些查询图虽然查询得到的答案和真实答案不完全相同，但根据它的相同程度（F1-score）也可以说它比完全错误的查询图要好。</li>
</ul>

      
    </div>

    
	
	

	
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/03/01/%E7%AC%AC05%E5%91%A8/6.%20%E5%9F%BA%E4%BA%8E%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C-Large-scale%20Simple%20Question%20Answering%20with%20Memory%20Networks/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Olivia">
      <meta itemprop="description" content="May All Your Troubles Be little Ones">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Olivia的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/03/01/%E7%AC%AC05%E5%91%A8/6.%20%E5%9F%BA%E4%BA%8E%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C-Large-scale%20Simple%20Question%20Answering%20with%20Memory%20Networks/" class="post-title-link" itemprop="url">6. 基于记忆网络-Large-scale Simple Question Answering with Memory Networks</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-03-01 00:00:00" itemprop="dateCreated datePublished" datetime="2021-03-01T00:00:00+08:00">2021-03-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-04 15:16:04" itemprop="dateModified" datetime="2021-05-04T15:16:04+08:00">2021-05-04</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/" itemprop="url" rel="index"><span itemprop="name">Knowledge Base Qestion Answering</span></a>
                </span>
                  >
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/paper-comprehension/" itemprop="url" rel="index"><span itemprop="name">paper comprehension</span></a>
                </span>
                  >
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/paper-comprehension/basis/" itemprop="url" rel="index"><span itemprop="name">basis</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>2.3k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>2 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ul>
<li>论文：https://arxiv.org/abs/1506.02075</li>
</ul>
<h2 id="简介">1. 简介</h2>
<ul>
<li><p>当时的KB-QA对于解决<strong>只依赖一个知识三元组</strong>的简单问题（称为Simple Question Answering）仍有些困难，为此作者构建了一个更大的简单问题数据集，称作<strong>SimpleQuestions</strong>。该数据集的每个问题都依据一个知识三元组知识，进行人工构建问题，数据集最终一共包含了108,442个问题-答案对，相比之前只含8000多个问题-答案对的benchmark数据集WebQuestion，其数据量大了很多。该数据集的部分数据如下图所示<em>（下划线表示答案）</em>：<img src="https://pic1.zhimg.com/80/v2-97d2063bf381150a3e97860e6d53d760_720w.png" alt="img" /></p></li>
<li><p>整体思想是<strong>将知识库里的知识存储到记忆模块M中，问题经过输入模块I转化为分布式表达，输出模块O选择与问题最相关的支撑记忆（由于SimpleQuestions的问题只依赖一个知识，所以只需要选择一条记忆），回答模块R将该记忆对应三元组的宾语作为最终答案输出。</strong></p></li>
<li><p>在模型训练完毕后，我们将Reverb中提取的三元组（Reverb的知识三元组是自然语言形式，如<em>(“Obama”, “was also born in”, “<strong>August 1961</strong>”)</em>，知识三元组抽取自ClueWeb）作为新的知识，用<strong>泛化模块G</strong>将新知识存储到记忆模块中，在不经过re-training的情况下使用该记忆回答问题，测试模型的泛化性能。</p></li>
</ul>
<h2 id="整体流程">2. 整体流程</h2>
<h3 id="存储知识">2.1 存储知识</h3>
<ul>
<li>首先将知识库中的知识存储到记忆网络中。作者使用Freebase的两个子集FB2M（含2M实体和5K实体关系）和FB5M（含5M实体和7K实体关系）分别作为知识库。使用<strong>输入模块I</strong>来处理数据。</li>
<li>由于一个问句可能有多个答案，并且对于一个<strong>问题输出模块O</strong>只能选择一个支撑记忆，我们先对知识做两种预处理：
<ul>
<li>将具有相同主语和实体关系的三元组进行<strong>合并</strong>（Group），这样每一条知识将包含k个不同的宾语，即<span class="math inline">\(y=(s,r,\{o_1,...,o_k\})\)</span>。合并的原因在于我们想用一条记忆回答具有多个答案的问题（我们将合并前的知识三元体成为Atomic Facts，合并后的三元组成为Facts），合并后和合并前的知识库大小如下：<img src="https://pic3.zhimg.com/80/v2-4ed153a77495a8cde90f7ed1d81180a6_720w.png" alt="img" /></li>
<li><strong>去除中间节点。</strong>有些知识中日期会链接两个实体以区分某一事实的时间范围，我们可以将中间节点（mediator node）去除转化成一个二阶关系，这样我们就把长度为2的路径压缩成了长度为1的路径，即压缩为一个三元组。这个操作使得WebQuestion里的能被单一关系回答的问题数量从65%上升到86%。</li>
</ul></li>
<li>预处理完知识后，我们的<strong>输入模块I</strong>对知识进行预处理并存储到记忆中。这里使用词袋模型bag-of-symbol的方法，用一个<span class="math inline">\(N_S\)</span>维的multi-hot向量<span class="math inline">\(f(y)\)</span>来表示每一条知识并作为记忆。<span class="math inline">\(N_S\)</span>的大小为知识库实体和实体关系的大小之和，主语实体<span class="math inline">\(s\)</span>和实体关系<span class="math inline">\(r\)</span>对应向量维的值为1，宾语实体<span class="math inline">\(o_i\)</span>对应维的值设为<span class="math inline">\(1/k\)</span>。</li>
</ul>
<h3 id="训练记忆网络">2.2 训练记忆网络</h3>
<ul>
<li>使用问题-答案对来训练记忆网络。</li>
<li>首先用<strong>输入模块I</strong>来处理输入的自然语言问句<span class="math inline">\(q\)</span>，我们使用n-gram词袋模型（bag-of-ngrams）方法，用一个<span class="math inline">\(N_V\)</span>维的multi-hot向量<span class="math inline">\(g(q)\)</span>来表示每一个问句。<span class="math inline">\(N_V\)</span>的大小是字典大小，字典包含所有问题中出现的单词和所有知识库实体的自然语言别称（这个别称可能由多个单词构成，我们用1个n-gram来表示）。</li>
<li>对于输入<span class="math inline">\(g(q)\)</span>，我们的<strong>输出模块O</strong>要在记忆中寻找一个与之最相关的支撑记忆。为了避免遍历整个记忆模块里的每一条知识，我们先确定一个候选范围。确定方式如下，将问句中的所有n-gram与知识库实体别称进行匹配，以确定候选实体，将含有候选实体作为主语的知识作为我们的候选支撑记忆。我们将记忆和问题投影到一个低维分布式空间，通过consine相似度作为得分函数，来寻找最相关的支撑记忆，即：<span class="math inline">\(S_{QA}(q,y)=cos(W_Vg(q),W_Sf(y))\)</span>。这里我们需要学习的参数就是两个权值矩阵<span class="math inline">\(W_V,W_S\)</span>。</li>
<li>这里与[[4. Multi-Column向量建模-Question Answering over Freebase with Multi-Column Convolutional Neural Networks]]提到的训练方法一样，我们构建margin-based ranking损失函数，也进行多任务的训练，通过多任务训练让语义相同的问题的分布式表达<span class="math inline">\(W_V(q)\)</span>相似。</li>
<li>需要注意的是，我们知道构建margin-based ranking损失函数需要提供支撑记忆的正样本和负样本，由于SimpleQuestion数据集的每个问题都有对应的知识标签，因此我们已经有支撑记忆的正确标签。但是对于WebQuestion数据集，我们没有正确的支撑记忆标签，作者通过类似之前寻找候选支撑记忆的方式去得到标签。</li>
</ul>
<h3 id="测试网络泛化能力">2.3 测试网络泛化能力</h3>
<ul>
<li>使用<strong>泛化模块G</strong>来连接新的知识库Reverb到我们的记忆中，通过实体链接和实体别名匹配等方式，来匹配已有记忆中的实体和新知识库里的实体（这种方式只能匹配到新知识库中17%的实体）。新知识库中剩下的实体和所有的关系都用词袋模型表示，因此我们可以用一个<span class="math inline">\(N_V+N_S\)</span>维的向量来<span class="math inline">\(h(y)\)</span>表示新知识并将其存储到记忆中。同样的，输出模块在寻找支撑记忆时的相似度得分函数为<span class="math inline">\(S_{RVB}(q,y)=cos(W_Vg(q),W_{VS}h(y))\)</span>，其中矩阵<span class="math inline">\(W_{VS}\)</span>直接由之前训练好的<span class="math inline">\(W_V,W_s\)</span>拼接（concatenate）而成。</li>
</ul>

      
    </div>

    
	
	

	
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/03/01/%E7%AC%AC05%E5%91%A8/7.%20%E5%BC%95%E5%85%A5%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6-Question%20Answering%20over%20Knowledge%20Base%20with%20Neural%20Attention%20Combining%20Global%20Knowledge%20Information/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Olivia">
      <meta itemprop="description" content="May All Your Troubles Be little Ones">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Olivia的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/03/01/%E7%AC%AC05%E5%91%A8/7.%20%E5%BC%95%E5%85%A5%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6-Question%20Answering%20over%20Knowledge%20Base%20with%20Neural%20Attention%20Combining%20Global%20Knowledge%20Information/" class="post-title-link" itemprop="url">7. 引入注意力机制-Question Answering over Knowledge Base with Neural Attention Combining Global Knowledge Information</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-03-01 00:00:00" itemprop="dateCreated datePublished" datetime="2021-03-01T00:00:00+08:00">2021-03-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-04 15:16:09" itemprop="dateModified" datetime="2021-05-04T15:16:09+08:00">2021-05-04</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/" itemprop="url" rel="index"><span itemprop="name">Knowledge Base Qestion Answering</span></a>
                </span>
                  >
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/paper-comprehension/" itemprop="url" rel="index"><span itemprop="name">paper comprehension</span></a>
                </span>
                  >
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/paper-comprehension/basis/" itemprop="url" rel="index"><span itemprop="name">basis</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>1.9k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>2 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ul>
<li>论文：https://arxiv.org/abs/1606.00979</li>
</ul>
<h2 id="简介">1. 简介</h2>
<ul>
<li>深度学习提升向量建模方法的大体框架都很接近：根据问题确定主题词，根据主题词确定候选答案，通过候选答案和问题的分布式表达相似度得分确定最终答案。<strong>而方法的核心在于学习问题和候选答案的分布式表达</strong>，其实相关的方法都是在这两个部分做文章。这篇文章的想法在于，<strong>对于不同的答案，我们关注问题的焦点是不同的，我们根据候选答案的信息，来引入注意力机制，对同一个问题提取出不同的分布式表达。</strong></li>
<li>比如 对于问题 <em>"who is the president of France?"</em>，其中之一的答案是实体<em>“Francois Holland”</em>，我们通过知识库可以知道<em>Francois</em> <em>Holland</em> 是一个总统，因此我们会更加关注问句中的 <em>“president”</em> 和 <em>“France”</em> 单词，而根据<em>Francois</em> <em>Holland</em>的类型person，我们会更关注问句中的疑问词<em>who</em>。</li>
</ul>
<h2 id="过程">2. 过程</h2>
<h3 id="将候选答案转化为分布式表达">2.1 将候选答案转化为分布式表达</h3>
<ul>
<li>我们从多个方面考虑答案的特征：答案实体、答案上下文环境（知识库中所有与答案实体直接相连的实体）、答案关系（答案与问题主题词之间的实体关系）、答案类型。每一种特征都可以用<span class="math inline">\(v_k\)</span>维的multi-hot向量表示，<span class="math inline">\(v_k\)</span>即知识库实体和实体关系的数量之和。我们通过Embedding矩阵<span class="math inline">\(E_k\)</span>将每一种特征转化为低维的分布式表达，我们就得到了四种关于答案的分布式表达<span class="math inline">\(e_e,e_c,e_r,e_t\)</span>（其中由于答案上下文环境涉及的实体较多，我们取这些实体的embedding均值作为上下文环境的embedding）。</li>
</ul>
<h3 id="将自然语言问题转化为分布式表达">2.2 将自然语言问题转化为分布式表达</h3>
<ul>
<li>将问句中的每一个单词经过Embedding矩阵<span class="math inline">\(E_w\)</span>转化为wrod-embedding，使用双向LSTM(bi-LSTM)提取问句特征。bi-LSTM第<span class="math inline">\(j\)</span>时刻的输出记作<span class="math inline">\(h_j\)</span>，使用bi-LSTM的好处在于<span class="math inline">\(h_j\)</span>既包含了第<span class="math inline">\(j\)</span>个单词之前的信息，又包含了该单词之后的信息。</li>
</ul>
<h3 id="在得分函数中引入注意力机制">2.3 在得分函数中引入注意力机制</h3>
<ul>
<li><p>我们希望我们问句的分布式表达对于四种不同的答案特征有不同的表达（根据答案特征对于问题有不同的关注点），第<span class="math inline">\(i\)</span>种答案的分布式表达<span class="math inline">\(e_i\)</span>对应的问句分布式表达记作<span class="math inline">\(q_i\)</span>，我们的得分函数定义为四种对应表达的点乘之和，即：<img src="https://pic3.zhimg.com/80/v2-802b38aa199f6d26e3a73283998105fa_720w.png" alt="img" /></p></li>
<li><p>对于一般的LSTM，我们通常将最后一个时刻的输出<span class="math inline">\(h_T\)</span>作为句子的最终表达，而在这里，我们引入注意力机制，根据问题的特征，给予每一时刻的输出不同程度的关注（对bi-LSTM每一时刻的输出进行加权求和），即：</p>
<figure>
<img src="https://pic2.zhimg.com/80/v2-d735558c648d7fc61ce4bd7744c56575_720w.png" alt="img" /><figcaption aria-hidden="true">img</figcaption>
</figure></li>
<li><p>其中的权重系数<span class="math inline">\(a_{ij}\)</span>取决于bi-LSTM第<span class="math inline">\(j\)</span>时刻的输出<span class="math inline">\(h_j\)</span>和第<span class="math inline">\(i\)</span>种答案特征的分布式表达<span class="math inline">\(e_i\)</span>，因此可以使用一个单层的神经网络去学习这个权重，并通过Softmax对权重进行归一化，公式如下：<img src="https://pic1.zhimg.com/v2-6992d087e8a1da5e3f6d620f0ab65bec_r.jpg" alt="img" /></p></li>
</ul>
<h3 id="oov问题">2.3 OOV问题</h3>
<ul>
<li>在测试过程中，我们的候选答案可能从未在训练集中出现过，因此它对应的分布式表达是没有被我们的模型训练过的（这个问题称为<em>the problem of out of vocabulary, OOV</em>）。为了解决该问题，作者利用<a target="_blank" rel="noopener" href="https://www.utc.fr/~bordesan/dokuwiki/_media/en/transe_nips13.pdf">TransE</a>对知识库进行训练，训练实体和实体关系对应的Embedding矩阵<span class="math inline">\(E_k\)</span>（实际操作中，作者通过轮流训练KB-QA模型和TranE的方式训练并共用Embedding矩阵<span class="math inline">\(E_k\)</span>，每训练一个epoch的KB-QA就训练100个epoch的TransE)。这样，我们就利用了整个知识库的特性，预先对每一个知识库实体都进行了训练，使得相似实体的分布式表达也很相似。因此，即使遇到KB-QA训练集中未遇到的候选答案实体，KB-QA模型也能将它视作是在训练集中出现过的某个和它分布式表达相似的实体，这样就减轻了OOV问题所带来的破坏性。
<ul>
<li>关于TransE：<em>TransE是知识图谱补全的经典方法，它借鉴了word-embedding的思想，能够将知识库中的实体和实体关系用分布式向量表达。其主要思想是对于一个知识三元组（s,r,o），我们希望主语实体的分布式表达e(s)加上关系实体的分布式表达e(r)能够尽量接近宾语实体的分布式表达e(o)，因此我们可以构建类似的margin-rank损失函数通过正样本和采样负样本进行训练。TransE提出之后还出现了大量的改进算法，诸如TransH、TransR、TransG、TranSparse、TransD等等。</em></li>
</ul></li>
</ul>
<h2 id="实验环节">3. 实验环节</h2>
<ul>
<li>注意力机制的好处：<strong>可视化</strong>，通过可视化每个单词的权重，可以得到一些可解释性，如下图：<img src="https://pic2.zhimg.com/v2-e96c3293e5997acdd4b8676063248aed_r.jpg" alt="img" /></li>
</ul>

      
    </div>

    
	
	

	
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/default-index/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/default-index/">1</a><span class="page-number current">2</span><a class="page-number" href="/default-index/page/3/">3</a><a class="extend next" rel="next" href="/default-index/page/3/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Olivia"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Olivia</p>
  <div class="site-description" itemprop="description">May All Your Troubles Be little Ones</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">30</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="/yajie.wang@mail.hfut.edu.cn" title="E-Mail → yajie.wang@mail.hfut.edu.cn"><i class="fa fa-envelope fa-fw"></i></a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="http://www.hfut.edu.cn/" title="http:&#x2F;&#x2F;www.hfut.edu.cn&#x2F;" rel="noopener" target="_blank">合肥工业大学</a>
        </li>
    </ul>
  </div>

      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2019 – 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">wyj-Olivia</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">145k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">2:12</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest-nomobile.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  
<div id="needsharebutton-float">
      <span class="btn">
        <i class="fa fa-share-alt" aria-hidden="true"></i>
      </span>
    </div>
  <script src="//cdn.jsdelivr.net/gh/theme-next/theme-next-needmoreshare2@1/needsharebutton.min.js"></script>
  <script>
      pbOptions = {};
        pbOptions.iconStyle = "box";
        pbOptions.boxForm = "horizontal";
        pbOptions.position = "bottomCenter";
        pbOptions.networks = "Weibo,Wechat,Douban,QQZone,Twitter,Facebook";
      new needShareButton('#needsharebutton-postbottom', pbOptions);
      flOptions = {};
        flOptions.iconStyle = "box";
        flOptions.boxForm = "horizontal";
        flOptions.position = "middleRight";
        flOptions.networks = "Weibo,Wechat,Douban,QQZone,Twitter,Facebook";
      new needShareButton('#needsharebutton-float', flOptions);
  </script>
</body>
</html>
