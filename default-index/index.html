<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="May All Your Troubles Be little Ones">
<meta property="og:type" content="website">
<meta property="og:title" content="Olivia的博客">
<meta property="og:url" content="http://example.com/default-index/index.html">
<meta property="og:site_name" content="Olivia的博客">
<meta property="og:description" content="May All Your Troubles Be little Ones">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Olivia">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/default-index/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>
<link rel="stylesheet" href="//cdn.jsdelivr.net/gh/theme-next/theme-next-needmoreshare2@1/needsharebutton.min.css"><style>
#needsharebutton-postbottom {
  cursor: pointer;
  height: 26px;
  margin-top: 10px;
  position: relative;
}
#needsharebutton-postbottom .btn {
  border: 1px solid $btn-default-border-color;
  border-radius: 3px;
  display: initial;
  padding: 1px 4px;
}
</style><style>
#needsharebutton-float {
  bottom: 88px;
  cursor: pointer;
  left: -8px;
  position: fixed;
  z-index: 9999;
}
#needsharebutton-float .btn {
  border: 1px solid $btn-default-border-color;
  border-radius: 4px;
  padding: 0 10px 0 14px;
}
</style>
  <title>Olivia的博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Olivia的博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/04/15/%E7%AC%AC09%E5%91%A8/Graph%20Convolution%20over%20Pruned%20Dependency%20Trees%20Improves%20Relation%20Extraction/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Olivia">
      <meta itemprop="description" content="May All Your Troubles Be little Ones">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Olivia的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/04/15/%E7%AC%AC09%E5%91%A8/Graph%20Convolution%20over%20Pruned%20Dependency%20Trees%20Improves%20Relation%20Extraction/" class="post-title-link" itemprop="url">Graph Convolution over Pruned Dependency Trees Improves Relation Extraction</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-04-15 00:00:00" itemprop="dateCreated datePublished" datetime="2021-04-15T00:00:00+08:00">2021-04-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-06 14:42:01" itemprop="dateModified" datetime="2021-05-06T14:42:01+08:00">2021-05-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/" itemprop="url" rel="index"><span itemprop="name">Knowledge Base Qestion Answering</span></a>
                </span>
                  >
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/paper-comprehension/" itemprop="url" rel="index"><span itemprop="name">paper comprehension</span></a>
                </span>
                  >
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/paper-comprehension/latest/" itemprop="url" rel="index"><span itemprop="name">latest</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>2.2k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>2 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ul>
<li>论文及代码：https://github.com/qipeng/gcn-over-pruned-trees</li>
</ul>
<h2 id="abstract-intro">Abstract &amp; Intro</h2>
<ul>
<li>提出了一种基于图卷积网络的关系提取神经模型，使得它能够有效地并行汇集任意依赖结构上的信息</li>
<li>对输入树应用了一种新的剪枝策略，即两个实体之间可能存在关系的最短路径附近保持单词。帮助基于依赖的模型在不破坏关键内容的情况下最大限度地去除无关信息，以提高其鲁棒性</li>
<li>证明了基于依赖的模型与序列模型具有互补的优点。</li>
<li>通过图卷积运算<strong>对输入句子上的依存结构进行编码</strong>，然后提取以实体为中心的表示以做出稳健的关系预测。还<strong>应用了一种新的以路径为中心的剪枝技术</strong>，在最大限度地保留相关内容的同时从树中删除不相关的信息。</li>
</ul>
<h2 id="models">2. Models</h2>
<h3 id="依赖树上的图卷积网络graph-convolutional-networks-over-dependency-trees">2.1 依赖树上的图卷积网络(Graph Convolutional Networks over Dependency Trees)</h3>
<figure>
<img src="https://i.loli.net/2021/04/05/JQWgHKUC3DeX4uf.png" alt="image-20210405145405426.png" /><figcaption aria-hidden="true">image-20210405145405426.png</figcaption>
</figure>
<ul>
<li><p>将每棵树转换为其对应的邻接矩阵<span class="math inline">\(A\)</span>(图表示)使得图卷积操作适合于建模依赖树，其中如果标记<span class="math inline">\(i\)</span>和<span class="math inline">\(j\)</span>之间如果存在依赖边，则<span class="math inline">\(A_{ij}=1\)</span>。</p></li>
<li><p>因为token的度数变化很大，直接应用图卷积神经网络的公式会导致句子表示偏向于度数高的结点而不考虑节点中携带的信息(详见Sec. 2.2)，同时<span class="math inline">\(h_i^{(l-1)}\)</span>中的信息永远不会传递到<span class="math inline">\(h_i^{(l)}\)</span>，因为节点在依赖树中不会连接到自己。</p></li>
<li><p>故在<span class="math inline">\(L\)</span>层GCN中，假设共有<span class="math inline">\(n\)</span>个节点，<span class="math inline">\(h_i^{(l-1)}\)</span>表示为第<span class="math inline">\(l\)</span>层的输入向量，<span class="math inline">\(h_i^{(l)}\)</span>表示为第<span class="math inline">\(l\)</span>层的输出向量，公式更改为： <span class="math display">\[
h_i^{(l)}=\sigma(\sum_{j=1}^n\tilde A_{ij}W^{(l)}h_j^{(l-1)}/d_i+b^{(l)})
\]</span> 其中<span class="math inline">\(\tilde A=A+I\)</span>，<span class="math inline">\(I\)</span>为<span class="math inline">\(n×n\)</span>的单位矩阵，<span class="math inline">\(d_i=\sum_{j=1}^n\tilde A_{ij}\)</span>是在结果图中token i的度数，<span class="math inline">\(W^{(l)}\)</span>是线性变换，<span class="math inline">\(b^{(l)}\)</span>是偏置项，<span class="math inline">\(\sigma\)</span>是非线性函数（例如，ReLU）</p></li>
<li><p>好处：可通过矩阵乘法高效实现，这使得它非常适合在示例上进行批处理计算和在GPU上运行。此外，令牌之间的信息传播是并行进行的，运行时不依赖于依赖树的深度。</p></li>
<li><p>上述GCN模型对依赖图中所有边使用相同的参数。</p></li>
</ul>
<h3 id="使用gcn编码关系encoding-relations-with-gcn">2.2 使用GCN编码关系(Encoding Relations with GCN)</h3>
<ul>
<li><p>设<span class="math inline">\(\chi=[x_1,...,x_n]\)</span>表示一个句子，<span class="math inline">\(x_i\)</span>是第<span class="math inline">\(i\)</span>个令牌(token)。主语实体和宾语实体被标识出并分别对应句子中的两个跨度(span)：<span class="math inline">\(\chi_s=[x_{s_1},...,x_{s_2}]\ \ \chi_o=[x_{o_1},...,x_{o_2}]\)</span>，给定<span class="math inline">\(\chi,\chi_s,\chi_o\)</span>，关系提取的目标是预测实体之间存在的关系<span class="math inline">\(r\in R\)</span>（预定义的关系集），否则为“无关系”。</p></li>
<li><p>在对词向量应用<span class="math inline">\(L\)</span>层GCN后，得到了每个令牌的隐藏表示，为了利用这些单词表示进行关系提取，首先获得如下句子表示法： <span class="math display">\[
h_{sent}=f(h^{(L)})=f(GCN(h^{(0)}))
\]</span> <span class="math inline">\(h^{(l)}\)</span>表示第<span class="math inline">\(l\)</span>层GCN的集体隐藏表示，<span class="math inline">\(f:R^{d×n}\rightarrow R^d\)</span>是从<span class="math inline">\(n\)</span>个输出向量映射到句子向量的max-pooling。</p></li>
<li><p>依赖树中接近实体token的信息通常是关系分类的中心。因此我们也从<span class="math inline">\(h^{(L)}\)</span>中获得了主语表示： <span class="math display">\[
h_s=f(h^{(L)}_{s_1:s_2})
\]</span> 同样的方法也可以得到<span class="math inline">\(h_o\)</span>的表示</p></li>
<li><p>将句子和实体表示连接起来，并将它们馈送到前馈神经网络(FFNN)中来获得用于分类的最终表示： <span class="math display">\[
h_{final}=FFNN([h_{sent};h_s;h_o])
\]</span> 然后<span class="math inline">\(h_{final}\)</span>被馈送到线性层随后进行<span class="math inline">\(SoftMax\)</span>运算以获得关系上的概率分布。</p></li>
</ul>
<h3 id="情景化gcncontextualized-gcn">2.3 情景化GCN(Contextualized GCN)</h3>
<ul>
<li>输入词向量不包含关于语序或歧义消除的上下文信息。事先通过将输入的词向量反馈入LSTM中生成上下文表示，以用作<span class="math inline">\(h^{(0)}\)</span>。</li>
</ul>
<h2 id="将非路径信息与以路径为中心的修剪相结合incorporating-off-path-information-with-path-centric-pruning">3. 将非路径信息与以路径为中心的修剪相结合(Incorporating Off-path Information with Path-centric Pruning)</h2>
<ul>
<li><p>与关系相关的大部分信息通常包含在以两个实体的最短公共祖先(LCA)为根的子树中。将GCN模型与树修剪策略相结合以进一步提高性能。但是过于激进的修剪(例如只保留依赖路径)可能会导致关键信息丢失，反过来影响健壮性。例如：<img src="https://i.loli.net/2021/04/05/yKIgNkenm13CHJt.png" alt="image-20210405152541144.png" /></p></li>
<li><p>提出了以路径为中心的剪枝(path-centric pruning)。在LCA子树里添加距离依赖路径最远<span class="math inline">\(K\)</span>个路径的令牌来实现的。<span class="math inline">\(K=0\)</span>，相当于将树向下修剪到路径，<span class="math inline">\(K=1\)</span>保留直接连接到路径的所有节点，<span class="math inline">\(K=∞\)</span>保留整个LCA子树。</p></li>
<li><p>将剪枝后的树直接反馈到GCN中(LSTM仍然作用于整个句子)，发现<span class="math inline">\(K=1\)</span>的剪枝在包含相关信息(例如否定和合取)和尽可能地将不相关的内容排除在所得到的剪枝树之间达到了最佳的平衡。</p></li>
</ul>

      
    </div>

    
	
	

	
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/04/15/%E7%AC%AC09%E5%91%A8/Information%20Extraction%20over%20Structured%20Data%20Question%20Answering%20with%20Freebase/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Olivia">
      <meta itemprop="description" content="May All Your Troubles Be little Ones">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Olivia的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/04/15/%E7%AC%AC09%E5%91%A8/Information%20Extraction%20over%20Structured%20Data%20Question%20Answering%20with%20Freebase/" class="post-title-link" itemprop="url">Information Extraction over Structured Data Question Answering with Freebase</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-04-15 00:00:00" itemprop="dateCreated datePublished" datetime="2021-04-15T00:00:00+08:00">2021-04-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-06 14:42:24" itemprop="dateModified" datetime="2021-05-06T14:42:24+08:00">2021-05-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/" itemprop="url" rel="index"><span itemprop="name">Knowledge Base Qestion Answering</span></a>
                </span>
                  >
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/paper-comprehension/" itemprop="url" rel="index"><span itemprop="name">paper comprehension</span></a>
                </span>
                  >
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/paper-comprehension/latest/" itemprop="url" rel="index"><span itemprop="name">latest</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>1.1k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ul>
<li>论文：http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.650.469&amp;rep=rep1&amp;type=pdf</li>
</ul>
<h2 id="信息抽取">信息抽取</h2>
<ul>
<li><p>根据<strong>主题词</strong>，在相应跳的范围内为<strong>候选答案</strong>构成<strong>主题图</strong>。</p></li>
<li><p><a target="_blank" rel="noopener" href="http://www.hankcs.com/nlp/chinese-sentences-svo-java-extraction.html">语法依存树(Dependency tree)</a>通过提取<strong>问题词<em>qword</em></strong>，<strong>问题焦点<em>qfocus</em></strong>，<strong>问题主题词<em>qtopic</em></strong>和<strong>问题中心动词<em>qverb</em></strong>这四个问题特征，我们可以将该问题的依存树转化为<strong>问题图（Question Graph）</strong>，如下图所示</p>
<figure>
<img src="https://pic3.zhimg.com/v2-f83ebe87d2f27db0eea0de3de5248cbe_r.jpg" alt="img" /><figcaption aria-hidden="true">img</figcaption>
</figure>
<ul>
<li>问题词(qword)：例如 who, when, what, where, how, which, why, whom, whose</li>
<li>问题焦点(qfocus)：这个词<strong>暗示了答案的类型</strong>，比如name/time/place，我们直接将问题词<strong><em>qword</em></strong>相关的那个名词抽取出来作为<em>qfocus</em>【可最后一步确定答案类型时确定】</li>
<li>主题词(qtopic)：可通过命名实体识别。</li>
<li>中心动词(qverb)：<strong>动词能够给我们提供很多和答案相关的信息</strong>，比如play，那么答案有可能是某种球类或者乐器。我们可以通过词性标注（Part-of-Speech，POS）确定<em>qverb。</em></li>
<li>转换时还需去掉一些不重要的叶子节点，如限定词（determiner，如a/the/some/this/each等），介词（preposition）和标点符号（punctuation）</li>
</ul></li>
</ul>
<h2 id="构建特征向量对候选答案进行分类">构建特征向量对候选答案进行分类</h2>
<ul>
<li><p>对于每个候选答案而言实际上是一个二分类问题，训练分类器，<strong>分类器的输入特征向量中的每一维对应一个问题-候选答案特征</strong>。每一个问题-候选答案特征由问题特征中的一个特征，和候选答案特征的一个特征，<strong>组合（combine）而成</strong>。</p></li>
<li><p>问题特征：从问题图中的每一条边e(s,t)，抽取4种问题特征：s，t，s|t，和s|e|t。如对于边prep_of(qfocus=name，brother)，我们可以抽取这样四个特征：<em>qfocus=what，brother，qfocus=what|brother</em> 和 <em>qfocus=what|prep_of|brother。</em></p></li>
<li><p>候选答案特征：对于主题图中的每一个节点，我们都可以抽取出以下特征：该节点的所有<strong>关系</strong>（relation，记作rel），和该节点的所有<strong>属性</strong>（property，如type/gender/age）。</p></li>
<li><p>利用朴素贝叶斯计算了每一个关系R和整个问题Q的关联度，可表示为概率的形式<span class="math inline">\(P(R|Q)\)</span>。</p></li>
</ul>
<h2 id="训练">训练</h2>
<ul>
<li>使用<a target="_blank" rel="noopener" href="https://stanfordnlp.github.io/CoreNLP/">Standford CoreNLP</a>帮助对问题进行信息抽取。</li>
</ul>

      
    </div>

    
	
	

	
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/04/15/%E7%AC%AC09%E5%91%A8/KERMIT%20Complementing%20Transformer%20Architectures%20with%20Encoders%20of%20Explicit%20Syntactic%20Interpretations/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Olivia">
      <meta itemprop="description" content="May All Your Troubles Be little Ones">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Olivia的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/04/15/%E7%AC%AC09%E5%91%A8/KERMIT%20Complementing%20Transformer%20Architectures%20with%20Encoders%20of%20Explicit%20Syntactic%20Interpretations/" class="post-title-link" itemprop="url">KERMIT Complementing Transformer Architectures with Encoders of Explicit Syntactic Interpretations</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-04-15 00:00:00" itemprop="dateCreated datePublished" datetime="2021-04-15T00:00:00+08:00">2021-04-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-06 14:42:44" itemprop="dateModified" datetime="2021-05-06T14:42:44+08:00">2021-05-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/" itemprop="url" rel="index"><span itemprop="name">Knowledge Base Qestion Answering</span></a>
                </span>
                  >
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/paper-comprehension/" itemprop="url" rel="index"><span itemprop="name">paper comprehension</span></a>
                </span>
                  >
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/paper-comprehension/latest/" itemprop="url" rel="index"><span itemprop="name">latest</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>2.8k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>3 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ul>
<li>论文：https://www.aclweb.org/anthology/2020.emnlp-main.18/</li>
</ul>
<h2 id="abstract-intro">Abstract &amp; Intro</h2>
<ul>
<li><p>将句法分析树嵌入到人工神经网络并可视化语法推理</p></li>
<li><p>用<strong>显式通用句法解释</strong>（句法分析树）改进最新的通用句子嵌入，并创建在句法上可解释的神经网络结构</p></li>
<li><p>循环神经网络[RecNNs]是应用于二叉树的递归神经网络。</p></li>
<li><p>结构核函数[structural kernel function]一直是学习中利用句法信息的方法，但这些函数不能在神经网络中使用。核机器[kernel machine]利用了这些通常是递归的结构核函数，它们定义了计算公共子结构的两棵树之间的相似性度量。</p></li>
<li><p>结构核领域，分布式内核为了降低树核的计算量，这些分布式树核将巨大的子结构空间嵌入到较小的空间中。这种嵌入是通过使用递归函数来获得的，递归函数相对于树的大小是线性的。[ Distributed tree kernels.]</p></li>
<li><p>Reverse Feature Engineering of Syntactic Tree Kernels[2010]</p></li>
</ul>
<h2 id="the-model">3. The model</h2>
<ul>
<li>介绍Kernel-inspired Encoder with a Recursive Mechanism for Interpretable Trees(KERMIT)，及其可视化工具<span class="math inline">\(\bold {KERMIT}_{viz}\)</span>，可以与transformer网络结合使用。</li>
</ul>
<h3 id="预备表示preliminary-notation">3.1 预备表示(Preliminary notation)</h3>
<ul>
<li>修正了解析树、随机向量和对随机向量操作的表示。</li>
<li>解析树<span class="math inline">\(\mathcal{T}\)</span>和解析子树<span class="math inline">\(\tau\)</span>被递归定义为<span class="math inline">\(t=(r,[t_1,...,t_k])\)</span>，其中<span class="math inline">\(r\)</span>是树根的表示，<span class="math inline">\([t_1,...,t_k]\)</span>是子树<span class="math inline">\(t_i\)</span>的集合。叶子节点<span class="math inline">\(t\)</span>被定义为<span class="math inline">\(r=(r,[])\)</span>，其中的子树集合为空，也可直接记作<span class="math inline">\(t=r\)</span></li>
<li>对于解析树<span class="math inline">\(\mathcal{T}\)</span>，模型需要三个子树集合的定义：集合<span class="math inline">\(N(\mathcal{T})\)</span>、集合<span class="math inline">\(\bar S(\mathcal{T})\)</span>和集合<span class="math inline">\(S(\mathcal{T})\)</span>。后两个集合根据我们想要在通用句法embedding中建模而用到的子树定义。
<ul>
<li><span class="math inline">\(N(\mathcal{T})\)</span>包含<span class="math inline">\(\mathcal{T}\)</span>的所有<strong>完整子树</strong>。给定一棵树<span class="math inline">\(\mathcal{T}\)</span>和其中一个结点<span class="math inline">\(r\)</span>，<span class="math inline">\(\mathcal{T}\)</span>的一个完整子树是以<span class="math inline">\(r\)</span>为根一直到达叶子节点的子树。<img src="https://i.loli.net/2021/04/08/fTmQbLz7lOs1xGH.png" alt="image-20210408165347649.png" /></li>
<li><span class="math inline">\(\bar S(\mathcal{T})\)</span></li>
</ul></li>
<li>最后，为了构建未经训练的KERMIT编码器，我们利用从多变量高斯分布<span class="math inline">\(v\sim \mathcal{N}(d,\frac 1 {\sqrt{d}})\)</span>中提取出的随机向量的性质。这些向量保证了如果<span class="math inline">\(u ≠v\)</span>，则<span class="math inline">\(u^Tv≈0\)</span>并且<span class="math inline">\(u^Tu≈1\)</span>。这个性质对于可解释性很重要。</li>
<li>为了合成这些向量，我们利用混洗循环卷积(shuffled circular convolution)<span class="math inline">\(u\otimes v\)</span>。如何这些向量取自多元高斯分布，则该函数保证<span class="math inline">\((u\otimes v)^Tu≈0,(u\otimes v)^Tv≈0,(u\otimes v)≠(v\otimes u)\)</span>。这是一步循环卷积(circular convolution)的操作。这一步操作对于合理合成节点向量很重要。</li>
</ul>
<h3 id="解析树及其子网络的编码器the-encoder-for-parse-trees-and-its">3.2 解析树及其子网络的编码器(The encoder for parse trees and its</h3>
<p>sub-network)</p>
<figure>
<img src="C:\Users\Olivia~\AppData\Roaming\Typora\typora-user-images\image-20210408172002015.png" alt="image-20210408172002015" /><figcaption aria-hidden="true">image-20210408172002015</figcaption>
</figure>
<ul>
<li>主要有两个组件。第一个是Kermit编码器，它将解析树<span class="math inline">\(\mathcal{T}\)</span>实际编码为嵌入向量。 <span class="math display">\[
y=\mathcal{D}(\mathcal{T})
\]</span> 第二个组件是利用这些嵌入向量的多层感知器： <span class="math display">\[
z=mlp(y)
\]</span></li>
</ul>
<h4 id="第一个组件">第一个组件</h4>
<ul>
<li><p>编码器<span class="math inline">\(\mathcal{D}\)</span>来源于树核(tree kernel)和分布式树核(distributed tree kernel)。它使得在向量空间<span class="math inline">\(R^d\)</span>内表示解析树成为可能，这个空间承载了大量子树<span class="math inline">\(R^n\)</span>的空间，其中<span class="math inline">\(n\)</span>是不同子树的数目。</p></li>
<li><p>每个<span class="math inline">\(\mathcal{T}\)</span>使用它的有效子树<span class="math inline">\(S(\mathcal{T})\)</span>表示。</p></li>
<li><p>编码器是基于树节点标签<span class="math inline">\(x_r=W_or\in R^d\)</span>的嵌入层和基于混洗循环卷积<span class="math inline">\(\otimes\)</span>的递归编码函数。</p></li>
<li><p>嵌入层<span class="math inline">\(x_r=W_or\in R^d\)</span>是未经训练的编码函数，其将一个树节点标签<span class="math inline">\(r\)</span>的one-hot向量<span class="math inline">\(r\)</span>映射到先前介绍的多变量高斯分布<span class="math inline">\(v\sim \mathcal{N}(d,\frac 1 {\sqrt{d}})\)</span>中提取到的随机变量。</p></li>
<li><p>所以<span class="math inline">\(W_o\in R^{m×d}\)</span>是一个<span class="math inline">\(m\)</span>列的矩阵，其中<span class="math inline">\(m\)</span>是节点标签集合的基数，并且矩阵<span class="math inline">\(W_o\)</span>中每一列<span class="math inline">\(w^{(i)}\)</span>都满足<span class="math inline">\(w^{(i)}\sim \mathcal{N}(d,\frac 1 {\sqrt{d}})\)</span>。函数<span class="math inline">\(\mathcal{D}(\mathcal{T})\)</span>被定义为解析树上的递归函数<span class="math inline">\(\Upsilon(t)\)</span>的和： <span class="math display">\[
y=\mathcal{D}(\mathcal{T})=\sum_{t\in N(\mathcal{T})}\Upsilon(t)
\]</span> 其中，<span class="math inline">\(N(\mathcal{T})\)</span>之前定义为是完整子树<span class="math inline">\(\mathcal{T}\)</span>的集合，然后<span class="math inline">\(\Upsilon(t)\)</span>被定义为：<img src="https://i.loli.net/2021/04/08/AHOdWq2VGLFYyoI.png" alt="image-20210408191917727.png" /></p>
<p>其中，<span class="math inline">\(0&lt;\lambda≤1\)</span>是惩戒大子树的衰减因子。通过动态算法实现<span class="math inline">\(\mathcal{D}(\mathcal{T})\)</span>计算成本是相对于树的节点是线性的，并且基本函数的<span class="math inline">\(\otimes\)</span>的花销是<span class="math inline">\(dlogd\)</span>，<span class="math inline">\(d\)</span>是表示空间<span class="math inline">\(R^d\)</span>的大小。</p></li>
<li><p>由于其本质，树神经编码器有一个很好地解释为一个非常简单的嵌入层即<span class="math inline">\(W_{\Upsilon}\in R^{d×n}\)</span>，将子树的空间嵌入到较小的<span class="math inline">\(R^d\)</span>空间中，因此<span class="math inline">\(\mathcal{D(T)}\)</span>可看作： <span class="math display">\[
y=\mathcal{D(T)}=W_{\Upsilon}x
\]</span> 其中<span class="math inline">\(x\)</span>为子树集合<span class="math inline">\(S(\mathcal{T})\)</span>的向量表示，即<span class="math inline">\(\sqrt{\lambda^k}x_t\)</span>的和，其中<span class="math inline">\(x_t\)</span>是表示<span class="math inline">\(t\in S(\mathcal{T})\)</span>的one-hot向量，<span class="math inline">\(\lambda\)</span>是惩戒规模大的树的衰减因子，<span class="math inline">\(k\)</span>是树<span class="math inline">\(t\)</span>的节点数目。可以很容易的推导出，矩阵<span class="math inline">\(W_\Upsilon\)</span>中列<span class="math inline">\(w_i\)</span>编码子树<span class="math inline">\(t\)</span>如下：<img src="https://i.loli.net/2021/04/08/t8OMTVIE3JbGPlX.png" alt="image-20210408193355775.png" /></p></li>
</ul>

      
    </div>

    
	
	

	
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/04/15/%E7%AC%AC09%E5%91%A8/%E4%BE%9D%E5%AD%98%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Olivia">
      <meta itemprop="description" content="May All Your Troubles Be little Ones">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Olivia的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/04/15/%E7%AC%AC09%E5%91%A8/%E4%BE%9D%E5%AD%98%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90/" class="post-title-link" itemprop="url">依存句法分析</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-04-15 00:00:00" itemprop="dateCreated datePublished" datetime="2021-04-15T00:00:00+08:00">2021-04-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-06 14:53:13" itemprop="dateModified" datetime="2021-05-06T14:53:13+08:00">2021-05-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/" itemprop="url" rel="index"><span itemprop="name">Knowledge Base Qestion Answering</span></a>
                </span>
                  >
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/Others/" itemprop="url" rel="index"><span itemprop="name">Others</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>2.9k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>3 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="句法分析依存分析dependency-parsing">句法分析：依存分析(Dependency Parsing)</h1>
<h2 id="句法分析任务分类">1. 句法分析任务分类</h2>
<p>根据<strong>句法结构的表现形式</strong>不同，最常见的句法分析任务可以分为以下三种：</p>
<ul>
<li>句法结构分析(syntactic structure parsing)，又称短语结构分析（phrase structure parsing），也叫成分句法分析（constituent syntactic parsing）。作用是识别出句子中的短语结构以及短语之间的层次句法关系。</li>
<li><strong>依存关系分析</strong>，又称依存句法分析（dependency syntactic parsing），简称依存分析，作用是识别句子中词汇与词汇之间的相互依存关系。依存句法分析属于<strong>浅层句法分析</strong>。</li>
<li>深层文法句法分析，即利用深层文法，例如词汇化树邻接文法（Lexicalized Tree Adjoining Grammar， LTAG）、词汇功能文法（Lexical Functional Grammar， LFG）、组合范畴文法（Combinatory Categorial Grammar， CCG）等，对句子进行深层的句法以及语义分析。</li>
</ul>
<h2 id="依存分析方法">2. 依存分析方法</h2>
<p>PCFG、Lexical PCFG详见：https://blog.csdn.net/qq_28031525/article/details/79187080</p>
<p><a target="_blank" rel="noopener" href="https://wohugb.github.io/chatbot/12.semantic-dependency/">用语言云分析依存句法和语义依存</a>：语言云工具</p>
<p><a target="_blank" rel="noopener" href="https://wohugb.github.io/chatbot/18.tree/">生成句法分析树</a>：基于概率上下文无关文法(PCFG)</p>
<ul>
<li><p>依存语句树：除了一个词，即根节点（这里为jumped）外，其他词都有词作为父亲节点，而该根节点（jumped）的父亲节点为root。</p></li>
<li><p>但是注意，依存句法树是不允许弧之间有交叉或者回路！ <img src="https://img-blog.csdnimg.cn/img_convert/69120f8dc9aed900de650b9a592973e5.png" alt="69120f8dc9aed900de650b9a592973e5.png" /></p></li>
<li><p>文本表示格式为conll格式： <img src="https://img-blog.csdnimg.cn/img_convert/bfb3e982b9771e1855c8140fa3b10a05.png" alt="bfb3e982b9771e1855c8140fa3b10a05.png" /></p></li>
</ul>
<h3 id="传统的基于转移的依存分析transition-based-parsing">传统的基于转移的依存分析（Transition-based Parsing）</h3>
<ul>
<li><p>框架由状态和动作两部分构成，其中状态用来记录不完整的预测结果，动作则用来控制状态之间的转移。</p></li>
<li><p>构造一个三元组，分别是</p>
<ul>
<li>Stack：最开始只存放一个Root节点；</li>
<li>Buffer：则装有我们需要解析的一个句子；</li>
<li>Set：中则保存我们分析出来的依赖关系， 最开始是空的。</li>
</ul></li>
<li><p>用在生成依存句法树上，则具体表示为<strong>从空状态开始，通过动作转移到下一个状态，一步一步生成依存句法树，最后的状态保存了一个完整的依存树</strong>。依存分析就是用来预测词与词之间的关系，现在转为预测动作序列。在基于转移的框架中，我们定义了4种动作（栈顶的元素越小表示离栈顶越近）：</p>
<ul>
<li><p>移进（shift）：将buffer中的第一个词移出并放到stack上。</p></li>
<li><p>左规约（arc_left_I）：栈顶两个元素规约，左边节点下沉成为孩子节点，为弧上关系</p></li>
<li><p>右规约（arc_right_I）：栈顶两个元素规约，右边节点下沉成为孩子节点，为弧上关系</p></li>
<li><p>根出栈（pop_root）：根节点出栈，分析完毕</p></li>
<li><p>其中下沉的意思：</p>
<figure>
<img src="https://img-blog.csdnimg.cn/img_convert/f16fd3ae392da443a33e232dc0137a1c.png" alt="f16fd3ae392da443a33e232dc0137a1c.png" /><figcaption aria-hidden="true">f16fd3ae392da443a33e232dc0137a1c.png</figcaption>
</figure>
<p>0下沉，0是1的孩子</p></li>
</ul></li>
<li><p>具体例子理解：</p>
<ul>
<li><p>以上面依存树为例：</p>
<figure>
<img src="https://img-blog.csdnimg.cn/img_convert/a5f82461c27efca70218c269ff3f6eb5.png" alt="a5f82461c27efca70218c269ff3f6eb5.png" /><figcaption aria-hidden="true">a5f82461c27efca70218c269ff3f6eb5.png</figcaption>
</figure></li>
<li><p>一整套分析的动作序列为：</p>
<figure>
<img src="https://img-blog.csdnimg.cn/img_convert/adaa897b0aab1aeb7536f5e06c3b1863.png" alt="adaa897b0aab1aeb7536f5e06c3b1863.png" /><figcaption aria-hidden="true">adaa897b0aab1aeb7536f5e06c3b1863.png</figcaption>
</figure></li>
<li><p>初始状态 <img src="https://img-blog.csdnimg.cn/img_convert/885541f1d219e457829d439cd3894122.png" alt="885541f1d219e457829d439cd3894122.png" /></p>
<p>栈为空，队列为整个文本的数字序列。这个时候只能进行移进shift操作：</p></li>
<li><figure>
<img src="https://img-blog.csdnimg.cn/img_convert/e34663dd816b1ca94471bdfd888f87b3.png" alt="e34663dd816b1ca94471bdfd888f87b3.png" /><figcaption aria-hidden="true">e34663dd816b1ca94471bdfd888f87b3.png</figcaption>
</figure></li>
</ul>
<p>因为左边栈只有一个元素0，还是只能进行移进shift操作：</p>
<ul>
<li><img src="https://img-blog.csdnimg.cn/img_convert/c2beb7f2cf582a82b0850eba175b4b30.png" title="fig:" alt="c2beb7f2cf582a82b0850eba175b4b30.png" /></li>
</ul>
<p>这个时候栈中有2个元素，我们此时看依存树</p>
<pre><code>![06c37ba91a01f9587a79587f0e6b48d6.png](https://img-blog.csdnimg.cn/img_convert/06c37ba91a01f9587a79587f0e6b48d6.png) </code></pre>
<p>0、1之间并没有弧，不能进行规约，所以还是只能shift：</p>
<ul>
<li><img src="https://img-blog.csdnimg.cn/img_convert/f44b666f17bb65cdbaf7b58d737fad03.png" title="fig:" alt="f44b666f17bb65cdbaf7b58d737fad03.png" /></li>
</ul>
<p>此时看栈顶两元素，发现依存树中1、2之间有依存关系</p>
<pre><code>![41fd404827975a6e7d7d6612912aafea.png](https://img-blog.csdnimg.cn/img_convert/41fd404827975a6e7d7d6612912aafea.png) </code></pre>
<p>而且1为2的孩子，所以此时的动作为左规约arc_left，1下沉，为2的孩子（此时实际操作为1被踢出栈，栈里剩为0、2，踢出是因为最后能根据动作序列还原整个依存树，当然也为了接下来的操作方便），此时标签为amod：</p>
<ul>
<li><img src="https://img-blog.csdnimg.cn/img_convert/d4215341ff4eccb3f643a6b595921b80.png" title="fig:" alt="d4215341ff4eccb3f643a6b595921b80.png" /></li>
</ul>
<p>此时栈里为0、2，再次查看依存树</p>
<pre><code>![9186bf73f9d75305eb42097fefa09f9d.png](https://img-blog.csdnimg.cn/img_convert/9186bf73f9d75305eb42097fefa09f9d.png) </code></pre>
<p>发现0、2之间有依存关系，其中0为2的孩子，所以此时操作为左规约，此时标签为det</p>
<p>...</p>
<ul>
<li><p>中间略过一些步骤，因为都是同理，这次说下第9步： <img src="https://img-blog.csdnimg.cn/img_convert/05a8eb621856d2a90d2298ae0468dbba.png" alt="05a8eb621856d2a90d2298ae0468dbba.png" /></p>
<p>此时栈中为3、4，查看依存树</p>
<figure>
<img src="https://img-blog.csdnimg.cn/img_convert/7747df36c58715bc888df2582b7a5678.png" alt="7747df36c58715bc888df2582b7a5678.png" /><figcaption aria-hidden="true">7747df36c58715bc888df2582b7a5678.png</figcaption>
</figure>
<p>按照正常操作，此时应该arc_right右规约，但是如果真的4就下沉，就没了。而一会5要入栈，再查看依存树发现4是自己的父节点，天呐，5的父节点没了，其他词都有父节点，就5没有，还有比这个更惨的吗？这就没发再进行操作了！所以，还有一个潜规则<strong>如果操作为栈顶元素要进行arc_right时，不执行该操作，而选择shift。</strong></p>
<p>而你可能会问arc_left会有这样的问题吗？不会啦，比如3、4进行arc_left操作，3下沉，如果右边的队列中有父亲节点是3，那么就表示该依存树有交叉或者回路！这种是不可能发生的，因为依存树不允许有交叉或者回路！</p>
<p>最后说下，pop_root根弹出操作，只能发生在最后 <img src="https://img-blog.csdnimg.cn/img_convert/8ad7de60b3f63796fe7be7649b7a68bf.png" alt="8ad7de60b3f63796fe7be7649b7a68bf.png" /></p>
<p>右下角的数据为词与词之间的关系，这个就是根据动作序列生成的依存关系（父亲，孩子，关系），根据该关系，就能还原成原来的依存树。</p></li>
</ul></li>
</ul>
<h3 id="神经网络模型">神经网络模型</h3>
<ul>
<li>利用神经网络进行特征提取，分为两部分：
<ul>
<li>编码器：用来负责计算词的隐层表示</li>
<li>解码器：用来解码计算当前状态的所有动作得分</li>
</ul></li>
</ul>
<h4 id="编码器">编码器</h4>
<ul>
<li><p>用Bi-LSTM来编码一个句子<span class="math inline">\((e_1,e_2,...,e_n)\)</span>计算对应的隐层表示。公式为： <span class="math display">\[
\{h_1,...,h_n\}=Bi-LSTM(\{e_1\oplus p_1,...,e_n\oplus p_n\})
\]</span></p>
<p>其中：<span class="math inline">\(e\)</span>为词向量，<span class="math inline">\(p\)</span>为词性向量，<span class="math inline">\(\oplus\)</span>是向量拼接</p></li>
</ul>
<h4 id="解码器">解码器</h4>
<ul>
<li><p>解码端就需要<strong>对每一个状态打出所有动作的得分</strong>。根据经验，认为<strong>栈顶三元素和队列首元素为动作预测关键特征</strong>，于是将栈顶三元素（下标越小离栈顶越近）和队列首元素进行拼接。然后用线性变换计算每一个动作的分数： <span class="math display">\[
o=Linear(h_{s0}\oplus h_{s1}\oplus h_{s2}\oplus h_{q0})
\]</span></p></li>
<li><p>对每一个动作的分数进行Softmax概率化，然后输入到交叉熵中，作为目标函数。然后再用Adam来进行更新模型参数，最小化目标函数 <img src="https://img-blog.csdnimg.cn/img_convert/c9b57159a161b3117f27e79730a244bc.png" alt="c9b57159a161b3117f27e79730a244bc.png" /></p>
<p>其中<span class="math inline">\(p_{a_g}\)</span>为动作序列概率，<span class="math inline">\(\Theta\)</span>为模型参数</p></li>
</ul>

      
    </div>

    
	
	

	
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/04/15/%E7%AC%AC09%E5%91%A8/%E6%95%B0%E6%8D%AE%E9%9B%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Olivia">
      <meta itemprop="description" content="May All Your Troubles Be little Ones">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Olivia的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/04/15/%E7%AC%AC09%E5%91%A8/%E6%95%B0%E6%8D%AE%E9%9B%86/" class="post-title-link" itemprop="url">DataSet</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-04-15 00:00:00" itemprop="dateCreated datePublished" datetime="2021-04-15T00:00:00+08:00">2021-04-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-06 14:53:21" itemprop="dateModified" datetime="2021-05-06T14:53:21+08:00">2021-05-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/" itemprop="url" rel="index"><span itemprop="name">Knowledge Base Qestion Answering</span></a>
                </span>
                  >
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/Others/" itemprop="url" rel="index"><span itemprop="name">Others</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>297</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ul>
<li>ComplexWebQuestions: https://www.tau-nlp.org/compwebq</li>
<li>MetaQA: https://github.com/yuyuz/MetaQA</li>
<li>WebQuestionSP: http://aka.ms/WebQSP</li>
</ul>
<p><img src="https://i.loli.net/2021/04/11/hpmTO7FN6PIzrC9.png" alt="image-20210411210148108.png" />【图源Query Graph....】</p>
<ul>
<li>PathQuestion: https://github.com/zmtkeke/IRN/tree/master/PathQuestion
<ul>
<li>大部分都是 of 's</li>
<li>2/3跳</li>
</ul></li>
<li>ComplexQuestions: https://github.com/JunweiBao/MulCQA/tree/ComplexQuestions</li>
</ul>

      
    </div>

    
	
	

	
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/03/29/%E7%AC%AC08%E5%91%A8/Improving%20Multi-hop%20Knowledge%20Base%20Question%20Answering%20by%20Learning%20Intermediate%20Supervision%20Signals/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Olivia">
      <meta itemprop="description" content="May All Your Troubles Be little Ones">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Olivia的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/03/29/%E7%AC%AC08%E5%91%A8/Improving%20Multi-hop%20Knowledge%20Base%20Question%20Answering%20by%20Learning%20Intermediate%20Supervision%20Signals/" class="post-title-link" itemprop="url">Improving Multi-hop Knowledge Base Question Answering by Learning Intermediate Supervision Signals Bases</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-03-29 00:00:00" itemprop="dateCreated datePublished" datetime="2021-03-29T00:00:00+08:00">2021-03-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-06 14:51:48" itemprop="dateModified" datetime="2021-05-06T14:51:48+08:00">2021-05-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/" itemprop="url" rel="index"><span itemprop="name">Knowledge Base Qestion Answering</span></a>
                </span>
                  >
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/paper-comprehension/" itemprop="url" rel="index"><span itemprop="name">paper comprehension</span></a>
                </span>
                  >
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/paper-comprehension/latest/" itemprop="url" rel="index"><span itemprop="name">latest</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>4.2k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>4 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="introduction">1. Introduction</h2>
<ul>
<li><p>只能以最终答案为参考，而在中间步骤缺乏监督信号，学生网络的目标是找到问题的正确答案，教师网络则是试图学习中间监督信号以提高学生网络的推理能力，具体地说，教师模型推断中间步骤的哪些实体与问题更相关，并且这些实体被认为是中间监督信号。主要创新点是教师网络的设计，利用向前向后推理来<strong>增强中间实体分布的学习</strong>，教师网络可以产生更可靠的中间监督信号，解决虚假推理。</p></li>
<li><p>监督信号一般为&lt;question, answer&gt;而不是&lt;question, relation path&gt;。</p></li>
<li><p>双向搜索算法，向前和向后搜索来更有效地识别。我们也有两种不同的观点来考虑任务设置：寻找从主题实体(即查询中的实体)到答案实体的路径的正向推理和从答案实体返回到主题实体的反向推理。</p></li>
<li><p><strong>学生网络采用神经状态机(NSM)来实现</strong>，学生网络可以根据从教师网络学习到的中间实体分布来改进自己。</p></li>
</ul>
<h2 id="提出的方法">4. 提出的方法</h2>
<h3 id="overview">4.1 Overview</h3>
<ul>
<li>学生网络基于NSM，通过将知识库看作一个图，使其适应于多跳KBQA任务，并在多跳推理过程中保持逐步学习的实体在实体上的分布。教师网络是对NSM的体系结构进行了改进，加入了一种新颖的双向推理机制，使其能够在中间推理步骤中学习到更可靠的实体分布，这些实体分布随后将被学生网络用作监督信号。</li>
</ul>
<h3 id="neural-state-machine-for-multi-hop-kbqa">4.2 Neural State Machine for Multi-hop KBQA</h3>
<ul>
<li>由指令部件和推理组件组成，指令组件向推理组件发送指令向量，<strong>而推理组件判断实体分布并学习实体表示</strong>。<img src="https://i.loli.net/2021/04/02/NWzRXDf4rwcGiAL.png" alt="image-20210402095741740.png" /></li>
</ul>
<h4 id="指令组件instruction-component">4.2.1 指令组件(Instruction Component)</h4>
<ul>
<li><p>先描述将给定的<strong>自然语言问题转换为</strong>一系列控制推理过程的<strong>指令向量</strong>。</p></li>
<li><p>指令组件的输入由<strong>查询嵌入</strong>和来自前一个推理步骤的<strong>指令向量</strong>组成。</p></li>
<li><p>初始向量为0向量。利用GloVe获得查询词的嵌入，然后利用LSTM网络获得一组隐藏层<span class="math inline">\(\{h_j\}^l_{j=1}\)</span>，其中<span class="math inline">\(h_j\in R^d,l\)</span>是查询的长度，最后一个隐藏层状态为问题表示即<span class="math inline">\(q=h_l\)</span>。令<span class="math inline">\(i^{(k)}\in R^d\)</span>为第<span class="math inline">\(k\)</span>步推理的指令向量，采用下列方法学习指令向量<span class="math inline">\(i^{(k)}\)</span>： <span class="math display">\[
i^{(k)}=\sum_{j=1}^l\alpha_j^{(k)}h_j,\\
\alpha_j^{(k)}=softmax_j(W_\alpha(q^{(k)}\odot h_j)+b_{\alpha}),\\
q^{(k)}=W^{(k)}[i^{(k-1)}:q]+b^{(k)}.
\]</span></p>
<p>其中<span class="math inline">\(W^{(k)}\in R^{d×2d},W_{\alpha}\in R^{d×d},b^{k}、b_{\alpha}\in R^d\)</span>都是需要学习的参数。</p>
<p>核心思想是学习不同时间步的指令向量时关注查询的特定部分。同时动态更新查询表示，以便包含先前指令向量的信息，通过重复以上步骤，可以在<span class="math inline">\(n\)</span>步推理后获得指令向量列表<span class="math inline">\(\{i^{(k)}\}^n_{k=1}\)</span>。</p></li>
</ul>
<h4 id="推理组件reasoning-component">4.2.2 推理组件(Reasoning Component)</h4>
<ul>
<li><p>获得指令组件<span class="math inline">\(i^{k}\)</span>后，我们可以将其用作推理信号的指导信号。</p></li>
<li><p>推理组件的输入包括当前步骤的指令向量、以及上一步推理步骤中获得的实体分布(entity distribution)和实体嵌入(entity embeddings)。首先，考虑涉及<span class="math inline">\(e\)</span>的关系来设置初始实体嵌入： <span class="math display">\[
e^{(0)}=\sigma(\sum_{(&lt;e&#39;,r,e&gt;\in N_e)}r\cdot W_T)
\]</span> 其中<span class="math inline">\(W_T\in R^{d×d}\)</span>是需要学习的参数，没有用到<span class="math inline">\(e\)</span>的嵌入来初始化，因为重要的是关系不是实体。</p></li>
<li><p>给定三元组<span class="math inline">\(&lt;e&#39;,r,e&gt;\)</span>，匹配向量<span class="math inline">\(m_{&lt;e&#39;,r,e&gt;}^{(k)}\)</span>通过匹配当前指令向量<span class="math inline">\(i^{(k)}\)</span>与关系向量<span class="math inline">\(r\)</span>来获得： <span class="math display">\[
m_{&lt;e&#39;,r,e&gt;}=\sigma(i^{(k)}\odot W_Rr)
\]</span> <span class="math inline">\(W_R\in R^{d×d}\)</span>是需要学习的参数。</p></li>
<li><p>最后我们聚合来自相邻三元组的匹配信息，并根据它们在上一推理步骤中受到的关注程度来为其分配权重。 <span class="math display">\[
\tilde e^{(k)}=\sum_{&lt;e&#39;,r,e&gt;\in N_e}p^{(k-1)}_{e&#39;}\cdot m^{(k)}_{&lt;e&#39;,r,e&gt;&#39;}
\]</span> 其中<span class="math inline">\(p_{e&#39;}^{(k-1)}\)</span>是上一推理步骤中实体<span class="math inline">\(e&#39;\)</span>的分配概率。这样的表示能捕获与知识库中实体相关联的关系语义。</p></li>
<li><p>然后更新实体嵌入如下： <span class="math display">\[
e^{(k)}=FFN([e^{(k-1)};\tilde e^{(k)}])
\]</span> 其中，FFN是以上一步嵌入<span class="math inline">\(e^{(k-1)}\)</span>及关系聚合embedding<span class="math inline">\(\tilde e^{(k)}\)</span>为输入的前反馈层。</p></li>
<li><p>通过此过程，关系路径(从topic entities到answer entities)和它与问题的匹配程度都编码到节点嵌入中去。在步骤<span class="math inline">\(k\)</span>导出的中间实体上的概率分布可计算为： <span class="math display">\[
p^{(k)}=softmax(E^{ {(k)}^T}w)
\]</span> 其中<span class="math inline">\(E^{(k)}\)</span>是一个矩阵，每一列为第<span class="math inline">\(k\)</span>步的实体嵌入，<span class="math inline">\(w\)</span>为参数。</p></li>
</ul>
<h3 id="the-teacher-network">4.3 The Teacher Network</h3>
<ul>
<li>目标是在中间步骤中学习或推断可靠的实体分布。没有这样的标签实体分布来训练教师网络，故受双向搜索算法启发，结合了双向推理机制来增强教师网络中中间实体分布的学习。</li>
</ul>
<h4 id="多跳kbqa的双向推理">4.3.1 多跳KBQA的双向推理</h4>
<ul>
<li><p>考虑forward reasoning和backward reasoning，让这两个推理过程在中间步骤相互同步。这样派生的中间实体分布比从单一方向学习的分布更可靠。</p></li>
<li><p>给定<span class="math inline">\(n\)</span>跳推理路径，让<span class="math inline">\(p_f^{(k)}\)</span>和<span class="math inline">\(p_b^{(n-k)}\)</span>分别表示前向推理第<span class="math inline">\(k\)</span>步和后向推理第<span class="math inline">\(n-k\)</span>步的实体分布。正常情况下<span class="math inline">\(p_f^{(k)}≈p_b^{(n-k)}\)</span>。</p></li>
</ul>
<h4 id="推理体系结构reasoning-architectures">4.3.2 推理体系结构(Reasoning Architectures)</h4>
<ul>
<li><p>有两种神经结构：并行推理和混合推理</p>
<ul>
<li><p>并行推理(parallel reasoning)：建立两个独立地NSM分别用于正向和反向推理，这两个网络相互独立，不共享参数，只考虑在中间实体分布上加上对应约束。</p></li>
<li><p>混合推理(hybrid reasoning)：<strong>共享相同的指令组件</strong>，并将两个推理过程安排在一个循环流水线中。除了对应约束之外，<strong>这两个进程还接收相同的指令向量。此外，在正向推理的最后一步中导出的信息作为初始值被馈送到反向推理中。</strong>在形式上，以下公式在这种情况下成立： <span class="math display">\[
p_b^{(0)}=p_f^{(n)},E_b^{(0)}=E_f^{(n)},\\
i_b^{(k)}=i_f^{(n+1-k)}
\]</span></p></li>
</ul></li>
<li><p>两种结构图如下：<img src="https://i.loli.net/2021/04/02/jJDR7XM2aNGtF5e.png" alt="image-20210402112347486.png" /></p></li>
<li><p>并行推理具有更松散的集成，而混合推理则需要两个推理过程中的信息进行更深层次的融合。与双向BFS不同，在我们的任务中，<strong>反向推理可能无法准确模拟正向推理的反向过程，因为这两个过程对应于多跳KBQA中不同的语义</strong>。考虑到这一问题，我们共享指令向量，并循环正向推理的最终状态来初始化后向推理。通过这种方式，反向推理获得了更多关于正向推理的信息，从而可以更好地追溯正向推理的推理路径。</p></li>
</ul>
<h3 id="通过学生-教师框架学习">4.4 通过学生-教师框架学习</h3>
<h4 id="optimizing-the-teacher-network">4.4.1 Optimizing the Teacher Network</h4>
<ul>
<li><p>教师网络主要考虑两个方面的损失，即推理损失和通信损失。</p></li>
<li><p>推理损失反映了对准确实体的预测能力，分成两个方向 <span class="math display">\[
\mathcal{L}_f=D_{KL}(p_f^{(n)},p^{*}_f),\ \mathcal{L}_b=D_{KL}(p_b^{(n)},p_b^{*})
\]</span> 其中<span class="math inline">\(p_f^{(n)}\)</span>（<span class="math display">\[p_b^{(n)}\]</span>）表示前向(后向)推理过程中最后的实体分布。<span class="math inline">\(p_f^*\)</span>及<span class="math inline">\(p_b^*\)</span>表示真实的实体分布。<span class="math inline">\(D_{KL}(\cdot,\cdot)\)</span>表示Kullback-Leibler发散，以不对称的方式测量两个分布之间的差异。</p>
<p>为了获得<span class="math inline">\(p_f^*\)</span>和<span class="math inline">\(p_b^*\)</span>我们将正确实体出现的次数转化为频率归一化分布。例如，如果图中<span class="math inline">\(k\)</span>个实体是正确实体，则最终分布中为他们分配<span class="math inline">\(\frac{1}{k}\)</span>的概率。</p></li>
<li><p>通信损失反映了两个推理过程的中间实体分布之间的一致性。可以通过计算每个中间步骤的损失相加来计算： <span class="math display">\[
\mathcal{L}_c=\sum_{k=1}^{n-1}D_{JS}(p_f^{(k)},p_b^{(n-k)})
\]</span> 其中<span class="math inline">\(D_{JS}(\cdot,\cdot)\)</span>是Jensen-Shannon散度，以对称的方式测量两个分布之间的差异。</p></li>
<li><p>最后教师网络整体的损失函数<span class="math inline">\(\mathcal{L}_t\)</span>为： <span class="math display">\[
\mathcal{L}_t=\mathcal{L}_f+\lambda_b\mathcal{L}_b+\lambda_c\mathcal{L}_c
\]</span></p></li>
<li><p>其中<span class="math inline">\(\lambda_b\ and\ \lambda_c\in(0,1)\)</span>是控制因子权重的超参数。</p></li>
</ul>
<h4 id="optimizing-the-student-network">4.4.2 Optimizing the Student Network</h4>
<ul>
<li><p>对教师模型进行收敛训练后，可以得到教师网络两个推理过程中的中间实体分布。我们将两个分布的平均值最为监督信号： <span class="math display">\[
p_t^{(k)}=\frac{1}{2}(p_f^{k}+p_b^{(n-k)}),\ k=1,...,n-1
\]</span></p></li>
<li><p>采用NSM模型作为学生网络进行正向推理。除了推理损失外，还考虑了学生网络的预测和教师网络的监督信号的损失： <span class="math display">\[
\mathcal{L}_1=D_{KL}(p_s^{(n)},p_f^*)\\
\mathcal{L}_2=\sum_{k=1}^{n-1}D_{KL}(p_s^{(k)},p_t^{(k)})\\
\mathcal{L}_s=\mathcal{L}_1+\lambda\mathcal{L}_2
\]</span> 其中<span class="math inline">\(p_t^{(k)}\)</span>与<span class="math inline">\(p_s^{(k)}\)</span>是分别表示教师网络和学生网络在第<span class="math inline">\(k\)</span>步的中间实体分布，<span class="math inline">\(\lambda\)</span>是需要调优的参数。</p></li>
</ul>

      
    </div>

    
	
	

	
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/03/29/%E7%AC%AC08%E5%91%A8/Multi-hop%20knowledge%20base%20question%20answering%20with%20an%20iterative%20sequence%20matching%20model/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Olivia">
      <meta itemprop="description" content="May All Your Troubles Be little Ones">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Olivia的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/03/29/%E7%AC%AC08%E5%91%A8/Multi-hop%20knowledge%20base%20question%20answering%20with%20an%20iterative%20sequence%20matching%20model/" class="post-title-link" itemprop="url">Multi-hop knowledge base question answering with an iterative sequence matching model</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-03-29 00:00:00" itemprop="dateCreated datePublished" datetime="2021-03-29T00:00:00+08:00">2021-03-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-06 14:36:35" itemprop="dateModified" datetime="2021-05-06T14:36:35+08:00">2021-05-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/" itemprop="url" rel="index"><span itemprop="name">Knowledge Base Qestion Answering</span></a>
                </span>
                  >
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/paper-comprehension/" itemprop="url" rel="index"><span itemprop="name">paper comprehension</span></a>
                </span>
                  >
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/paper-comprehension/latest/" itemprop="url" rel="index"><span itemprop="name">latest</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>2.4k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>2 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ul>
<li>论文地址：https://ink.library.smu.edu.sg/cgi/viewcontent.cgi?article=5939&amp;context=sis_research</li>
</ul>
<h2 id="introduction">1. Introduction</h2>
<ul>
<li><p>迭代的增长候选关系路径，最终到候选答案。每次迭代修剪掉不太可能到正确答案的分支。</p></li>
<li><p>采用match-aggregate框架将问题与候选答案序列进行匹配。提出一种增量式序列匹配模型来计算匹配分数，而不需要重新访问关系路径中的早期关系。</p></li>
<li><p>无需假设跳数已知等</p></li>
<li><p>由3个模块组成：迭代路径增长、增量序列匹配和终止检查。【3跳数据集】</p></li>
</ul>
<h2 id="our-method">3. Our Method</h2>
<h3 id="迭代路径增长iterative-path-growth">3.1 迭代路径增长(Iterative Path Growth)</h3>
<ul>
<li>迭代路径增长将候选路径增长到<span class="math inline">\(T\)</span>跳，每次迭代一跳。在每次迭代结束时，它只保留与问题最匹配的前K个候选路径。</li>
</ul>
<h4 id="candidate-path">3.1.1 Candidate path</h4>
<ul>
<li>给定问题<span class="math inline">\(q\)</span>，首先确定主题实体(topic entity)<span class="math inline">\(e_0\)</span>，候选路径是起始于<span class="math inline">\(e_0\)</span>的实体和关系的序列，使用<span class="math inline">\(p=(e_0,r_1,e_1,r_2,e_2,...,r_t,e_t)\)</span>表示<span class="math inline">\(t\)</span>跳的候选路径。</li>
</ul>
<h4 id="candidate-path-set">3.1.2 Candidate path set</h4>
<ul>
<li>在第<span class="math inline">\(t\)</span>次迭代后的候选路径集合定义为在第<span class="math inline">\(t\)</span>次迭代结束时保留的前<span class="math inline">\(K\)</span>条候选路径的集合，用<span class="math inline">\(\mathcal{P}^{(t)}\)</span>表示。<span class="math inline">\(|\mathcal{P}|=K\)</span>，<span class="math inline">\(each\ p\in \mathcal{P}^{(t)}\)</span>有<span class="math inline">\(t\)</span>跳关系。</li>
</ul>
<h4 id="tail-entity">3.1.3 Tail entity</h4>
<ul>
<li>候选路径<span class="math inline">\(p\)</span>的最后一个实体。</li>
</ul>
<h4 id="总结算法">3.1.4 总结算法</h4>
<figure>
<img src="https://i.loli.net/2021/04/01/RUD9H1qvJsBKbGh.png" alt="image-20210401202726357.png" /><figcaption aria-hidden="true">image-20210401202726357.png</figcaption>
</figure>
<h3 id="增量序列匹配incremental-sequence-matching">3.2 增量序列匹配(Incremental Sequence Matching)</h3>
<ul>
<li><p>因为路径是迭代增长，在第<span class="math inline">\(t\)</span>此迭代中，当需要匹配候选路径<span class="math inline">\(p\in \tilde{\mathcal{P}}\)</span>时，前<span class="math inline">\(t-1\)</span>个关系时的<span class="math inline">\(p\)</span>已经与先前迭代中的问题匹配完了，故只需将最后一个关系<span class="math inline">\(p\)</span>与问题进行匹配，并将此迭代中的分数与前几次迭代分数聚合起来，故为增量。</p></li>
<li><p>问题表示为：<span class="math inline">\(Q=(q_1,q_2,...,q_m)\)</span>，其中<span class="math inline">\(q_i\)</span>是问题中第i个词的embedding向量。</p></li>
<li><p>对于候选路径<span class="math inline">\(p=(e_0,r_1,e_1,...,r_t,e_t)\)</span>，表示为<span class="math inline">\(P^{(t)}=(w_{r_t,1},w_{r_t,2},...,w_{r_t,n})\)</span>，其中<span class="math inline">\(w_{r_t,j}\)</span>是关系<span class="math inline">\(r_t\)</span>的第<span class="math inline">\(j\)</span>个词的embedding向量。只考虑<span class="math inline">\(r_t\)</span>而不考虑其他关系，因为我们是增量的。也无需考虑各个实体。</p></li>
<li><p>然后考虑两组注意力权重：一组在Q(<span class="math inline">\(\beta\)</span>)上归一化，一组在<span class="math inline">\(P^{t}\)</span>(<span class="math inline">\(\alpha\)</span>)上归一化。<img src="https://i.loli.net/2021/04/01/r2lPWLTsKECpiou.png" alt="image-20210401210423623.png" /></p></li>
<li><p>为衡量<span class="math inline">\(P^{(t)}\)</span>与<span class="math inline">\(Q\)</span>的匹配程度，对于<span class="math inline">\(Q\)</span>中每个单词<span class="math inline">\(q_i\)</span>，推导出注意力加权和<span class="math inline">\(\bar P^{(t)}\)</span>如下： <span class="math display">\[
v_i^{(t)}=\sum_{j=1}^n\alpha_{i,j}\cdot \bar w_{r_t,j}
\]</span> 可以将<span class="math inline">\(\bar q_i\)</span>与<span class="math inline">\(v_i^{(t)}\)</span>进行比较，衡量问题中的第<span class="math inline">\(i\)</span>个单词通过关系<span class="math inline">\(r_t\)</span>在当前迭代中的匹配程度。</p></li>
<li><p>因为做的是增量匹配，可能<span class="math inline">\(\bar q_i\)</span>已在<span class="math inline">\(p_{(t-1)}\)</span>中与其他单词匹配过，故在当前阶段<span class="math inline">\(\bar q_i\)</span>与<span class="math inline">\(r_t\)</span>的匹配可能不关键。故定义标量<span class="math inline">\(a_i^{(t)}\)</span>来记录路径<span class="math inline">\(p\)</span>中到第<span class="math inline">\(t\)</span>次迭代得匹配程度，首先设置<span class="math inline">\(a_i^{(0)}=0\)</span>，然后定义 <span class="math display">\[
a^{(t)}_i=a^{(t-1)}_i+\sum_{j=1}^n\beta_{i,j}
\]</span> 与<span class="math inline">\(Q\)</span>中其他单词相比，<span class="math inline">\(\sum_{j=1}^n\)</span>直观展示了<span class="math inline">\(q_i\)</span>与<span class="math inline">\(r_t\)</span>中所有单词的匹配程度。</p></li>
<li><p>匹配向量(matching vector)：<img src="C:\Users\Olivia~\AppData\Roaming\Typora\typora-user-images\image-20210401212652816.png" alt="image-20210401212652816" /></p></li>
<li><p>给定序列<span class="math inline">\((m_1^{(t)},m_2^{(t)},...,m_m^{t})\)</span>，使用LSTM来处理该序列，然后进行maxpooling来获得单个向量<span class="math inline">\(\bar m^{(t)}\)</span>： <span class="math display">\[
\bar m^{(t)}=Max-Pool(LSTM(m_1^{(t)},m_2^{(t)},...,m_m^{t}))
\]</span></p></li>
<li><p>然后使用该向量导出<span class="math inline">\(Q\)</span>和<span class="math inline">\(P^{(t)}\)</span>的匹配分数，如下图：<img src="https://i.loli.net/2021/04/01/x2VaZF9qdluI6tT.png" alt="image-20210401213322706.png" /></p></li>
<li><p>整个候选路径<span class="math inline">\(p\)</span>和问题之间的完全匹配分数定义为如下，其中<span class="math inline">\(s^{(0)}(\cdot)=1\)</span>，对于有<span class="math inline">\(t\)</span>个关系的<span class="math inline">\(p\)</span>来说： <span class="math display">\[
s^{(t)}(p)=s^{(t-1)}(p_{t-1})\cdot  \gamma^{(t)}
\]</span> <span class="math inline">\(s^{(t)}(\cdot)\)</span>之后被用来rank<span class="math inline">\(\tilde{\mathcal{P}}\)</span>，来获得<span class="math inline">\(\mathcal{P}^{(t)}\)</span>。</p></li>
</ul>
<h3 id="终止检查termination-check">3.3 终止检查(Termination Check)</h3>
<ul>
<li><p>向量<span class="math inline">\(\bar m^{(t)}\)</span>是对<span class="math inline">\(p\)</span>相对于<span class="math inline">\(q\)</span>的匹配程度进行编码，将其转换为单个值便于终止检查，首先在第<span class="math inline">\(t\)</span>次迭代中为每个候选路径<span class="math inline">\(p\)</span>定义以下分数<img src="https://i.loli.net/2021/04/01/QwIJn9Dcrzgyxks.png" alt="image-20210401215412299.png" /></p>
<p>在预测阶段，将<span class="math inline">\(\bar z(T)\)</span>与阀值<span class="math inline">\(\tau\)</span>进行比较以确定何时停止。</p></li>
</ul>
<h3 id="损失函数">3.4 损失函数</h3>
<ul>
<li><p>需要学习的参数：<img src="https://i.loli.net/2021/04/01/rev7tJaUHiXLEAl.png" alt="image-20210401220026815.png" /></p></li>
<li><p>希望终止时<span class="math inline">\(\bar z^{(t)}\)</span>接近1，反之接近0</p></li>
<li><p>对于<span class="math inline">\(each\ p\in \mathcal{P}^{(t)}\)</span>，通过比较tail entity(或者tail entities)与正确答案entity或entities，可以计算F1分数，然后使用以下公式进行归一化：<img src="https://i.loli.net/2021/04/01/yuKoxiGUclDM83T.png" alt="image-20210401220943615.png" /></p></li>
<li><p>第二个目标是终止检查：<img src="https://i.loli.net/2021/04/01/UlI38qg9icGzfys.png" alt="image-20210401221241224.png" /></p></li>
</ul>

      
    </div>

    
	
	

	
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/03/29/%E7%AC%AC08%E5%91%A8/%E6%80%BB%E7%BB%93/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Olivia">
      <meta itemprop="description" content="May All Your Troubles Be little Ones">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Olivia的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/03/29/%E7%AC%AC08%E5%91%A8/%E6%80%BB%E7%BB%93/" class="post-title-link" itemprop="url">Summary(1)-to 2021.3.29</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-03-29 00:00:00" itemprop="dateCreated datePublished" datetime="2021-03-29T00:00:00+08:00">2021-03-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-06 14:39:36" itemprop="dateModified" datetime="2021-05-06T14:39:36+08:00">2021-05-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/" itemprop="url" rel="index"><span itemprop="name">Knowledge Base Qestion Answering</span></a>
                </span>
                  >
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/Others/" itemprop="url" rel="index"><span itemprop="name">Others</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>1.4k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="合成图">合成图</h2>
<ul>
<li><p>The Web as a Knowledge-base for Answering Complex Questions：大问题分解成小问题</p></li>
<li><p>Answering Complex Questions by Combining Information from Curatedand Extracted Knowledge Bases：</p>
<ul>
<li><p>部分查询。问句编码(q)、主路径编码、约束编码、注意力机制。其中注意力机制是利用查询向量<span class="math inline">\(g\)</span>(主路径编码和约束编码联合)学习<strong>针对问句</strong>中的emphasize parts最后形成上下文向量<span class="math inline">\(c\)</span>。最后<span class="math inline">\(c,q,g\)</span>一起训练得到语义相似度分数<span class="math inline">\(S_{sem}(q,G_i)\)</span>，最后的损失函数为 <span class="math display">\[
loss=ylog(S_{sem})+(1-y)log(1-S_{sem})
\]</span> <span class="math inline">\(y\in \{0,1\}\)</span>表示<span class="math inline">\(G_i\)</span>是否正确。将部分查询的质量估计为其所有完整查询派生的最佳<span class="math inline">\(F_1\)</span>分数。</p></li>
<li><p>每一步搜索出的作为部分查询，然后判断部分查询与原问题的相似度大小。</p></li>
<li><p>数据集：CompQWeb、WebQSP</p></li>
<li><p>最后不是可以直接生成问句？？</p></li>
</ul></li>
</ul>
<h2 id="uhop模型">UHop模型</h2>
<ul>
<li>UHop An Unrestricted-Hop Relation Extraction Framework for Knowledge-Based Question Answering：
<ul>
<li>使用的数据集为带标记的数据集(严重bug！)：
<ul>
<li>WebQSP：有标记，但跳数少</li>
<li>PathQuestion(L)：2 跳或3 跳</li>
<li>Grid World：跳数很多，但是三元组很特殊(relations in Grid World are the relative directions of two nodes)</li>
<li>Complex Sequential QA 未使用，不是需要多跳的问题，而是问题序列，每个问题需要一跳关系</li>
</ul></li>
<li>单跳关系提取、比较终止、动态问题表示</li>
<li>一次确定一条边，更新颖的是结束标志，所有outbound 比之前的都小</li>
</ul></li>
<li>Query Graph Generation for Answering Multi-hop Complex Questions from Knowledge Bases：
<ul>
<li>查询图一边加约束一边延伸，直到某一迭代的评分不比前一代高，但是语义匹配做的不好。</li>
<li>数据集
<ul>
<li>ComplexWebQuestions(CWQ)为主，1 跳 2 跳</li>
<li>WebQuestionSP(WQSP)</li>
<li>ComplexQuestion(CQ)</li>
</ul></li>
</ul></li>
<li>Multi-hop knowledge base question answering with an iterative sequence matching model：
<ul>
<li>一个很传统的搜索匹配模型</li>
<li>之前已经匹配过了，所以相似度得分只考虑最后一个的，但是还是设置一个变量考虑之前的匹配程度</li>
<li>终止检查考虑的是阀值【可以考虑利用UHop里的】</li>
</ul></li>
<li>问题和推理分开！！！相当于监督概率分布，监督的损失不好。教师网络相当于把学生网络正着反着做了一遍，损失一个是最后的结果，一个是中间各步骤的差。没有讲清楚推理的步数（推理的步数由指示组件完成）？忽略了语序，正着反着也容易忽略语义情况</li>
<li>监督也的确是得监督中间的概率分布，至于中间预设的跳数可以用UHop，监督语义匹配的分数概率</li>
<li>没有中间路径，所以很多是直接计算的目前的和整个问题的相似度，利用那个分解树，建立中间的监督或者是调节？来消除虚假推理。去年和前年两篇中顶会的论文采用了部分查询的思想，但是还是比较的</li>
</ul>

      
    </div>

    
	
	

	
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/03/15/%E7%AC%AC07%E5%91%A8/Answering%20Complex%20Questions%20by%20Combining%20Information%20from%20Curatedand%20Extracted%20Knowledge%20Bases/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Olivia">
      <meta itemprop="description" content="May All Your Troubles Be little Ones">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Olivia的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/03/15/%E7%AC%AC07%E5%91%A8/Answering%20Complex%20Questions%20by%20Combining%20Information%20from%20Curatedand%20Extracted%20Knowledge%20Bases/" class="post-title-link" itemprop="url">Answering Complex Questions by Combining Information from Curatedand Extracted Knowledge Bases</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-03-15 00:00:00" itemprop="dateCreated datePublished" datetime="2021-03-15T00:00:00+08:00">2021-03-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-06 11:56:39" itemprop="dateModified" datetime="2021-05-06T11:56:39+08:00">2021-05-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/" itemprop="url" rel="index"><span itemprop="name">Knowledge Base Qestion Answering</span></a>
                </span>
                  >
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/paper-comprehension/" itemprop="url" rel="index"><span itemprop="name">paper comprehension</span></a>
                </span>
                  >
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/paper-comprehension/latest/" itemprop="url" rel="index"><span itemprop="name">latest</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>4.3k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>4 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>论文：https://www.aclweb.org/anthology/2020.nli-1.1.pdf</p>
<h2 id="abstract">Abstract</h2>
<ul>
<li>在这项工作中，我们着眼于回答复杂的问题，这些问题往往需要结合来自多个来源的信息。提出了一种新颖的知识库问答系统MULTIQUE，它<strong>可以通过一系列针对特定知识库的简单查询将复杂问题映射为复杂查询模式</strong>。它使用基于神经网络的模型发现简单查询，该模型能够对抽取知识库中的文本关系和精选知识库中的本体关系进行集体推理。</li>
</ul>
<h2 id="introduction">1. Introduction</h2>
<ul>
<li><p>利用<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/25735572">curated KB和extracted KB</a>一起回答，二者互为补充</p></li>
<li><p>MULTIQUE构建查询路径来回答来自简单查询的复杂问题，每个查询都针对特定的知识库。</p></li>
<li><p>在语义解析的基础上，遵循enumerate-encode-compare方法。首先收集候选查询并编码为语义向量，然后与问题向量进行比较。然后在知识库上执行具有最高语义相似度的候选。</p></li>
<li><p>提出了两个关键修改：为了能够对知识库中的本体[curated KB]和文本关系[extracted KB]进行集体推理，首先对不同关系进行对齐，并学习了统一的语义表示。其次，由于缺乏完整注解的查询来训练模型，我们使用问题答案形式的隐式监督信号来学习。</p></li>
</ul>
<h2 id="task-and-overview">2. Task and Overview</h2>
<ul>
<li><p>Complex Question:</p>
<ul>
<li>问题Q对应的一个查询(query)G有不止一个关系，但只有一个查询焦点(query focus)。G是一个部分查询(partial queries)<span class="math inline">\(G=(G_1,G_2,...,G_O)\)</span>通过不同条件连接起来的序列。</li>
<li>一个部分查询包含四个基本要素
<ul>
<li>a <em>seed</em> entity <span class="math inline">\(s^r\)</span> is the root of the query</li>
<li>a <em>variable</em> node <span class="math inline">\(o^v\)</span> corresponds to an answer to the query</li>
<li>a <em>main relation path</em> <span class="math inline">\((s^r,p,o^v)\)</span> is the path that links <span class="math inline">\(s^r\)</span> to <span class="math inline">\(o^v\)</span> by one or two edges from either <span class="math inline">\(R^o\)</span> or <span class="math inline">\(R^t\)</span>（两种知识库中的关系）</li>
<li><em>constraints</em> take the form of an entity linked to the main relation by a relation <span class="math inline">\(c\)</span></li>
</ul></li>
<li>一个合成树(composition tree)<span class="math inline">\(C\)</span>描述如何在给定部分查询的情况下构造和评估查询<span class="math inline">\(G\)</span>，包含两个函数：
<ul>
<li><span class="math inline">\(simQA\)</span> 是用于查找简单查询的模型，它枚举简单查询的候选项，对其进行编码，并与问题表示进行比较，然后评估出最佳候选项</li>
<li><span class="math inline">\(join\)</span>描述了如何连接两个部分查询，即它们是否共享查询焦点或另一个变量节点</li>
</ul></li>
</ul></li>
<li><p><strong>方法总览</strong>：</p>
<ul>
<li><p>给定一个复杂的输入问题</p>
<ol type="1">
<li>首先计算一颗合成树，该树描述如何将推理分解为简单的部分查询</li>
<li>从curated和extracted KBs中为每个部分查询收集候选查询</li>
<li>对于每个候选，使用一个基于神经网络模型来衡量其与问题的语义相似性，该模型可对不同形式的关系进行推理</li>
<li>联接不同的部分查询找到问题的复杂查询</li>
<li>将派生出的几个完整的查询根据它们部分查询的语义相似分数(semantic similarity of their partial queries)、查询结构(query structure)和实体链接分数(entity linking scores)对其进行排序，在多个KB上寻找最佳推导。下图为MULTIQUE的体系结构：</li>
</ol>
<p><img src="https://i.loli.net/2021/03/21/kiUZOLudEWpFP6I.png" alt="image-20210321172428400.png" style="zoom:150%;" /></p></li>
</ul></li>
</ul>
<h2 id="partial-query-candidate-generation">3. Partial Query Candidate Generation</h2>
<figure>
<img src="https://i.loli.net/2021/03/21/6oFZhsmleQiwRPz.png" alt="image-20210321173056774.png" /><figcaption aria-hidden="true">image-20210321173056774.png</figcaption>
</figure>
<h3 id="identify-seed-entity">3.1 Identify seed entity</h3>
<ul>
<li>部分查询的seed <span class="math inline">\(s^r\)</span> 是问题中的链接实体或先前评估的部分查询的答案。</li>
</ul>
<h3 id="identify-main-relation-path">3.2 Identify main relation path</h3>
<ul>
<li>给定一个种子实体，考虑所有1跳和2跳路径<span class="math inline">\(p\)</span>，包括ontological and textual relations，路径的另一端是变量结点<span class="math inline">\(o^v\)</span>。</li>
</ul>
<h3 id="identify-constraints">3.3 Identify constraints</h3>
<ul>
<li>上一步确认的那些要给个实体和类型约束(<em>entity and type constraints</em>)。在例子中，我们考虑利用约束关系<em>is_a</em>来查找变量结点<span class="math inline">\(o^v\)</span>。我们还考虑通过单个关系连接到路径上的实体。我们还考虑约束的子集，以支持具有多个约束的查询。</li>
</ul>
<h3 id="transition-to-next-partial-query">3.4 Transition to next partial query</h3>
<ul>
<li>一旦收集到部分查询<span class="math inline">\(G_i\)</span>的候选，我们就参考合成树来确定下一部分查询<span class="math inline">\(G_{i+1}\)</span>的开始状态。</li>
<li>如果下一个操作是simQA，我们使用语义匹配模型来计算<span class="math inline">\(G_i\)</span>候选的语义相似度，并评估K个最好的候选。否则，继续生成<span class="math inline">\(G_i\)</span>中不重叠的实体链接候选。</li>
</ul>
<h2 id="semantic-matching">4. Semantic Matching</h2>
<figure>
<img src="https://i.loli.net/2021/03/21/VZbctA2Sfnu6OKl.png" alt="image-20210321200753591.png" /><figcaption aria-hidden="true">image-20210321200753591.png</figcaption>
</figure>
<h3 id="model-architecture">4.1 Model Architecture</h3>
<h4 id="encoding-question">4.1.1 Encoding question</h4>
<ul>
<li>使用令牌序列(token sequence)和依存结构(dependency structure)。</li>
<li><span class="math inline">\(&lt;w_1,w_2,...,w_n&gt;\)</span>是<span class="math inline">\(Q\)</span>中的令牌，其中，seed(constraint)已经被替换为<span class="math inline">\(w_E,w_C\)</span></li>
<li>利用embedding矩阵<span class="math inline">\(E_w\)</span>将token转换成向量<span class="math inline">\(&lt;q_1^w,q_2^w,...,q_n^w&gt;\)</span></li>
<li>再利用LSTM将序列编码为一个潜在向量<span class="math inline">\(q^w\)</span></li>
<li>类似地，将依存数编码为一个潜在向量<span class="math inline">\(q^{dep}\)</span></li>
</ul>
<h4 id="encoding-main-relation-path">4.1.2 Encoding main relation path</h4>
<ul>
<li><p>主关系路径可能是来自<span class="math inline">\(K_o\)</span>的textual relation，也可能来自<span class="math inline">\(K_c\)</span>的ontological relation，为在同一空间推断，需进行关系对齐</p></li>
<li><p>在关系对齐的情况下，对 对齐中的每个关系形式编码为潜在向量<span class="math inline">\(r_i\)</span>。然后对不同关系的潜在向量进行最大合并，以获得不同关系形式上的统一语义表示。</p></li>
<li><p>为了将每种关系形式编码成向量<span class="math inline">\(r_i\)</span>，考虑<strong>符号序列和id序列</strong>(Luo et al., 2018)。</p>
<p>For instance, the id sequence of the relation in Fig. 5 is {book_author}, while its token sequence is {‘book’, author’}.</p>
<ul>
<li>符号序列：将token编码成向量利用embedding矩阵，最后将average embedding记作token层的表示<span class="math inline">\(r^w\)</span>。</li>
<li>id序列：直接利用embedding矩阵<span class="math inline">\(E_r\)</span>计算id层的表示<span class="math inline">\(r_i^{id}\)</span></li>
</ul></li>
<li><p>一条路径的向量最终表示为<span class="math inline">\(r_i=[r_i^w;r_i^{id}]\)</span></p></li>
</ul>
<h4 id="encoding-constraints">4.1.3 Encoding constraints</h4>
<ul>
<li>同样的方法利用token级的表示<span class="math inline">\(c_i^w\)</span>和id级的表示<span class="math inline">\(c_i^{id}\)</span>编码约束关系<span class="math inline">\(c_i\)</span>。</li>
<li><strong>给定关系路径和约束路径的向量表示，我们通过应用max pooling来获得查询语句的组合语义表示(compositional semantic representation)<span class="math inline">\(g\)</span>。</strong></li>
</ul>
<h4 id="attention-mechanism">4.1.4 Attention mechanism</h4>
<ul>
<li><p>利用查询向量<span class="math inline">\(g\)</span>学习问句中的emphasize parts。</p></li>
<li><p>给定token层表示中的各隐藏层<span class="math inline">\(h_t,\ t\in \{1,2,...,n\}\)</span>，定义上下文向量[context vector]<span class="math inline">\(c\)</span>作为所有隐藏状态的加权和： <span class="math display">\[
c=\sum_{t=1}^n\alpha_th_t
\]</span> <span class="math inline">\(\alpha\)</span>是注意力权重，计算公式为： <span class="math display">\[
\alpha=softmax(Wtanh(W_qq^w+W_gg))
\]</span></p>
<p>其中<span class="math inline">\(W,W_g,W_q\)</span>是网络的参数矩阵。注意力权重表示给定部分查询，模型对各个token的关注度。</p></li>
</ul>
<h4 id="objective-function">4.1.5 Objective function</h4>
<ul>
<li><p>将上下文向量<span class="math inline">\(c\)</span>、问题依存向量<span class="math inline">\(q^{dep}\)</span>和查询向量<span class="math inline">\(g\)</span>连接起来，一起送到多层感知机(MLP)中。输出为一个标量，表示语义相似度分数<span class="math inline">\(S_{sem}(q,G_i)\)</span>。使用交叉熵损失函数来训练模型。 <span class="math display">\[
loss=ylog(S_{sem})+(1-y)log(1-S_{sem})
\]</span> <span class="math inline">\(y\in \{0,1\}\)</span>表示<span class="math inline">\(G_i\)</span>是否正确。</p></li>
<li><p>训练模型需要对等关系表单的对齐和(question, partial query)对。我们描述如何在给定QA对的情况下生成它们。</p></li>
</ul>
<h3 id="relation-alignment">4.2 Relation Alignment</h3>
<ul>
<li>首先学习textual嵌入然后对其进行聚类以获得规范化(canonicalized)关系蔟(Vashishth et al., 2018)。例如，一个聚类可以包含"is author of"和"authored"。</li>
<li>使用规范化的文本关系(canonicalized textual relations)来推导出与本体论关系(ontological relations)的对齐。</li>
<li>基于一对 本体关系 和 规范化文本关系 的 支持实体对<span class="math inline">\((s,o)\)</span> 来实现这种对齐。</li>
<li>以我们的示例问题为例，关系<em>"is author of"</em>和<em>book.author</em>一定比关系<em>"is author of"</em>和<em>education.institution</em>有更多关联实体。</li>
<li>该对齐基于支持阀值，即一对关系的最小数量的支持实体对，本文中设置为5.</li>
</ul>
<h3 id="implicit-supervision">4.3 Implicit Supervision</h3>
<ul>
<li><p>候选查询的质量可以通过计算其对标签答案的<span class="math inline">\(F_1\)</span>分数间接获得(Peng et al., 2017a)。但是对于复杂问题，候选查询的答案可能与标签答案几乎没有重叠。</p></li>
<li><p>因此采用另一种评分策略，将部分查询的质量估计为其所有完整查询派生的最佳<span class="math inline">\(F_1\)</span>分数。计算部分查询的分数<span class="math inline">\(V(G_i^{(k)})\)</span>为： <span class="math display">\[
V(G_i^{(k)})=\max_{i\leq t \leq n-1}F_1(D_{t+1}^{k})
\]</span> 其中<span class="math inline">\(D_t\)</span>表示级别<span class="math inline">\(t\)</span>的派生，<span class="math inline">\(n\)</span>表示部分查询的数量。</p></li>
<li><p>这种隐含监督可能收到虚假推导的影响，恰好评估出了正确答案，却没有捕捉到问题的语义含义，所以还需要考虑额外的先验来促进训练数据中的真阳性和假阴性的示例。</p></li>
<li><p>我们使用<span class="math inline">\(L(Q,G_i^{(k)})\)</span>作为问题<span class="math inline">\(Q\)</span>中提到<span class="math inline">\(G_i^{(k)}\)</span>的关系中的词数之比。也使用<span class="math inline">\(C(Q,G_i^{(k)})\)</span></p></li>
</ul>

      
    </div>

    
	
	

	
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/03/15/%E7%AC%AC07%E5%91%A8/Query%20Graph%20Generation%20for%20Answering%20Multi-hop%20Complex%20Questions%20from%20Knowledge%20Bases/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Olivia">
      <meta itemprop="description" content="May All Your Troubles Be little Ones">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Olivia的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/03/15/%E7%AC%AC07%E5%91%A8/Query%20Graph%20Generation%20for%20Answering%20Multi-hop%20Complex%20Questions%20from%20Knowledge%20Bases/" class="post-title-link" itemprop="url">Query Graph Generation for Answering Multi-hop Complex Questions from Knowledge Bases</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-03-15 00:00:00" itemprop="dateCreated datePublished" datetime="2021-03-15T00:00:00+08:00">2021-03-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-06 11:56:45" itemprop="dateModified" datetime="2021-05-06T11:56:45+08:00">2021-05-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/" itemprop="url" rel="index"><span itemprop="name">Knowledge Base Qestion Answering</span></a>
                </span>
                  >
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/paper-comprehension/" itemprop="url" rel="index"><span itemprop="name">paper comprehension</span></a>
                </span>
                  >
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Knowledge-Base-Qestion-Answering/paper-comprehension/latest/" itemprop="url" rel="index"><span itemprop="name">latest</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>3.4k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>3 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ul>
<li>论文原文：https://www.aclweb.org/anthology/2020.acl-main.91.pdf</li>
</ul>
<h2 id="introduction">1. Introduction</h2>
<ul>
<li>目前主要在研究两种复杂性问题：
<ul>
<li>带约束的单一关系问题(Single-relation questions with constraints)</li>
<li>具有多跳关系的问题(Questions with <em>multiple hops</em> of relations)
<ul>
<li>减少需考虑的多跳关系路径的数量，本文采用beam search，即consider only the best matching relation instead of all relations when extending a relation path.</li>
</ul></li>
</ul></li>
<li>本文同时处理复杂KBQA的约束和多跳关系。
<ul>
<li>在查询图的生成过程中，允许更长的关系路径。</li>
<li>不再是关系路径构建完成之后再添加约束，而是同时合并约束和扩展关系路径，可以减少搜索空间。</li>
</ul></li>
</ul>
<h2 id="method">2. Method</h2>
<h3 id="preliminaries">2.1 Preliminaries</h3>
<ul>
<li><p>现有的查询图生成方法【本文largely inspired by】</p>
<p>【<span id="2015"><a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/P15-1128.pdf">Semantic parsing via staged query graph generation: Question answering with knowledge base, 2015</a></span></p>
<p><span id="2016"><a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/C16-1236.pdf">Constraint-based question an- swering with knowledge graph, 2016</a></span></p>
<p><span id="2018"><a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/D18-1242.pdf">Knowledge base question answering via en- coding of complex query graphs, 2018</a></span>】</p></li>
<li><p>一个查询图(query graph)有四种结点：</p>
<ul>
<li>grounded entity(带阴影的矩形)：知识库中已经存在的实体</li>
<li>existential variable(无阴影的矩形)：不是一个grounded entity</li>
<li>lambda variable(圆形)：不是一个grounded entity，但是代表了答案</li>
<li>aggregation function(菱形)：聚合函数</li>
</ul></li>
<li><p>查询图的边来自知识图中的关系，一个查询图应该只有一个lambda变量表示答案，不止一个grounded entity、没有或者多个existential变量和聚合函数。</p></li>
<li><p>查询图生成过程(<a href="#2015">Yih et al., 2015</a>; <a href="#2016">Bao et al., 2016</a>)：</p>
<ol type="1">
<li><p>Starting from a grounded entity found in the question (referred to as a <em>topic entity</em>), identify a core relation path linking the topic entity to a lambda variable. Existing work considers core relation paths containing a single relation(<a href="#2015">Yih et al., 2015</a>; <a href="#2016">Bao et al., 2016</a>; <a href="#2018">Luo et al., 2018</a>).</p></li>
<li><p>From a core relation path identified in Step 1, attach one or more constraints found in the question. A constraint consists of either a grounded entity or an aggregation function together with a relation.</p></li>
<li><p>With all the candidate query graphs generated from Step 1 and Step 2, rank them by measuring their similarities with the question. This is typically done through a neural network model such as a CNN . (<a href="#2015">Yih et al., 2015</a>; <a href="#2016">Bao et al., 2016</a>).</p></li>
<li><p>Execute the top-ranked query graph against the KB to obtain the answer entities.</p></li>
</ol>
<figure>
<img src="https://i.loli.net/2021/03/22/XeE7IC63fdyuUp5.png" alt="image-20210322215711338.png" /><figcaption aria-hidden="true">image-20210322215711338.png</figcaption>
</figure></li>
</ul>
<h3 id="motivation">2.2 Motivation</h3>
<ul>
<li>看起来更像是两个模型的组合：上述模型不利于解决多跳问题；最新研究出的多跳模型(beam search，在生成t+1跳关系路径之前只保留前K个t跳关系路径【(<a href="#2019">Chen et al., 2019</a>; <a href="#2019b">Lan et al., 2019b</a>)】)但忽略了在生成过程中的约束。</li>
<li>不再是关系路径构建完成之后再添加约束，而是同时合并约束和扩展关系路径。</li>
<li>This more flexible way of generating query graphs, coupled with <strong>a beam search mechanism</strong> and <strong>a semantic matching model</strong> to guide pruning, explores a much smaller search space while still maintaining a high chance of finding the correct query graph.</li>
</ul>
<h3 id="query-graph-generation">2.3 Query Graph Generation</h3>
<ul>
<li><p>利用波束搜索来迭代生成候选查询图。假设第<span class="math inline">\(t\)</span>次迭代产生K个查询图的集合，在<span class="math inline">\(t+1\)</span>次迭代中，作者使用了extend、connect、aggregate三个行为之一来为当前的查询图添加一条边或一个节点。在每个时间步获得查询图之后，用评分函数来对所有查询图进行排序，并找出 top-k。如此持续迭代，<strong>直到某一迭代的评分不高于它前一迭代的评分。</strong></p>
<p>如下图：<img src="http://p3.itc.cn/q_70/images03/20200715/7d053c5f849e45c0b9c06fc39fda1b8f.png" alt="img" /></p></li>
</ul>
<h4 id="extend">2.3.1 extend</h4>
<ul>
<li><strong>扩展</strong>动作将核心关系路径扩展了 R 中的一个关系。如果当前查询图仅包含主题实体 e，则扩展动作将在 KB 中找到链接到 e 的关系 r，并将路径增长到 r。<strong>它还使 r 的另一端成为 lambda 变量 x。</strong>如果当前查询图具有 lambda 变量 x，则扩展操作会将 x 更改为存在变量 y，通过对 KB 执行当前查询图来查找 KB 中 y 的所有绑定，找到链接到这些实体之一的关系 r ，最后将 r 附加到 y。r 的另一端成为新的 lambda 变量 x。</li>
</ul>
<h4 id="connect">2.3.2 connect</h4>
<ul>
<li>除了当前核心关系路径开始处的主题实体之外，问题中通常还会找到其他实体。 <strong>连接</strong>操作将这样的实体 e <strong>链接到 lambda 变量 x 或连接到 x 的存在变量</strong>（即 CVT 节点）。要确定使用哪个关系 r 链接 e 和 x，我们可以再次找到 x 的所有绑定，通过执行当前查询图，然后找到这些实体之一与 e 之间存在的关系。</li>
</ul>
<h4 id="aggregate">2.3.3 aggregate</h4>
<ul>
<li>作者使用一组预定义的关键字从问题中检测聚合函数。聚合操作会将检测到的聚合函数作为新节点附加到 lambda 变量 x 或连接到作为 CVT 节点的 x 的存在变量。</li>
</ul>
<h4 id="总结">2.3.4 总结</h4>
<ul>
<li>该方法的新颖之处在于，可以在连接和聚合操作之后应用扩展操作，而以前的方法是不允许的。扩展和连接操作可以理解为对多跳推理的实现，而聚合操作可理解为对问题约束的实现。</li>
</ul>
<h3 id="query-graph-ranking">2.4. Query Graph Ranking</h3>
<ul>
<li>在第 t 次迭代的末尾，算法对候选查询图进行排序，每个图获得 7 维的特征向量，并将这些向量馈送到一个全连接层。</li>
<li>向量的第一个维度来自基于 BERT 的语义匹配模型。具体来说，算法通过遵循构造查询图 g 所采取的动作序列并将每个步骤所涉及的实体和关系的文本描述顺序添加到序列中，将 g 转换为标记序列。存在变量和 lambda 变量将被忽略。</li>
<li>向量的其他 6 个维度如下：第一个维度是查询图中所有已链接实体的累积实体链接得分。第二个是查询图中出现的链接实体的数量。第三到第五个分别是查询图中实体类型的数量，时间表达式和最高级的数量。最后一个特征是查询图的答案实体的数量。</li>
</ul>
<h2 id="引用">引用</h2>
<ol type="1">
<li><p><a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/P15-1128.pdf">Semantic parsing via staged query graph generation: Question answering with knowledge base, 2015</a></p></li>
<li><p><a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/C16-1236.pdf">Constraint-based question an- swering with knowledge graph, 2016</a></p></li>
<li><p><a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/D18-1242.pdf">Knowledge base question answering via encoding of complex query graphs, 2018</a></p></li>
<li><p><span id="2019"><a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/N19-1031.pdf">Uhop: An unrestricted-hop relation extraction framework for knowledge-based question answering, 2019</a></span></p></li>
<li><p><span id="2019b"><a target="_blank" rel="noopener" href="https://ink.library.smu.edu.sg/cgi/viewcontent.cgi?article=5939&amp;context=sis_research">Multi-hop knowledge base question answering with an iterative sequence matching model, 2019b</a></span></p></li>
</ol>

      
    </div>

    
	
	

	
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/default-index/page/2/">2</a><a class="page-number" href="/default-index/page/3/">3</a><a class="extend next" rel="next" href="/default-index/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Olivia"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Olivia</p>
  <div class="site-description" itemprop="description">May All Your Troubles Be little Ones</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">30</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="/yajie.wang@mail.hfut.edu.cn" title="E-Mail → yajie.wang@mail.hfut.edu.cn"><i class="fa fa-envelope fa-fw"></i></a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="http://www.hfut.edu.cn/" title="http:&#x2F;&#x2F;www.hfut.edu.cn&#x2F;" rel="noopener" target="_blank">合肥工业大学</a>
        </li>
    </ul>
  </div>

      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2019 – 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">wyj-Olivia</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">145k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">2:12</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest-nomobile.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  
<div id="needsharebutton-float">
      <span class="btn">
        <i class="fa fa-share-alt" aria-hidden="true"></i>
      </span>
    </div>
  <script src="//cdn.jsdelivr.net/gh/theme-next/theme-next-needmoreshare2@1/needsharebutton.min.js"></script>
  <script>
      pbOptions = {};
        pbOptions.iconStyle = "box";
        pbOptions.boxForm = "horizontal";
        pbOptions.position = "bottomCenter";
        pbOptions.networks = "Weibo,Wechat,Douban,QQZone,Twitter,Facebook";
      new needShareButton('#needsharebutton-postbottom', pbOptions);
      flOptions = {};
        flOptions.iconStyle = "box";
        flOptions.boxForm = "horizontal";
        flOptions.position = "middleRight";
        flOptions.networks = "Weibo,Wechat,Douban,QQZone,Twitter,Facebook";
      new needShareButton('#needsharebutton-float', flOptions);
  </script>
</body>
</html>
